{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vpw-pkewCVks"
      },
      "source": [
        "## Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if1-sLljCBi0",
        "outputId": "b08c8066-8583-4ef3-8644-b7addd4adf85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting calflops\n",
            "  Downloading calflops-0.2.9-py3-none-any.whl (30 kB)\n",
            "Collecting accelerate>=0.22.0 (from calflops)\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from calflops) (0.19.4)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from calflops) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->calflops) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->calflops) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->calflops) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->calflops) (6.0.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.22.0->calflops) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->calflops) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->calflops) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->calflops) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->calflops) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.16.4->calflops) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->calflops) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->calflops) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->calflops) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.1.0->calflops) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.1.0->calflops) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.16.4->calflops) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.16.4->calflops) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.16.4->calflops) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.16.4->calflops) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.1.0->calflops) (1.3.0)\n",
            "Installing collected packages: accelerate, calflops\n",
            "Successfully installed accelerate-0.25.0 calflops-0.2.9\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime\n",
            "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: onnx, humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.15.0 onnxruntime-1.16.3\n",
            "Cloning into 'onnx-tensorflow'...\n",
            "remote: Enumerating objects: 6516, done.\u001b[K\n",
            "remote: Counting objects: 100% (465/465), done.\u001b[K\n",
            "remote: Compressing objects: 100% (200/200), done.\u001b[K\n",
            "remote: Total 6516 (delta 326), reused 383 (delta 261), pack-reused 6051\u001b[K\n",
            "Receiving objects: 100% (6516/6516), 1.98 MiB | 12.15 MiB/s, done.\n",
            "Resolving deltas: 100% (5051/5051), done.\n",
            "Obtaining file:///content/onnx-tensorflow\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: onnx>=1.10.2 in /usr/local/lib/python3.10/dist-packages (from onnx-tf==1.10.0) (1.15.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from onnx-tf==1.10.0) (6.0.1)\n",
            "Collecting tensorflow_addons (from onnx-tf==1.10.0)\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow_probability in /usr/local/lib/python3.10/dist-packages (from onnx-tf==1.10.0) (0.22.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx>=1.10.2->onnx-tf==1.10.0) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.10.2->onnx-tf==1.10.0) (3.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons->onnx-tf==1.10.0) (23.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons->onnx-tf==1.10.0)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (1.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (1.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (2.2.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (0.5.4)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (0.1.8)\n",
            "Requirement already satisfied: typing-extensions<4.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_probability->onnx-tf==1.10.0) (4.5.0)\n",
            "Installing collected packages: typeguard, tensorflow_addons, onnx-tf\n",
            "  Running setup.py develop for onnx-tf\n",
            "Successfully installed onnx-tf-1.10.0 tensorflow_addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install calflops\n",
        "!apt-get -qq install xxd\n",
        "!pip install pandas numpy matplotlib\n",
        "!pip install onnx onnxruntime\n",
        "!git clone https://github.com/onnx/onnx-tensorflow.git && cd onnx-tensorflow && pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6bslSW5CMUH"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"./onnx-tensorflow\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlGKIskrCR43",
        "outputId": "360b9dc4-1e8f-44ef-c150-14c5d55a63a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting onnx-simplifier\n",
            "  Downloading onnx_simplifier-0.4.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from onnx-simplifier) (1.15.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from onnx-simplifier) (13.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx->onnx-simplifier) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx->onnx-simplifier) (3.20.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnx-simplifier) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnx-simplifier) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->onnx-simplifier) (0.1.2)\n",
            "Installing collected packages: onnx-simplifier\n",
            "Successfully installed onnx-simplifier-0.4.35\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx-simplifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrG2WY_YCU35",
        "outputId": "5a6ee32c-3f72-42f7-cc98-94de36c810a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-01-02 16:41:44--  https://github.com/PINTO0309/onnx2tf/releases/download/1.16.31/flatc.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/541831874/29499355-44ab-4fb6-86c8-582f4bad68a3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240102%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240102T164144Z&X-Amz-Expires=300&X-Amz-Signature=29fb775133e36ce63055b0455cc296ad44627c448eac882fa875388812194514&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=541831874&response-content-disposition=attachment%3B%20filename%3Dflatc.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-01-02 16:41:44--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/541831874/29499355-44ab-4fb6-86c8-582f4bad68a3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240102%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240102T164144Z&X-Amz-Expires=300&X-Amz-Signature=29fb775133e36ce63055b0455cc296ad44627c448eac882fa875388812194514&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=541831874&response-content-disposition=attachment%3B%20filename%3Dflatc.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1382707 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘flatc.tar.gz’\n",
            "\n",
            "flatc.tar.gz        100%[===================>]   1.32M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2024-01-02 16:41:44 (22.6 MB/s) - ‘flatc.tar.gz’ saved [1382707/1382707]\n",
            "\n",
            "flatc\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.3.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.ngc.nvidia.com\n",
            "Collecting onnx_graphsurgeon\n",
            "  Downloading https://developer.download.nvidia.com/compute/redist/onnx-graphsurgeon/onnx_graphsurgeon-0.3.27-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx_graphsurgeon) (1.23.5)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from onnx_graphsurgeon) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx->onnx_graphsurgeon) (3.20.3)\n",
            "Installing collected packages: onnx_graphsurgeon\n",
            "Successfully installed onnx_graphsurgeon-0.3.27\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting onnxruntime==1.16.0\n",
            "  Downloading onnxruntime-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.16.0) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.16.0) (23.5.26)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.16.0) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.16.0) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.16.0) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.16.0) (1.12)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime==1.16.0) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime==1.16.0) (1.3.0)\n",
            "Downloading onnxruntime-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnxruntime\n",
            "  Attempting uninstall: onnxruntime\n",
            "    Found existing installation: onnxruntime 1.16.3\n",
            "    Uninstalling onnxruntime-1.16.3:\n",
            "      Successfully uninstalled onnxruntime-1.16.3\n",
            "Successfully installed onnxruntime-1.16.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting onnxsim==0.4.33\n",
            "  Downloading onnxsim-0.4.33-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from onnxsim==0.4.33) (1.15.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from onnxsim==0.4.33) (13.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx->onnxsim==0.4.33) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx->onnxsim==0.4.33) (3.20.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnxsim==0.4.33) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnxsim==0.4.33) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->onnxsim==0.4.33) (0.1.2)\n",
            "Downloading onnxsim-0.4.33-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnxsim\n",
            "Successfully installed onnxsim-0.4.33\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting simple_onnx_processing_tools\n",
            "  Downloading simple_onnx_processing_tools-1.1.30-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting snc4onnx>=1.0.12 (from simple_onnx_processing_tools)\n",
            "  Downloading snc4onnx-1.0.12-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting sne4onnx>=1.0.11 (from simple_onnx_processing_tools)\n",
            "  Downloading sne4onnx-1.0.11-py3-none-any.whl (7.0 kB)\n",
            "Collecting snd4onnx>=1.1.6 (from simple_onnx_processing_tools)\n",
            "  Downloading snd4onnx-1.1.6-py3-none-any.whl (9.0 kB)\n",
            "Collecting scs4onnx>=1.0.18 (from simple_onnx_processing_tools)\n",
            "  Downloading scs4onnx-1.0.18-py3-none-any.whl (10 kB)\n",
            "Collecting sog4onnx>=1.0.16 (from simple_onnx_processing_tools)\n",
            "  Downloading sog4onnx-1.0.16-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting sam4onnx>=1.0.14 (from simple_onnx_processing_tools)\n",
            "  Downloading sam4onnx-1.0.14-py3-none-any.whl (10 kB)\n",
            "Collecting soc4onnx>=1.0.2 (from simple_onnx_processing_tools)\n",
            "  Downloading soc4onnx-1.0.2-py3-none-any.whl (5.7 kB)\n",
            "Collecting scc4onnx>=1.0.5 (from simple_onnx_processing_tools)\n",
            "  Downloading scc4onnx-1.0.5-py3-none-any.whl (9.4 kB)\n",
            "Collecting sna4onnx>=1.0.6 (from simple_onnx_processing_tools)\n",
            "  Downloading sna4onnx-1.0.6-py3-none-any.whl (10 kB)\n",
            "Collecting sbi4onnx>=1.0.5 (from simple_onnx_processing_tools)\n",
            "  Downloading sbi4onnx-1.0.5-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting sor4onnx>=1.0.5 (from simple_onnx_processing_tools)\n",
            "  Downloading sor4onnx-1.0.5-py3-none-any.whl (7.1 kB)\n",
            "Collecting sit4onnx>=1.0.7 (from simple_onnx_processing_tools)\n",
            "  Downloading sit4onnx-1.0.7-py3-none-any.whl (9.8 kB)\n",
            "Collecting onnx2json>=2.0.4 (from simple_onnx_processing_tools)\n",
            "  Downloading onnx2json-2.0.4-py3-none-any.whl (5.0 kB)\n",
            "Collecting json2onnx>=2.0.3 (from simple_onnx_processing_tools)\n",
            "  Downloading json2onnx-2.0.3-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting sed4onnx>=1.0.5 (from simple_onnx_processing_tools)\n",
            "  Downloading sed4onnx-1.0.5-py3-none-any.whl (5.7 kB)\n",
            "Collecting soa4onnx>=1.0.4 (from simple_onnx_processing_tools)\n",
            "  Downloading soa4onnx-1.0.4-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting sod4onnx>=1.0.0 (from simple_onnx_processing_tools)\n",
            "  Downloading sod4onnx-1.0.0-py3-none-any.whl (5.9 kB)\n",
            "Collecting ssi4onnx>=1.0.2 (from simple_onnx_processing_tools)\n",
            "  Downloading ssi4onnx-1.0.2-py3-none-any.whl (5.5 kB)\n",
            "Collecting ssc4onnx>=1.0.5 (from simple_onnx_processing_tools)\n",
            "  Downloading ssc4onnx-1.0.8-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting sio4onnx>=1.0.2 (from simple_onnx_processing_tools)\n",
            "  Downloading sio4onnx-1.0.2-py3-none-any.whl (6.9 kB)\n",
            "Collecting svs4onnx>=1.0.0 (from simple_onnx_processing_tools)\n",
            "  Downloading svs4onnx-1.0.0-py3-none-any.whl (6.3 kB)\n",
            "Collecting onnx2tf>=1.17.6 (from simple_onnx_processing_tools)\n",
            "  Downloading onnx2tf-1.19.4-py3-none-any.whl.metadata (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sng4onnx>=1.0.1 (from simple_onnx_processing_tools)\n",
            "  Downloading sng4onnx-1.0.1-py3-none-any.whl (5.8 kB)\n",
            "Collecting sde4onnx>=1.0.0 (from simple_onnx_processing_tools)\n",
            "  Downloading sde4onnx-1.0.0-py3-none-any.whl (5.5 kB)\n",
            "Collecting spo4onnx>=1.0.3 (from simple_onnx_processing_tools)\n",
            "  Downloading spo4onnx-1.0.3-py3-none-any.whl.metadata (8.9 kB)\n",
            "Downloading simple_onnx_processing_tools-1.1.30-py3-none-any.whl (7.8 kB)\n",
            "Downloading json2onnx-2.0.3-py3-none-any.whl (5.0 kB)\n",
            "Downloading onnx2tf-1.19.4-py3-none-any.whl (409 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.9/409.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sbi4onnx-1.0.5-py3-none-any.whl (6.8 kB)\n",
            "Downloading snc4onnx-1.0.12-py3-none-any.whl (10 kB)\n",
            "Downloading soa4onnx-1.0.4-py3-none-any.whl (6.3 kB)\n",
            "Downloading sog4onnx-1.0.16-py3-none-any.whl (9.6 kB)\n",
            "Downloading spo4onnx-1.0.3-py3-none-any.whl (11 kB)\n",
            "Downloading ssc4onnx-1.0.8-py3-none-any.whl (6.6 kB)\n",
            "Installing collected packages: svs4onnx, ssi4onnx, ssc4onnx, spo4onnx, sor4onnx, sog4onnx, sod4onnx, soc4onnx, soa4onnx, sng4onnx, sne4onnx, snd4onnx, snc4onnx, sit4onnx, sio4onnx, sed4onnx, sde4onnx, scs4onnx, scc4onnx, sbi4onnx, sam4onnx, onnx2tf, onnx2json, json2onnx, sna4onnx, simple_onnx_processing_tools\n",
            "Successfully installed json2onnx-2.0.3 onnx2json-2.0.4 onnx2tf-1.19.4 sam4onnx-1.0.14 sbi4onnx-1.0.5 scc4onnx-1.0.5 scs4onnx-1.0.18 sde4onnx-1.0.0 sed4onnx-1.0.5 simple_onnx_processing_tools-1.1.30 sio4onnx-1.0.2 sit4onnx-1.0.7 sna4onnx-1.0.6 snc4onnx-1.0.12 snd4onnx-1.1.6 sne4onnx-1.0.11 sng4onnx-1.0.1 soa4onnx-1.0.4 soc4onnx-1.0.2 sod4onnx-1.0.0 sog4onnx-1.0.16 sor4onnx-1.0.5 spo4onnx-1.0.3 ssc4onnx-1.0.8 ssi4onnx-1.0.2 svs4onnx-1.0.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: onnx2tf in /usr/local/lib/python3.10/dist-packages (1.19.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (3.20.3)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting h5py==3.7.0\n",
            "  Downloading h5py-3.7.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.10/dist-packages (from h5py==3.7.0) (1.23.5)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "Successfully installed h5py-3.7.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: psutil==5.9.5 in /usr/local/lib/python3.10/dist-packages (5.9.5)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: ml_dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: numpy>1.20 in /usr/local/lib/python3.10/dist-packages (from ml_dtypes==0.2.0) (1.23.5)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/PINTO0309/onnx2tf/releases/download/1.16.31/flatc.tar.gz \\\n",
        "  && tar -zxvf flatc.tar.gz \\\n",
        "  && sudo chmod +x flatc \\\n",
        "  && sudo mv flatc /usr/bin/\n",
        "!pip install -U pip \\\n",
        "  && pip install -U onnx>=1.14.1 \\\n",
        "  && python -m pip install onnx_graphsurgeon \\\n",
        "        --index-url https://pypi.ngc.nvidia.com \\\n",
        "  && pip install -U onnxruntime==1.16.0 \\\n",
        "  && pip install -U onnxsim==0.4.33 \\\n",
        "  && pip install -U simple_onnx_processing_tools \\\n",
        "  && pip install -U onnx2tf \\\n",
        "  && pip install -U protobuf==3.20.3 \\\n",
        "  && pip install -U h5py==3.7.0 \\\n",
        "  && pip install -U psutil==5.9.5 \\\n",
        "  && pip install -U ml_dtypes==0.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4hRjLejmepm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    # torch.backends.cudnn.deterministic = True\n",
        "    # torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5ToCLX_Cfie"
      },
      "source": [
        "## Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkxOkhMv65me"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Define the directory containing the CSV files\n",
        "directory = \"./\" # Replace with the actual directory path\n",
        "\n",
        "def prepare_data():\n",
        "  # Initialize an empty list to store the data\n",
        "  data = []\n",
        "\n",
        "  # List of CSV files\n",
        "  csv_files = [\"AlohomoraCharm.csv\", \"ArrestoMomentumCharm.csv\", \"AvadaKedavra.csv\", \"LocomotorCharm.csv\", \"Revelio.csv\"]\n",
        "\n",
        "  # Loop through each file\n",
        "  for file in csv_files:\n",
        "      # Construct the full path to the file\n",
        "      file_path = os.path.join(directory, file)\n",
        "\n",
        "      # Read the CSV file, skipping empty rows (which are interpreted as NaN)\n",
        "      df = pd.read_csv(file_path, header=0)\n",
        "\n",
        "      # Drop NaN rows\n",
        "      df = df.dropna()\n",
        "      df['aX'] = (df['aX']+4)/8\n",
        "      df['aY'] = (df['aY']+4)/8\n",
        "      df['aZ'] = (df['aZ']+4)/8\n",
        "\n",
        "      df['gX'] = (df['gX']+2000)/4000\n",
        "      df['gY'] = (df['gY']+2000)/4000\n",
        "      df['gZ'] = (df['gZ']+2000)/4000\n",
        "\n",
        "      # Split the dataframe into samples of 119 rows each\n",
        "      for i in range(0, len(df), 119):\n",
        "          sample = df.iloc[i:i+119]\n",
        "\n",
        "          # Convert the sample dataframe to a numpy array\n",
        "          sample_array = sample.to_numpy()\n",
        "\n",
        "          # Get the label from the file name\n",
        "          label = file.replace(\".csv\", \"\")\n",
        "\n",
        "          # Append the label and data to the list\n",
        "          data.append({'label': label, 'data': sample_array})\n",
        "\n",
        "  # Create a final dataframe\n",
        "  final_df = pd.DataFrame(data)\n",
        "  return final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaAWlyp0-5QO"
      },
      "outputs": [],
      "source": [
        "df = prepare_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1vk8RP973sL",
        "outputId": "d366393f-fe13-4985-aa94-30de013f20d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 125 samples in total.\n"
          ]
        }
      ],
      "source": [
        "print(f'There are {len(df.index)} samples in total.')\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labels = df[\"label\"].unique()\n",
        "encoder = LabelEncoder()\n",
        "df[\"ClassID\"] = encoder.fit_transform(df[\"label\"])\n",
        "\n",
        "df[\"data\"] = df[\"data\"].apply(lambda x: x.transpose((1, 0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mexmik73-cZJ",
        "outputId": "3a2f2da2-6df6-4fcc-bb99-32af8587b04c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['AlohomoraCharm', 'ArrestoMomentumCharm', 'AvadaKedavra',\n",
              "       'LocomotorCharm', 'Revelio'], dtype=object)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoder.inverse_transform([0,1,2,3,4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9qjMsLx-kZC",
        "outputId": "9beb8bac-eef4-44c0-d196-88d853deada4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6, 119)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.iloc[0][\"data\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z98SEY0H-n1F"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-4ak190-tdw",
        "outputId": "9c16cc6e-48d7-4b96-b794-90c7b5d147de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training set: 100\n",
            "Number of test set: 25\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of training set: {len(df_train.index)}\")\n",
        "print(f\"Number of test set: {len(df_test.index)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxRXDQ8e_XgQ"
      },
      "source": [
        "## Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCSerHfn_WoI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFIRwGpR_RMN"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class GestureDataset(Dataset):\n",
        "    def __init__(self, df, transform, preload=False, device='cpu'):\n",
        "        self.df = df\n",
        "        self.num_classes = self.df[\"ClassID\"].nunique()\n",
        "        self.transform = transform\n",
        "        self.preload = preload\n",
        "        self.data = []\n",
        "\n",
        "        if self.preload:\n",
        "            for index in tqdm(range(len(self.df.index)), f\"Preloading dataset to {device}\"):\n",
        "                data = self.df.iloc[index]['data']\n",
        "                data = torch.tensor(data, dtype=torch.float32)\n",
        "                label = self.df.iloc[index][\"ClassID\"]\n",
        "\n",
        "                data = data.to(device)  # Move to the specified device\n",
        "                self.data.append((data, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df.index)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.preload:\n",
        "            return self.data[index]\n",
        "\n",
        "        data = self.df.iloc[index]['data']\n",
        "        data = torch.tensor(data, dtype=torch.float32)\n",
        "\n",
        "        label = self.df.iloc[index][\"ClassID\"]\n",
        "\n",
        "        return data, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zognLFdW_w0t",
        "outputId": "ac8299d0-5c3c-4d92-aaf9-fd4a628f4987"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bC4moDrl_0PD"
      },
      "outputs": [],
      "source": [
        "# # Transforms\n",
        "# transform = transforms.Compose([\n",
        "#     # transforms.Resize((32, 32)),\n",
        "#     transforms.ToTensor(),\n",
        "# ])\n",
        "\n",
        "# # Create dataset and dataloaders\n",
        "# train_dataset = GestureDataset(df=df_train, transform=transform, preload=True, device=device)\n",
        "\n",
        "# test_dataset = GestureDataset(df=df_test, transform=transform, preload=True, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-zN0DLTqIW8"
      },
      "source": [
        "### Add data augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7703kIdB5tL_",
        "outputId": "de6e334d-eb28-4d1c-a0c6-812a74f2bfc1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Preloading dataset to cpu: 100%|██████████| 100/100 [00:00<00:00, 1871.09it/s]\n",
            "Preloading dataset to cpu: 100%|██████████| 25/25 [00:00<00:00, 2186.49it/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "\n",
        "class AddRandomNoise(object):\n",
        "    def __init__(self, noise_level=0.05):\n",
        "        self.noise_level = noise_level\n",
        "\n",
        "    def __call__(self, data):\n",
        "        noise = torch.randn_like(data) * self.noise_level\n",
        "        return data + noise\n",
        "\n",
        "class TimeWarp(object):\n",
        "    def __init__(self, warp_factor=0.1):\n",
        "        self.warp_factor = warp_factor\n",
        "\n",
        "    def __call__(self, data):\n",
        "        time_steps = data.shape[0]\n",
        "        warp = np.random.uniform(1 - self.warp_factor, 1 + self.warp_factor)\n",
        "        new_time_steps = int(time_steps * warp)\n",
        "        data = torch.nn.functional.interpolate(data.view(1, 1, -1), size=new_time_steps, mode='linear', align_corners=False)\n",
        "        return data.view(-1)\n",
        "\n",
        "class ScaleTransform(object):\n",
        "    def __init__(self, scale_factor=1.2):\n",
        "        self.scale_factor = scale_factor\n",
        "\n",
        "    def __call__(self, data):\n",
        "        return data * self.scale_factor\n",
        "\n",
        "# Define your transform pipeline\n",
        "transform_train = transforms.Compose([\n",
        "    AddRandomNoise(noise_level=0.05),\n",
        "    TimeWarp(warp_factor=0.1),\n",
        "    ScaleTransform(scale_factor=1.2),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Create dataset and dataloaders\n",
        "train_dataset = GestureDataset(df=df_train, transform=transform_train, preload=True, device=device)\n",
        "test_dataset = GestureDataset(df=df_test, transform=transform_test, preload=True, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sLrweV9ASvS",
        "outputId": "0a714df2-c504-4aa7-e1a9-26dc64ebad16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of classes: 5\n",
            "torch.Size([100, 6, 119]) torch.Size([100])\n"
          ]
        }
      ],
      "source": [
        "# set_seed(666)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=True)\n",
        "\n",
        "print(f'Num of classes: {train_dataset.num_classes}')\n",
        "num_classes = train_dataset.num_classes\n",
        "# Example: Print the shape of first batch data and labels\n",
        "for data, labels in train_loader:\n",
        "    print(data.shape,  labels.shape)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOGYOKq9AgDr"
      },
      "source": [
        "## Plot examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 970
        },
        "id": "e3cZiwq2AfUt",
        "outputId": "afd85277-8e71-4fba-db84-bc5f917eeb6c"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": [
              "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
              "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
              "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
              "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"1072.863125pt\" height=\"711.43625pt\" viewBox=\"0 0 1072.863125 711.43625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
              " <metadata>\n",
              "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
              "   <cc:Work>\n",
              "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
              "    <dc:date>2024-01-02T16:50:14.742490</dc:date>\n",
              "    <dc:format>image/svg+xml</dc:format>\n",
              "    <dc:creator>\n",
              "     <cc:Agent>\n",
              "      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n",
              "     </cc:Agent>\n",
              "    </dc:creator>\n",
              "   </cc:Work>\n",
              "  </rdf:RDF>\n",
              " </metadata>\n",
              " <defs>\n",
              "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
              " </defs>\n",
              " <g id=\"figure_1\">\n",
              "  <g id=\"patch_1\">\n",
              "   <path d=\"M 0 711.43625 \n",
              "L 1072.863125 711.43625 \n",
              "L 1072.863125 0 \n",
              "L 0 0 \n",
              "z\n",
              "\" style=\"fill: #ffffff\"/>\n",
              "  </g>\n",
              "  <g id=\"axes_1\">\n",
              "   <g id=\"patch_2\">\n",
              "    <path d=\"M 30.103125 155.658125 \n",
              "L 1065.663125 155.658125 \n",
              "L 1065.663125 22.318125 \n",
              "L 30.103125 22.318125 \n",
              "z\n",
              "\" style=\"fill: #ffffff\"/>\n",
              "   </g>\n",
              "   <g id=\"matplotlib.axis_1\">\n",
              "    <g id=\"xtick_1\">\n",
              "     <g id=\"line2d_1\">\n",
              "      <defs>\n",
              "       <path id=\"m75345596d3\" d=\"M 0 0 \n",
              "L 0 3.5 \n",
              "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </defs>\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"77.174034\" y=\"155.658125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_1\">\n",
              "      <!-- 0 -->\n",
              "      <g transform=\"translate(73.992784 170.256562) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
              "Q 1547 4250 1301 3770 \n",
              "Q 1056 3291 1056 2328 \n",
              "Q 1056 1369 1301 889 \n",
              "Q 1547 409 2034 409 \n",
              "Q 2525 409 2770 889 \n",
              "Q 3016 1369 3016 2328 \n",
              "Q 3016 3291 2770 3770 \n",
              "Q 2525 4250 2034 4250 \n",
              "z\n",
              "M 2034 4750 \n",
              "Q 2819 4750 3233 4129 \n",
              "Q 3647 3509 3647 2328 \n",
              "Q 3647 1150 3233 529 \n",
              "Q 2819 -91 2034 -91 \n",
              "Q 1250 -91 836 529 \n",
              "Q 422 1150 422 2328 \n",
              "Q 422 3509 836 4129 \n",
              "Q 1250 4750 2034 4750 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_2\">\n",
              "     <g id=\"line2d_2\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"236.736438\" y=\"155.658125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_2\">\n",
              "      <!-- 20 -->\n",
              "      <g transform=\"translate(230.373938 170.256562) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
              "L 3431 531 \n",
              "L 3431 0 \n",
              "L 469 0 \n",
              "L 469 531 \n",
              "Q 828 903 1448 1529 \n",
              "Q 2069 2156 2228 2338 \n",
              "Q 2531 2678 2651 2914 \n",
              "Q 2772 3150 2772 3378 \n",
              "Q 2772 3750 2511 3984 \n",
              "Q 2250 4219 1831 4219 \n",
              "Q 1534 4219 1204 4116 \n",
              "Q 875 4013 500 3803 \n",
              "L 500 4441 \n",
              "Q 881 4594 1212 4672 \n",
              "Q 1544 4750 1819 4750 \n",
              "Q 2544 4750 2975 4387 \n",
              "Q 3406 4025 3406 3419 \n",
              "Q 3406 3131 3298 2873 \n",
              "Q 3191 2616 2906 2266 \n",
              "Q 2828 2175 2409 1742 \n",
              "Q 1991 1309 1228 531 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_3\">\n",
              "     <g id=\"line2d_3\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"396.298841\" y=\"155.658125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_3\">\n",
              "      <!-- 40 -->\n",
              "      <g transform=\"translate(389.936341 170.256562) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
              "L 825 1625 \n",
              "L 2419 1625 \n",
              "L 2419 4116 \n",
              "z\n",
              "M 2253 4666 \n",
              "L 3047 4666 \n",
              "L 3047 1625 \n",
              "L 3713 1625 \n",
              "L 3713 1100 \n",
              "L 3047 1100 \n",
              "L 3047 0 \n",
              "L 2419 0 \n",
              "L 2419 1100 \n",
              "L 313 1100 \n",
              "L 313 1709 \n",
              "L 2253 4666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_4\">\n",
              "     <g id=\"line2d_4\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"555.861245\" y=\"155.658125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_4\">\n",
              "      <!-- 60 -->\n",
              "      <g transform=\"translate(549.498745 170.256562) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
              "Q 1688 2584 1439 2293 \n",
              "Q 1191 2003 1191 1497 \n",
              "Q 1191 994 1439 701 \n",
              "Q 1688 409 2113 409 \n",
              "Q 2538 409 2786 701 \n",
              "Q 3034 994 3034 1497 \n",
              "Q 3034 2003 2786 2293 \n",
              "Q 2538 2584 2113 2584 \n",
              "z\n",
              "M 3366 4563 \n",
              "L 3366 3988 \n",
              "Q 3128 4100 2886 4159 \n",
              "Q 2644 4219 2406 4219 \n",
              "Q 1781 4219 1451 3797 \n",
              "Q 1122 3375 1075 2522 \n",
              "Q 1259 2794 1537 2939 \n",
              "Q 1816 3084 2150 3084 \n",
              "Q 2853 3084 3261 2657 \n",
              "Q 3669 2231 3669 1497 \n",
              "Q 3669 778 3244 343 \n",
              "Q 2819 -91 2113 -91 \n",
              "Q 1303 -91 875 529 \n",
              "Q 447 1150 447 2328 \n",
              "Q 447 3434 972 4092 \n",
              "Q 1497 4750 2381 4750 \n",
              "Q 2619 4750 2861 4703 \n",
              "Q 3103 4656 3366 4563 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_5\">\n",
              "     <g id=\"line2d_5\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"715.423649\" y=\"155.658125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_5\">\n",
              "      <!-- 80 -->\n",
              "      <g transform=\"translate(709.061149 170.256562) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
              "Q 1584 2216 1326 1975 \n",
              "Q 1069 1734 1069 1313 \n",
              "Q 1069 891 1326 650 \n",
              "Q 1584 409 2034 409 \n",
              "Q 2484 409 2743 651 \n",
              "Q 3003 894 3003 1313 \n",
              "Q 3003 1734 2745 1975 \n",
              "Q 2488 2216 2034 2216 \n",
              "z\n",
              "M 1403 2484 \n",
              "Q 997 2584 770 2862 \n",
              "Q 544 3141 544 3541 \n",
              "Q 544 4100 942 4425 \n",
              "Q 1341 4750 2034 4750 \n",
              "Q 2731 4750 3128 4425 \n",
              "Q 3525 4100 3525 3541 \n",
              "Q 3525 3141 3298 2862 \n",
              "Q 3072 2584 2669 2484 \n",
              "Q 3125 2378 3379 2068 \n",
              "Q 3634 1759 3634 1313 \n",
              "Q 3634 634 3220 271 \n",
              "Q 2806 -91 2034 -91 \n",
              "Q 1263 -91 848 271 \n",
              "Q 434 634 434 1313 \n",
              "Q 434 1759 690 2068 \n",
              "Q 947 2378 1403 2484 \n",
              "z\n",
              "M 1172 3481 \n",
              "Q 1172 3119 1398 2916 \n",
              "Q 1625 2713 2034 2713 \n",
              "Q 2441 2713 2670 2916 \n",
              "Q 2900 3119 2900 3481 \n",
              "Q 2900 3844 2670 4047 \n",
              "Q 2441 4250 2034 4250 \n",
              "Q 1625 4250 1398 4047 \n",
              "Q 1172 3844 1172 3481 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_6\">\n",
              "     <g id=\"line2d_6\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"874.986053\" y=\"155.658125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_6\">\n",
              "      <!-- 100 -->\n",
              "      <g transform=\"translate(865.442303 170.256562) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
              "L 1825 531 \n",
              "L 1825 4091 \n",
              "L 703 3866 \n",
              "L 703 4441 \n",
              "L 1819 4666 \n",
              "L 2450 4666 \n",
              "L 2450 531 \n",
              "L 3481 531 \n",
              "L 3481 0 \n",
              "L 794 0 \n",
              "L 794 531 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_7\">\n",
              "     <g id=\"line2d_7\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"1034.548456\" y=\"155.658125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_7\">\n",
              "      <!-- 120 -->\n",
              "      <g transform=\"translate(1025.004706 170.256562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"matplotlib.axis_2\">\n",
              "    <g id=\"ytick_1\">\n",
              "     <g id=\"line2d_8\">\n",
              "      <defs>\n",
              "       <path id=\"m953c48f76d\" d=\"M 0 0 \n",
              "L -3.5 0 \n",
              "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </defs>\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"149.597216\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_8\">\n",
              "      <!-- 0.0 -->\n",
              "      <g transform=\"translate(7.2 153.396435) scale(0.1 -0.1)\">\n",
              "       <defs>\n",
              "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
              "L 1344 794 \n",
              "L 1344 0 \n",
              "L 684 0 \n",
              "L 684 794 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       </defs>\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_2\">\n",
              "     <g id=\"line2d_9\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"125.35358\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_9\">\n",
              "      <!-- 0.2 -->\n",
              "      <g transform=\"translate(7.2 129.152798) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_3\">\n",
              "     <g id=\"line2d_10\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"101.109943\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_10\">\n",
              "      <!-- 0.4 -->\n",
              "      <g transform=\"translate(7.2 104.909162) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_4\">\n",
              "     <g id=\"line2d_11\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"76.866307\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_11\">\n",
              "      <!-- 0.6 -->\n",
              "      <g transform=\"translate(7.2 80.665526) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_5\">\n",
              "     <g id=\"line2d_12\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"52.62267\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_12\">\n",
              "      <!-- 0.8 -->\n",
              "      <g transform=\"translate(7.2 56.421889) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_6\">\n",
              "     <g id=\"line2d_13\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"28.379034\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_13\">\n",
              "      <!-- 1.0 -->\n",
              "      <g transform=\"translate(7.2 32.178253) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"line2d_14\">\n",
              "    <path d=\"M 77.174034 93.01863 \n",
              "L 85.152154 95.715734 \n",
              "L 93.130274 98.170401 \n",
              "L 101.108395 100.837203 \n",
              "L 109.086515 104.110092 \n",
              "L 117.064635 108.867907 \n",
              "L 125.042755 115.247014 \n",
              "L 133.020875 121.55036 \n",
              "L 140.998996 127.49005 \n",
              "L 148.977116 132.187254 \n",
              "L 156.955236 134.763141 \n",
              "L 164.933356 133.793396 \n",
              "L 172.911476 130.035632 \n",
              "L 180.889596 124.489901 \n",
              "L 188.867717 117.171351 \n",
              "L 196.845837 109.489149 \n",
              "L 204.823957 102.216058 \n",
              "L 212.802077 95.62482 \n",
              "L 220.780197 90.579114 \n",
              "L 228.758318 87.169854 \n",
              "L 236.736438 84.396987 \n",
              "L 244.714558 81.760487 \n",
              "L 252.692678 79.305824 \n",
              "L 260.670798 77.048132 \n",
              "L 268.648919 75.472295 \n",
              "L 276.627039 73.532807 \n",
              "L 284.605159 72.214561 \n",
              "L 292.583279 71.472096 \n",
              "L 300.561399 71.153899 \n",
              "L 308.539519 71.517556 \n",
              "L 316.51764 72.699435 \n",
              "L 324.49576 73.729787 \n",
              "L 332.47388 75.032882 \n",
              "L 340.452 77.01783 \n",
              "L 348.43012 79.320975 \n",
              "L 356.408241 81.957467 \n",
              "L 364.386361 84.487901 \n",
              "L 372.364481 87.215308 \n",
              "L 380.342601 89.882109 \n",
              "L 388.320721 92.291319 \n",
              "L 396.298841 94.700533 \n",
              "L 404.276962 97.079437 \n",
              "L 412.255082 99.534108 \n",
              "L 420.233202 101.200857 \n",
              "L 428.211322 103.07974 \n",
              "L 436.189442 104.549508 \n",
              "L 444.167563 105.337427 \n",
              "L 452.145683 105.670778 \n",
              "L 460.123803 105.382884 \n",
              "L 468.101923 104.822251 \n",
              "L 476.080043 103.928267 \n",
              "L 484.058164 102.610017 \n",
              "L 492.036284 101.291771 \n",
              "L 500.014404 99.852305 \n",
              "L 507.992524 97.973422 \n",
              "L 515.970644 96.170302 \n",
              "L 523.948764 94.261117 \n",
              "L 531.926885 92.397385 \n",
              "L 539.905005 90.745788 \n",
              "L 547.883125 89.003276 \n",
              "L 555.861245 87.942622 \n",
              "L 563.839365 87.07894 \n",
              "L 571.817486 86.412237 \n",
              "L 579.795606 85.927364 \n",
              "L 587.773726 85.669779 \n",
              "L 595.751846 85.715233 \n",
              "L 603.729966 85.730384 \n",
              "L 611.708086 85.563714 \n",
              "L 619.686207 85.548556 \n",
              "L 627.664327 85.412188 \n",
              "L 635.642447 85.44249 \n",
              "L 643.620567 85.07884 \n",
              "L 651.598687 85.048531 \n",
              "L 659.576808 85.169754 \n",
              "L 667.554928 85.897061 \n",
              "L 675.533048 87.245617 \n",
              "L 683.511168 89.382084 \n",
              "L 691.489288 91.321576 \n",
              "L 699.467409 93.079238 \n",
              "L 707.445529 94.549011 \n",
              "L 715.423649 95.321775 \n",
              "L 723.401769 96.215759 \n",
              "L 731.379889 97.018829 \n",
              "L 739.358009 97.624919 \n",
              "L 747.33613 98.170401 \n",
              "L 755.31425 98.518904 \n",
              "L 763.29237 98.973472 \n",
              "L 771.27049 98.655275 \n",
              "L 779.24861 97.306723 \n",
              "L 787.226731 95.8218 \n",
              "L 795.204851 93.912614 \n",
              "L 803.182971 91.306424 \n",
              "L 811.161091 88.806296 \n",
              "L 819.139211 86.366784 \n",
              "L 827.117331 83.215108 \n",
              "L 835.095452 79.836151 \n",
              "L 843.073572 77.154198 \n",
              "L 851.051692 75.123796 \n",
              "L 859.029812 73.532807 \n",
              "L 867.007932 72.290317 \n",
              "L 874.986053 71.39634 \n",
              "L 882.964173 70.805401 \n",
              "L 890.942293 71.062985 \n",
              "L 898.920413 71.411491 \n",
              "L 906.898533 71.956969 \n",
              "L 914.876654 72.487297 \n",
              "L 922.854774 73.305525 \n",
              "L 930.832894 74.063134 \n",
              "L 938.811014 74.851053 \n",
              "L 946.789134 75.563209 \n",
              "L 954.767254 76.184458 \n",
              "L 962.745375 76.654173 \n",
              "L 970.723495 76.957218 \n",
              "L 978.701615 77.320875 \n",
              "L 986.679735 77.729986 \n",
              "L 994.657855 78.093643 \n",
              "L 1002.635976 78.426991 \n",
              "L 1010.614096 78.745187 \n",
              "L 1018.592216 79.01793 \n",
              "\" clip-path=\"url(#pc9aabe8b1d)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_15\">\n",
              "    <path d=\"M 77.174034 107.867858 \n",
              "L 85.152154 108.82245 \n",
              "L 93.130274 121.126096 \n",
              "L 101.108395 139.172452 \n",
              "L 109.086515 149.597216 \n",
              "L 117.064635 149.597216 \n",
              "L 125.042755 149.597216 \n",
              "L 133.020875 149.597216 \n",
              "L 140.998996 149.597216 \n",
              "L 148.977116 149.597216 \n",
              "L 156.955236 143.066586 \n",
              "L 164.933356 116.807697 \n",
              "L 172.911476 93.01863 \n",
              "L 180.889596 72.790349 \n",
              "L 188.867717 56.304672 \n",
              "L 196.845837 47.561808 \n",
              "L 204.823957 42.470645 \n",
              "L 212.802077 42.743388 \n",
              "L 220.780197 45.804149 \n",
              "L 228.758318 48.970976 \n",
              "L 236.736438 49.577066 \n",
              "L 244.714558 47.501204 \n",
              "L 252.692678 44.152548 \n",
              "L 260.670798 40.425092 \n",
              "L 268.648919 38.364381 \n",
              "L 276.627039 37.531008 \n",
              "L 284.605159 35.879407 \n",
              "L 292.583279 33.773242 \n",
              "L 300.561399 30.242766 \n",
              "L 308.539519 28.379034 \n",
              "L 316.51764 28.379034 \n",
              "L 324.49576 28.379034 \n",
              "L 332.47388 28.379034 \n",
              "L 340.452 28.379034 \n",
              "L 348.43012 30.030635 \n",
              "L 356.408241 34.909667 \n",
              "L 364.386361 39.743239 \n",
              "L 372.364481 44.531357 \n",
              "L 380.342601 48.713384 \n",
              "L 388.320721 52.213558 \n",
              "L 396.298841 55.07734 \n",
              "L 404.276962 58.183555 \n",
              "L 412.255082 61.94132 \n",
              "L 420.233202 65.335429 \n",
              "L 428.211322 69.881107 \n",
              "L 436.189442 77.366329 \n",
              "L 444.167563 85.563714 \n",
              "L 452.145683 92.639822 \n",
              "L 460.123803 98.564361 \n",
              "L 468.101923 104.564663 \n",
              "L 476.080043 110.640721 \n",
              "L 484.058164 115.125794 \n",
              "L 492.036284 118.307772 \n",
              "L 500.014404 121.1564 \n",
              "L 507.992524 123.1565 \n",
              "L 515.970644 124.595966 \n",
              "L 523.948764 125.641473 \n",
              "L 531.926885 126.308174 \n",
              "L 539.905005 126.111194 \n",
              "L 547.883125 125.156599 \n",
              "L 555.861245 124.308072 \n",
              "L 563.839365 122.95952 \n",
              "L 571.817486 121.398837 \n",
              "L 579.795606 118.671429 \n",
              "L 587.773726 114.519704 \n",
              "L 595.751846 110.110394 \n",
              "L 603.729966 106.746588 \n",
              "L 611.708086 105.261664 \n",
              "L 619.686207 105.595015 \n",
              "L 627.664327 107.8224 \n",
              "L 635.642447 111.868057 \n",
              "L 643.620567 115.989476 \n",
              "L 651.598687 119.656326 \n",
              "L 659.576808 121.565511 \n",
              "L 667.554928 123.035282 \n",
              "L 675.533048 123.262565 \n",
              "L 683.511168 121.383684 \n",
              "L 691.489288 118.504752 \n",
              "L 699.467409 116.292521 \n",
              "L 707.445529 115.519753 \n",
              "L 715.423649 115.004577 \n",
              "L 723.401769 114.398487 \n",
              "L 731.379889 113.201458 \n",
              "L 739.358009 111.701383 \n",
              "L 747.33613 110.01948 \n",
              "L 755.31425 107.398135 \n",
              "L 763.29237 103.56461 \n",
              "L 771.27049 99.140149 \n",
              "L 779.24861 95.079338 \n",
              "L 787.226731 91.139747 \n",
              "L 795.204851 87.942622 \n",
              "L 803.182971 83.381786 \n",
              "L 811.161091 77.381487 \n",
              "L 819.139211 69.926567 \n",
              "L 827.117331 62.804995 \n",
              "L 835.095452 56.653178 \n",
              "L 843.073572 51.592317 \n",
              "L 851.051692 49.167956 \n",
              "L 859.029812 48.198208 \n",
              "L 867.007932 48.213359 \n",
              "L 874.986053 50.395287 \n",
              "L 882.964173 53.622719 \n",
              "L 890.942293 57.062288 \n",
              "L 898.920413 60.456397 \n",
              "L 906.898533 63.623224 \n",
              "L 914.876654 66.850655 \n",
              "L 922.854774 70.350829 \n",
              "L 930.832894 73.941918 \n",
              "L 938.811014 76.745087 \n",
              "L 946.789134 80.017979 \n",
              "L 954.767254 83.503002 \n",
              "L 962.745375 86.184955 \n",
              "L 970.723495 87.200156 \n",
              "L 978.701615 86.760743 \n",
              "L 986.679735 86.321323 \n",
              "L 994.657855 86.412237 \n",
              "L 1002.635976 87.094091 \n",
              "L 1010.614096 87.821398 \n",
              "L 1018.592216 88.897211 \n",
              "\" clip-path=\"url(#pc9aabe8b1d)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_16\">\n",
              "    <path d=\"M 77.174034 120.610918 \n",
              "L 85.152154 125.596016 \n",
              "L 93.130274 130.641722 \n",
              "L 101.108395 129.899262 \n",
              "L 109.086515 124.747489 \n",
              "L 117.064635 114.15605 \n",
              "L 125.042755 91.245813 \n",
              "L 133.020875 80.775596 \n",
              "L 140.998996 69.199253 \n",
              "L 148.977116 58.032028 \n",
              "L 156.955236 50.122545 \n",
              "L 164.933356 44.394989 \n",
              "L 172.911476 41.152399 \n",
              "L 180.889596 38.925017 \n",
              "L 188.867717 38.712887 \n",
              "L 196.845837 39.000781 \n",
              "L 204.823957 43.394939 \n",
              "L 212.802077 50.22861 \n",
              "L 220.780197 56.986525 \n",
              "L 228.758318 62.411036 \n",
              "L 236.736438 65.638474 \n",
              "L 244.714558 66.15365 \n",
              "L 252.692678 63.865657 \n",
              "L 260.670798 61.001875 \n",
              "L 268.648919 59.638176 \n",
              "L 276.627039 58.047187 \n",
              "L 284.605159 56.410737 \n",
              "L 292.583279 55.350083 \n",
              "L 300.561399 56.137994 \n",
              "L 308.539519 57.168354 \n",
              "L 316.51764 60.441246 \n",
              "L 324.49576 65.668777 \n",
              "L 332.47388 71.214511 \n",
              "L 340.452 75.926866 \n",
              "L 348.43012 78.942167 \n",
              "L 356.408241 80.411939 \n",
              "L 364.386361 80.396788 \n",
              "L 372.364481 78.457293 \n",
              "L 380.342601 75.548058 \n",
              "L 388.320721 72.623672 \n",
              "L 396.298841 68.426493 \n",
              "L 404.276962 63.562612 \n",
              "L 412.255082 60.592765 \n",
              "L 420.233202 60.213957 \n",
              "L 428.211322 62.50195 \n",
              "L 436.189442 65.411185 \n",
              "L 444.167563 66.532459 \n",
              "L 452.145683 65.365732 \n",
              "L 460.123803 64.426294 \n",
              "L 468.101923 64.699029 \n",
              "L 476.080043 65.911217 \n",
              "L 484.058164 67.562811 \n",
              "L 492.036284 69.487147 \n",
              "L 500.014404 72.381231 \n",
              "L 507.992524 76.138997 \n",
              "L 515.970644 79.411889 \n",
              "L 523.948764 82.169605 \n",
              "L 531.926885 84.07879 \n",
              "L 539.905005 84.715183 \n",
              "L 547.883125 85.760694 \n",
              "L 555.861245 86.184955 \n",
              "L 563.839365 86.291021 \n",
              "L 571.817486 85.972825 \n",
              "L 579.795606 84.503052 \n",
              "L 587.773726 82.8363 \n",
              "L 595.751846 81.608968 \n",
              "L 603.729966 82.396887 \n",
              "L 611.708086 84.563664 \n",
              "L 619.686207 87.44259 \n",
              "L 627.664327 91.367033 \n",
              "L 635.642447 95.276318 \n",
              "L 643.620567 98.473447 \n",
              "L 651.598687 100.519003 \n",
              "L 659.576808 100.276566 \n",
              "L 667.554928 98.943169 \n",
              "L 675.533048 96.882458 \n",
              "L 683.511168 94.185354 \n",
              "L 691.489288 91.579164 \n",
              "L 699.467409 90.306371 \n",
              "L 707.445529 89.791195 \n",
              "L 715.423649 88.548712 \n",
              "L 723.401769 85.775845 \n",
              "L 731.379889 82.487802 \n",
              "L 739.358009 79.927065 \n",
              "L 747.33613 78.608819 \n",
              "L 755.31425 77.533006 \n",
              "L 763.29237 76.229911 \n",
              "L 771.27049 73.714636 \n",
              "L 779.24861 69.411391 \n",
              "L 787.226731 63.653526 \n",
              "L 795.204851 58.622968 \n",
              "L 803.182971 54.092441 \n",
              "L 811.161091 51.122594 \n",
              "L 819.139211 49.501303 \n",
              "L 827.117331 49.880111 \n",
              "L 835.095452 50.789247 \n",
              "L 843.073572 51.758994 \n",
              "L 851.051692 53.365134 \n",
              "L 859.029812 56.274369 \n",
              "L 867.007932 61.410986 \n",
              "L 874.986053 68.077987 \n",
              "L 882.964173 74.184351 \n",
              "L 890.942293 79.457343 \n",
              "L 898.920413 83.048431 \n",
              "L 906.898533 85.987976 \n",
              "L 914.876654 86.760743 \n",
              "L 922.854774 85.184906 \n",
              "L 930.832894 81.775646 \n",
              "L 938.811014 77.987578 \n",
              "L 946.789134 75.017731 \n",
              "L 954.767254 72.896414 \n",
              "L 962.745375 71.850904 \n",
              "L 970.723495 71.608471 \n",
              "L 978.701615 71.850904 \n",
              "L 986.679735 72.260015 \n",
              "L 994.657855 72.926717 \n",
              "L 1002.635976 74.00253 \n",
              "L 1010.614096 75.684433 \n",
              "L 1018.592216 77.517855 \n",
              "\" clip-path=\"url(#pc9aabe8b1d)\" style=\"fill: none; stroke: #2ca02c; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_17\">\n",
              "    <path d=\"M 77.174034 90.353161 \n",
              "L 85.152154 90.199641 \n",
              "L 93.130274 90.081271 \n",
              "L 101.108395 89.776073 \n",
              "L 109.086515 89.193439 \n",
              "L 117.064635 88.446187 \n",
              "L 125.042755 90.438259 \n",
              "L 133.020875 88.475767 \n",
              "L 140.998996 86.110074 \n",
              "L 148.977116 86.711222 \n",
              "L 156.955236 87.195821 \n",
              "L 164.933356 87.13849 \n",
              "L 172.911476 86.546611 \n",
              "L 180.889596 85.187117 \n",
              "L 188.867717 84.247491 \n",
              "L 196.845837 85.275878 \n",
              "L 204.823957 85.240756 \n",
              "L 212.802077 85.103868 \n",
              "L 220.780197 85.072446 \n",
              "L 228.758318 85.344336 \n",
              "L 236.736438 85.803026 \n",
              "L 244.714558 86.343143 \n",
              "L 252.692678 86.742652 \n",
              "L 260.670798 86.96463 \n",
              "L 268.648919 87.158821 \n",
              "L 276.627039 87.325282 \n",
              "L 284.605159 87.560208 \n",
              "L 292.583279 87.77291 \n",
              "L 300.561399 87.907919 \n",
              "L 308.539519 88.129898 \n",
              "L 316.51764 88.374036 \n",
              "L 324.49576 88.727325 \n",
              "L 332.47388 89.319204 \n",
              "L 340.452 89.744618 \n",
              "L 348.43012 89.888897 \n",
              "L 356.408241 89.931446 \n",
              "L 364.386361 90.001722 \n",
              "L 372.364481 90.149697 \n",
              "L 380.342601 90.260672 \n",
              "L 388.320721 90.323556 \n",
              "L 396.298841 90.460441 \n",
              "L 404.276962 90.667604 \n",
              "L 412.255082 90.900645 \n",
              "L 420.233202 91.118928 \n",
              "L 428.211322 91.401912 \n",
              "L 436.189442 91.738536 \n",
              "L 444.167563 92.147315 \n",
              "L 452.145683 92.395174 \n",
              "L 460.123803 92.300835 \n",
              "L 468.101923 92.319321 \n",
              "L 476.080043 92.56903 \n",
              "L 484.058164 92.681854 \n",
              "L 492.036284 92.654128 \n",
              "L 500.014404 92.615274 \n",
              "L 507.992524 92.37666 \n",
              "L 515.970644 92.060371 \n",
              "L 523.948764 91.782931 \n",
              "L 531.926885 91.485128 \n",
              "L 539.905005 91.309423 \n",
              "L 547.883125 91.165144 \n",
              "L 555.861245 91.020893 \n",
              "L 563.839365 90.935799 \n",
              "L 571.817486 90.780425 \n",
              "L 579.795606 90.628751 \n",
              "L 587.773726 90.519626 \n",
              "L 595.751846 90.569569 \n",
              "L 603.729966 90.665755 \n",
              "L 611.708086 90.60472 \n",
              "L 619.686207 90.427136 \n",
              "L 627.664327 90.134911 \n",
              "L 635.642447 89.705797 \n",
              "L 643.620567 89.221166 \n",
              "L 651.598687 88.755084 \n",
              "L 659.576808 88.375879 \n",
              "L 667.554928 88.046657 \n",
              "L 675.533048 87.767368 \n",
              "L 683.511168 87.573148 \n",
              "L 691.489288 87.515809 \n",
              "L 699.467409 87.452929 \n",
              "L 707.445529 87.330831 \n",
              "L 715.423649 87.15143 \n",
              "L 723.401769 86.931322 \n",
              "L 731.379889 86.631673 \n",
              "L 739.358009 86.306143 \n",
              "L 747.33613 86.000945 \n",
              "L 755.31425 85.815995 \n",
              "L 763.29237 85.693897 \n",
              "L 771.27049 85.621775 \n",
              "L 779.24861 85.627317 \n",
              "L 787.226731 85.581076 \n",
              "L 795.204851 85.603286 \n",
              "L 803.182971 85.629167 \n",
              "L 811.161091 85.697596 \n",
              "L 819.139211 85.943606 \n",
              "L 827.117331 86.435604 \n",
              "L 835.095452 86.886931 \n",
              "L 843.073572 87.177339 \n",
              "L 851.051692 87.465869 \n",
              "L 859.029812 87.69891 \n",
              "L 867.007932 87.85243 \n",
              "L 874.986053 87.993017 \n",
              "L 882.964173 88.129898 \n",
              "L 890.942293 88.131748 \n",
              "L 898.920413 88.031867 \n",
              "L 906.898533 87.952318 \n",
              "L 914.876654 87.876497 \n",
              "L 922.854774 87.833948 \n",
              "L 930.832894 87.885738 \n",
              "L 938.811014 87.911647 \n",
              "L 946.789134 87.935678 \n",
              "L 954.767254 88.055898 \n",
              "L 962.745375 88.187237 \n",
              "L 970.723495 88.296366 \n",
              "L 978.701615 88.477616 \n",
              "L 986.679735 88.688476 \n",
              "L 994.657855 88.853087 \n",
              "L 1002.635976 88.927094 \n",
              "L 1010.614096 88.962244 \n",
              "L 1018.592216 88.969636 \n",
              "\" clip-path=\"url(#pc9aabe8b1d)\" style=\"fill: none; stroke: #d62728; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_18\">\n",
              "    <path d=\"M 77.174034 89.387659 \n",
              "L 85.152154 90.18855 \n",
              "L 93.130274 91.566527 \n",
              "L 101.108395 92.755858 \n",
              "L 109.086515 94.185628 \n",
              "L 117.064635 95.663489 \n",
              "L 125.042755 97.157989 \n",
              "L 133.020875 97.513128 \n",
              "L 140.998996 97.109895 \n",
              "L 148.977116 96.99892 \n",
              "L 156.955236 96.307157 \n",
              "L 164.933356 95.691219 \n",
              "L 172.911476 94.868146 \n",
              "L 180.889596 94.242963 \n",
              "L 188.867717 93.702875 \n",
              "L 196.845837 93.184971 \n",
              "L 204.823957 92.461754 \n",
              "L 212.802077 91.868026 \n",
              "L 220.780197 91.501797 \n",
              "L 228.758318 91.326059 \n",
              "L 236.736438 91.213238 \n",
              "L 244.714558 91.139263 \n",
              "L 252.692678 91.229903 \n",
              "L 260.670798 91.165144 \n",
              "L 268.648919 90.937648 \n",
              "L 276.627039 90.6713 \n",
              "L 284.605159 90.355011 \n",
              "L 292.583279 89.998023 \n",
              "L 300.561399 89.530059 \n",
              "L 308.539519 89.088009 \n",
              "L 316.51764 88.575647 \n",
              "L 324.49576 87.939378 \n",
              "L 332.47388 87.708179 \n",
              "L 340.452 87.728518 \n",
              "L 348.43012 87.782158 \n",
              "L 356.408241 87.883888 \n",
              "L 364.386361 88.059597 \n",
              "L 372.364481 88.257516 \n",
              "L 380.342601 88.390698 \n",
              "L 388.320721 88.449886 \n",
              "L 396.298841 88.462826 \n",
              "L 404.276962 88.392547 \n",
              "L 412.255082 88.146538 \n",
              "L 420.233202 87.819158 \n",
              "L 428.211322 87.436289 \n",
              "L 436.189442 87.16252 \n",
              "L 444.167563 87.055241 \n",
              "L 452.145683 87.060783 \n",
              "L 460.123803 86.98127 \n",
              "L 468.101923 86.827742 \n",
              "L 476.080043 86.661282 \n",
              "L 484.058164 86.520702 \n",
              "L 492.036284 86.411573 \n",
              "L 500.014404 86.322783 \n",
              "L 507.992524 86.272835 \n",
              "L 515.970644 86.337602 \n",
              "L 523.948764 86.472604 \n",
              "L 531.926885 86.666831 \n",
              "L 539.905005 86.890623 \n",
              "L 547.883125 87.07006 \n",
              "L 555.861245 87.273492 \n",
              "L 563.839365 87.464019 \n",
              "L 571.817486 87.636029 \n",
              "L 579.795606 87.784008 \n",
              "L 587.773726 87.889437 \n",
              "L 595.751846 87.896829 \n",
              "L 603.729966 87.819158 \n",
              "L 611.708086 87.771067 \n",
              "L 619.686207 87.808067 \n",
              "L 627.664327 87.911647 \n",
              "L 635.642447 88.126206 \n",
              "L 643.620567 88.438796 \n",
              "L 651.598687 88.890087 \n",
              "L 659.576808 89.411693 \n",
              "L 667.554928 89.922202 \n",
              "L 675.533048 90.375346 \n",
              "L 683.511168 90.771184 \n",
              "L 691.489288 91.080078 \n",
              "L 699.467409 91.329787 \n",
              "L 707.445529 91.557282 \n",
              "L 715.423649 91.821781 \n",
              "L 723.401769 92.11401 \n",
              "L 731.379889 92.391478 \n",
              "L 739.358009 92.58197 \n",
              "L 747.33613 92.705918 \n",
              "L 755.31425 92.829833 \n",
              "L 763.29237 92.953748 \n",
              "L 771.27049 93.096178 \n",
              "L 779.24861 93.231216 \n",
              "L 787.226731 93.310736 \n",
              "L 795.204851 93.242307 \n",
              "L 803.182971 93.042538 \n",
              "L 811.161091 92.661523 \n",
              "L 819.139211 92.186164 \n",
              "L 827.117331 91.607226 \n",
              "L 835.095452 91.054169 \n",
              "L 843.073572 90.56772 \n",
              "L 851.051692 90.07018 \n",
              "L 859.029812 89.592944 \n",
              "L 867.007932 89.15274 \n",
              "L 874.986053 88.799447 \n",
              "L 882.964173 88.614497 \n",
              "L 890.942293 88.551617 \n",
              "L 898.920413 88.679227 \n",
              "L 906.898533 88.899335 \n",
              "L 914.876654 89.16383 \n",
              "L 922.854774 89.483815 \n",
              "L 930.832894 89.737223 \n",
              "L 938.811014 89.874107 \n",
              "L 946.789134 89.896292 \n",
              "L 954.767254 89.816772 \n",
              "L 962.745375 89.666947 \n",
              "L 970.723495 89.494938 \n",
              "L 978.701615 89.330323 \n",
              "L 986.679735 89.191589 \n",
              "L 994.657855 89.091705 \n",
              "L 1002.635976 88.988125 \n",
              "L 1010.614096 88.904877 \n",
              "L 1018.592216 88.864206 \n",
              "\" clip-path=\"url(#pc9aabe8b1d)\" style=\"fill: none; stroke: #9467bd; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_19\">\n",
              "    <path d=\"M 77.174034 91.745928 \n",
              "L 85.152154 91.533222 \n",
              "L 93.130274 91.523978 \n",
              "L 101.108395 91.364912 \n",
              "L 109.086515 90.896949 \n",
              "L 117.064635 90.810034 \n",
              "L 125.042755 90.60472 \n",
              "L 133.020875 85.860394 \n",
              "L 140.998996 82.941643 \n",
              "L 148.977116 80.624041 \n",
              "L 156.955236 78.591269 \n",
              "L 164.933356 77.161503 \n",
              "L 172.911476 76.340283 \n",
              "L 180.889596 76.171937 \n",
              "L 188.867717 76.556684 \n",
              "L 196.845837 77.585071 \n",
              "L 204.823957 78.502508 \n",
              "L 212.802077 79.619685 \n",
              "L 220.780197 80.71838 \n",
              "L 228.758318 81.580299 \n",
              "L 236.736438 82.236936 \n",
              "L 244.714558 82.804755 \n",
              "L 252.692678 83.343023 \n",
              "L 260.670798 83.892352 \n",
              "L 268.648919 84.51199 \n",
              "L 276.627039 85.181568 \n",
              "L 284.605159 85.812303 \n",
              "L 292.583279 86.372723 \n",
              "L 300.561399 86.883232 \n",
              "L 308.539519 87.29386 \n",
              "L 316.51764 87.759969 \n",
              "L 324.49576 88.719927 \n",
              "L 332.47388 90.336525 \n",
              "L 340.452 91.586862 \n",
              "L 348.43012 92.570879 \n",
              "L 356.408241 93.447621 \n",
              "L 364.386361 94.257753 \n",
              "L 372.364481 94.973576 \n",
              "L 380.342601 95.600608 \n",
              "L 388.320721 96.125907 \n",
              "L 396.298841 96.610506 \n",
              "L 404.276962 97.047014 \n",
              "L 412.255082 97.468729 \n",
              "L 420.233202 97.842357 \n",
              "L 428.211322 98.180856 \n",
              "L 436.189442 98.515631 \n",
              "L 444.167563 98.722794 \n",
              "L 452.145683 98.709854 \n",
              "L 460.123803 98.523026 \n",
              "L 468.101923 98.265922 \n",
              "L 476.080043 97.955178 \n",
              "L 484.058164 97.526068 \n",
              "L 492.036284 97.010011 \n",
              "L 500.014404 96.490286 \n",
              "L 507.992524 95.937229 \n",
              "L 515.970644 95.350899 \n",
              "L 523.948764 94.757171 \n",
              "L 531.926885 94.141229 \n",
              "L 539.905005 93.530837 \n",
              "L 547.883125 92.933413 \n",
              "L 555.861245 92.36187 \n",
              "L 563.839365 91.82548 \n",
              "L 571.817486 91.305727 \n",
              "L 579.795606 90.80076 \n",
              "L 587.773726 90.342071 \n",
              "L 595.751846 89.998023 \n",
              "L 603.729966 89.768678 \n",
              "L 611.708086 89.648462 \n",
              "L 619.686207 89.596672 \n",
              "L 627.664327 89.520818 \n",
              "L 635.642447 89.411693 \n",
              "L 643.620567 89.21747 \n",
              "L 651.598687 88.916003 \n",
              "L 659.576808 88.466526 \n",
              "L 667.554928 87.95786 \n",
              "L 675.533048 87.390048 \n",
              "L 683.511168 86.801833 \n",
              "L 691.489288 86.261744 \n",
              "L 699.467409 85.788236 \n",
              "L 707.445529 85.388735 \n",
              "L 715.423649 85.013228 \n",
              "L 723.401769 84.63036 \n",
              "L 731.379889 84.241949 \n",
              "L 739.358009 83.847961 \n",
              "L 747.33613 83.474333 \n",
              "L 755.31425 83.132164 \n",
              "L 763.29237 82.814025 \n",
              "L 771.27049 82.555075 \n",
              "L 779.24861 82.375645 \n",
              "L 787.226731 82.248027 \n",
              "L 795.204851 82.166636 \n",
              "L 803.182971 82.116688 \n",
              "L 811.161091 82.085266 \n",
              "L 819.139211 82.138905 \n",
              "L 827.117331 82.364555 \n",
              "L 835.095452 82.760393 \n",
              "L 843.073572 83.274564 \n",
              "L 851.051692 83.933052 \n",
              "L 859.029812 84.64515 \n",
              "L 867.007932 85.342487 \n",
              "L 874.986053 86.049036 \n",
              "L 882.964173 86.755621 \n",
              "L 890.942293 87.386349 \n",
              "L 898.920413 87.941227 \n",
              "L 906.898533 88.416578 \n",
              "L 914.876654 88.836454 \n",
              "L 922.854774 89.174953 \n",
              "L 930.832894 89.461634 \n",
              "L 938.811014 89.665098 \n",
              "L 946.789134 89.794558 \n",
              "L 954.767254 89.868562 \n",
              "L 962.745375 89.857472 \n",
              "L 970.723495 89.752042 \n",
              "L 978.701615 89.628098 \n",
              "L 986.679735 89.546728 \n",
              "L 994.657855 89.507878 \n",
              "L 1002.635976 89.483815 \n",
              "L 1010.614096 89.463483 \n",
              "L 1018.592216 89.437603 \n",
              "\" clip-path=\"url(#pc9aabe8b1d)\" style=\"fill: none; stroke: #8c564b; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_3\">\n",
              "    <path d=\"M 30.103125 155.658125 \n",
              "L 30.103125 22.318125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_4\">\n",
              "    <path d=\"M 1065.663125 155.658125 \n",
              "L 1065.663125 22.318125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_5\">\n",
              "    <path d=\"M 30.103125 155.658125 \n",
              "L 1065.663125 155.658125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_6\">\n",
              "    <path d=\"M 30.103125 22.318125 \n",
              "L 1065.663125 22.318125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"text_14\">\n",
              "    <!-- Sample 83 Class:['AvadaKedavra'] -->\n",
              "    <g transform=\"translate(445.177187 16.318125) scale(0.12 -0.12)\">\n",
              "     <defs>\n",
              "      <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \n",
              "L 3425 3897 \n",
              "Q 3066 4069 2747 4153 \n",
              "Q 2428 4238 2131 4238 \n",
              "Q 1616 4238 1336 4038 \n",
              "Q 1056 3838 1056 3469 \n",
              "Q 1056 3159 1242 3001 \n",
              "Q 1428 2844 1947 2747 \n",
              "L 2328 2669 \n",
              "Q 3034 2534 3370 2195 \n",
              "Q 3706 1856 3706 1288 \n",
              "Q 3706 609 3251 259 \n",
              "Q 2797 -91 1919 -91 \n",
              "Q 1588 -91 1214 -16 \n",
              "Q 841 59 441 206 \n",
              "L 441 856 \n",
              "Q 825 641 1194 531 \n",
              "Q 1563 422 1919 422 \n",
              "Q 2459 422 2753 634 \n",
              "Q 3047 847 3047 1241 \n",
              "Q 3047 1584 2836 1778 \n",
              "Q 2625 1972 2144 2069 \n",
              "L 1759 2144 \n",
              "Q 1053 2284 737 2584 \n",
              "Q 422 2884 422 3419 \n",
              "Q 422 4038 858 4394 \n",
              "Q 1294 4750 2059 4750 \n",
              "Q 2388 4750 2728 4690 \n",
              "Q 3069 4631 3425 4513 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
              "Q 1497 1759 1228 1600 \n",
              "Q 959 1441 959 1056 \n",
              "Q 959 750 1161 570 \n",
              "Q 1363 391 1709 391 \n",
              "Q 2188 391 2477 730 \n",
              "Q 2766 1069 2766 1631 \n",
              "L 2766 1759 \n",
              "L 2194 1759 \n",
              "z\n",
              "M 3341 1997 \n",
              "L 3341 0 \n",
              "L 2766 0 \n",
              "L 2766 531 \n",
              "Q 2569 213 2275 61 \n",
              "Q 1981 -91 1556 -91 \n",
              "Q 1019 -91 701 211 \n",
              "Q 384 513 384 1019 \n",
              "Q 384 1609 779 1909 \n",
              "Q 1175 2209 1959 2209 \n",
              "L 2766 2209 \n",
              "L 2766 2266 \n",
              "Q 2766 2663 2505 2880 \n",
              "Q 2244 3097 1772 3097 \n",
              "Q 1472 3097 1187 3025 \n",
              "Q 903 2953 641 2809 \n",
              "L 641 3341 \n",
              "Q 956 3463 1253 3523 \n",
              "Q 1550 3584 1831 3584 \n",
              "Q 2591 3584 2966 3190 \n",
              "Q 3341 2797 3341 1997 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n",
              "Q 3544 3216 3844 3400 \n",
              "Q 4144 3584 4550 3584 \n",
              "Q 5097 3584 5394 3201 \n",
              "Q 5691 2819 5691 2113 \n",
              "L 5691 0 \n",
              "L 5113 0 \n",
              "L 5113 2094 \n",
              "Q 5113 2597 4934 2840 \n",
              "Q 4756 3084 4391 3084 \n",
              "Q 3944 3084 3684 2787 \n",
              "Q 3425 2491 3425 1978 \n",
              "L 3425 0 \n",
              "L 2847 0 \n",
              "L 2847 2094 \n",
              "Q 2847 2600 2669 2842 \n",
              "Q 2491 3084 2119 3084 \n",
              "Q 1678 3084 1418 2786 \n",
              "Q 1159 2488 1159 1978 \n",
              "L 1159 0 \n",
              "L 581 0 \n",
              "L 581 3500 \n",
              "L 1159 3500 \n",
              "L 1159 2956 \n",
              "Q 1356 3278 1631 3431 \n",
              "Q 1906 3584 2284 3584 \n",
              "Q 2666 3584 2933 3390 \n",
              "Q 3200 3197 3328 2828 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
              "L 1159 -1331 \n",
              "L 581 -1331 \n",
              "L 581 3500 \n",
              "L 1159 3500 \n",
              "L 1159 2969 \n",
              "Q 1341 3281 1617 3432 \n",
              "Q 1894 3584 2278 3584 \n",
              "Q 2916 3584 3314 3078 \n",
              "Q 3713 2572 3713 1747 \n",
              "Q 3713 922 3314 415 \n",
              "Q 2916 -91 2278 -91 \n",
              "Q 1894 -91 1617 61 \n",
              "Q 1341 213 1159 525 \n",
              "z\n",
              "M 3116 1747 \n",
              "Q 3116 2381 2855 2742 \n",
              "Q 2594 3103 2138 3103 \n",
              "Q 1681 3103 1420 2742 \n",
              "Q 1159 2381 1159 1747 \n",
              "Q 1159 1113 1420 752 \n",
              "Q 1681 391 2138 391 \n",
              "Q 2594 391 2855 752 \n",
              "Q 3116 1113 3116 1747 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
              "L 1178 4863 \n",
              "L 1178 0 \n",
              "L 603 0 \n",
              "L 603 4863 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
              "L 3597 1613 \n",
              "L 953 1613 \n",
              "Q 991 1019 1311 708 \n",
              "Q 1631 397 2203 397 \n",
              "Q 2534 397 2845 478 \n",
              "Q 3156 559 3463 722 \n",
              "L 3463 178 \n",
              "Q 3153 47 2828 -22 \n",
              "Q 2503 -91 2169 -91 \n",
              "Q 1331 -91 842 396 \n",
              "Q 353 884 353 1716 \n",
              "Q 353 2575 817 3079 \n",
              "Q 1281 3584 2069 3584 \n",
              "Q 2775 3584 3186 3129 \n",
              "Q 3597 2675 3597 1894 \n",
              "z\n",
              "M 3022 2063 \n",
              "Q 3016 2534 2758 2815 \n",
              "Q 2500 3097 2075 3097 \n",
              "Q 1594 3097 1305 2825 \n",
              "Q 1016 2553 972 2059 \n",
              "L 3022 2063 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
              "Q 3050 2419 3304 2112 \n",
              "Q 3559 1806 3559 1356 \n",
              "Q 3559 666 3084 287 \n",
              "Q 2609 -91 1734 -91 \n",
              "Q 1441 -91 1130 -33 \n",
              "Q 819 25 488 141 \n",
              "L 488 750 \n",
              "Q 750 597 1062 519 \n",
              "Q 1375 441 1716 441 \n",
              "Q 2309 441 2620 675 \n",
              "Q 2931 909 2931 1356 \n",
              "Q 2931 1769 2642 2001 \n",
              "Q 2353 2234 1838 2234 \n",
              "L 1294 2234 \n",
              "L 1294 2753 \n",
              "L 1863 2753 \n",
              "Q 2328 2753 2575 2939 \n",
              "Q 2822 3125 2822 3475 \n",
              "Q 2822 3834 2567 4026 \n",
              "Q 2313 4219 1838 4219 \n",
              "Q 1578 4219 1281 4162 \n",
              "Q 984 4106 628 3988 \n",
              "L 628 4550 \n",
              "Q 988 4650 1302 4700 \n",
              "Q 1616 4750 1894 4750 \n",
              "Q 2613 4750 3031 4423 \n",
              "Q 3450 4097 3450 3541 \n",
              "Q 3450 3153 3228 2886 \n",
              "Q 3006 2619 2597 2516 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \n",
              "L 4122 3641 \n",
              "Q 3803 3938 3442 4084 \n",
              "Q 3081 4231 2675 4231 \n",
              "Q 1875 4231 1450 3742 \n",
              "Q 1025 3253 1025 2328 \n",
              "Q 1025 1406 1450 917 \n",
              "Q 1875 428 2675 428 \n",
              "Q 3081 428 3442 575 \n",
              "Q 3803 722 4122 1019 \n",
              "L 4122 359 \n",
              "Q 3791 134 3420 21 \n",
              "Q 3050 -91 2638 -91 \n",
              "Q 1578 -91 968 557 \n",
              "Q 359 1206 359 2328 \n",
              "Q 359 3453 968 4101 \n",
              "Q 1578 4750 2638 4750 \n",
              "Q 3056 4750 3426 4639 \n",
              "Q 3797 4528 4122 4306 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
              "L 2834 2853 \n",
              "Q 2591 2978 2328 3040 \n",
              "Q 2066 3103 1784 3103 \n",
              "Q 1356 3103 1142 2972 \n",
              "Q 928 2841 928 2578 \n",
              "Q 928 2378 1081 2264 \n",
              "Q 1234 2150 1697 2047 \n",
              "L 1894 2003 \n",
              "Q 2506 1872 2764 1633 \n",
              "Q 3022 1394 3022 966 \n",
              "Q 3022 478 2636 193 \n",
              "Q 2250 -91 1575 -91 \n",
              "Q 1294 -91 989 -36 \n",
              "Q 684 19 347 128 \n",
              "L 347 722 \n",
              "Q 666 556 975 473 \n",
              "Q 1284 391 1588 391 \n",
              "Q 1994 391 2212 530 \n",
              "Q 2431 669 2431 922 \n",
              "Q 2431 1156 2273 1281 \n",
              "Q 2116 1406 1581 1522 \n",
              "L 1381 1569 \n",
              "Q 847 1681 609 1914 \n",
              "Q 372 2147 372 2553 \n",
              "Q 372 3047 722 3315 \n",
              "Q 1072 3584 1716 3584 \n",
              "Q 2034 3584 2315 3537 \n",
              "Q 2597 3491 2834 3397 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-3a\" d=\"M 750 794 \n",
              "L 1409 794 \n",
              "L 1409 0 \n",
              "L 750 0 \n",
              "L 750 794 \n",
              "z\n",
              "M 750 3309 \n",
              "L 1409 3309 \n",
              "L 1409 2516 \n",
              "L 750 2516 \n",
              "L 750 3309 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-5b\" d=\"M 550 4863 \n",
              "L 1875 4863 \n",
              "L 1875 4416 \n",
              "L 1125 4416 \n",
              "L 1125 -397 \n",
              "L 1875 -397 \n",
              "L 1875 -844 \n",
              "L 550 -844 \n",
              "L 550 4863 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-27\" d=\"M 1147 4666 \n",
              "L 1147 2931 \n",
              "L 616 2931 \n",
              "L 616 4666 \n",
              "L 1147 4666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-41\" d=\"M 2188 4044 \n",
              "L 1331 1722 \n",
              "L 3047 1722 \n",
              "L 2188 4044 \n",
              "z\n",
              "M 1831 4666 \n",
              "L 2547 4666 \n",
              "L 4325 0 \n",
              "L 3669 0 \n",
              "L 3244 1197 \n",
              "L 1141 1197 \n",
              "L 716 0 \n",
              "L 50 0 \n",
              "L 1831 4666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-76\" d=\"M 191 3500 \n",
              "L 800 3500 \n",
              "L 1894 563 \n",
              "L 2988 3500 \n",
              "L 3597 3500 \n",
              "L 2284 0 \n",
              "L 1503 0 \n",
              "L 191 3500 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \n",
              "L 2906 4863 \n",
              "L 3481 4863 \n",
              "L 3481 0 \n",
              "L 2906 0 \n",
              "L 2906 525 \n",
              "Q 2725 213 2448 61 \n",
              "Q 2172 -91 1784 -91 \n",
              "Q 1150 -91 751 415 \n",
              "Q 353 922 353 1747 \n",
              "Q 353 2572 751 3078 \n",
              "Q 1150 3584 1784 3584 \n",
              "Q 2172 3584 2448 3432 \n",
              "Q 2725 3281 2906 2969 \n",
              "z\n",
              "M 947 1747 \n",
              "Q 947 1113 1208 752 \n",
              "Q 1469 391 1925 391 \n",
              "Q 2381 391 2643 752 \n",
              "Q 2906 1113 2906 1747 \n",
              "Q 2906 2381 2643 2742 \n",
              "Q 2381 3103 1925 3103 \n",
              "Q 1469 3103 1208 2742 \n",
              "Q 947 2381 947 1747 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-4b\" d=\"M 628 4666 \n",
              "L 1259 4666 \n",
              "L 1259 2694 \n",
              "L 3353 4666 \n",
              "L 4166 4666 \n",
              "L 1850 2491 \n",
              "L 4331 0 \n",
              "L 3500 0 \n",
              "L 1259 2247 \n",
              "L 1259 0 \n",
              "L 628 0 \n",
              "L 628 4666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
              "Q 2534 3019 2420 3045 \n",
              "Q 2306 3072 2169 3072 \n",
              "Q 1681 3072 1420 2755 \n",
              "Q 1159 2438 1159 1844 \n",
              "L 1159 0 \n",
              "L 581 0 \n",
              "L 581 3500 \n",
              "L 1159 3500 \n",
              "L 1159 2956 \n",
              "Q 1341 3275 1631 3429 \n",
              "Q 1922 3584 2338 3584 \n",
              "Q 2397 3584 2469 3576 \n",
              "Q 2541 3569 2628 3553 \n",
              "L 2631 2963 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-5d\" d=\"M 1947 4863 \n",
              "L 1947 -844 \n",
              "L 622 -844 \n",
              "L 622 -397 \n",
              "L 1369 -397 \n",
              "L 1369 4416 \n",
              "L 622 4416 \n",
              "L 622 4863 \n",
              "L 1947 4863 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "     </defs>\n",
              "     <use xlink:href=\"#DejaVuSans-53\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"63.476562\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6d\" x=\"124.755859\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-70\" x=\"222.167969\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6c\" x=\"285.644531\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-65\" x=\"313.427734\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-20\" x=\"374.951172\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-38\" x=\"406.738281\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-33\" x=\"470.361328\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-20\" x=\"533.984375\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-43\" x=\"565.771484\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6c\" x=\"635.595703\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"663.378906\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-73\" x=\"724.658203\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-73\" x=\"776.757812\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-3a\" x=\"828.857422\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-5b\" x=\"862.548828\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-27\" x=\"901.5625\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-41\" x=\"929.052734\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-76\" x=\"991.585938\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"1050.765625\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-64\" x=\"1112.044922\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"1175.521484\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-4b\" x=\"1236.800781\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-65\" x=\"1297.376953\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-64\" x=\"1358.900391\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"1422.376953\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-76\" x=\"1483.65625\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-72\" x=\"1542.835938\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"1583.949219\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-27\" x=\"1645.228516\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-5d\" x=\"1672.71875\"/>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"legend_1\">\n",
              "    <g id=\"patch_7\">\n",
              "     <path d=\"M 37.103125 118.386875 \n",
              "L 114.742188 118.386875 \n",
              "Q 116.742188 118.386875 116.742188 116.386875 \n",
              "L 116.742188 29.318125 \n",
              "Q 116.742188 27.318125 114.742188 27.318125 \n",
              "L 37.103125 27.318125 \n",
              "Q 35.103125 27.318125 35.103125 29.318125 \n",
              "L 35.103125 116.386875 \n",
              "Q 35.103125 118.386875 37.103125 118.386875 \n",
              "z\n",
              "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
              "    </g>\n",
              "    <g id=\"line2d_20\">\n",
              "     <path d=\"M 39.103125 35.416563 \n",
              "L 49.103125 35.416563 \n",
              "L 59.103125 35.416563 \n",
              "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_15\">\n",
              "     <!-- feature 1 -->\n",
              "     <g transform=\"translate(67.103125 38.916563) scale(0.1 -0.1)\">\n",
              "      <defs>\n",
              "       <path id=\"DejaVuSans-66\" d=\"M 2375 4863 \n",
              "L 2375 4384 \n",
              "L 1825 4384 \n",
              "Q 1516 4384 1395 4259 \n",
              "Q 1275 4134 1275 3809 \n",
              "L 1275 3500 \n",
              "L 2222 3500 \n",
              "L 2222 3053 \n",
              "L 1275 3053 \n",
              "L 1275 0 \n",
              "L 697 0 \n",
              "L 697 3053 \n",
              "L 147 3053 \n",
              "L 147 3500 \n",
              "L 697 3500 \n",
              "L 697 3744 \n",
              "Q 697 4328 969 4595 \n",
              "Q 1241 4863 1831 4863 \n",
              "L 2375 4863 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
              "L 1172 3500 \n",
              "L 2356 3500 \n",
              "L 2356 3053 \n",
              "L 1172 3053 \n",
              "L 1172 1153 \n",
              "Q 1172 725 1289 603 \n",
              "Q 1406 481 1766 481 \n",
              "L 2356 481 \n",
              "L 2356 0 \n",
              "L 1766 0 \n",
              "Q 1100 0 847 248 \n",
              "Q 594 497 594 1153 \n",
              "L 594 3053 \n",
              "L 172 3053 \n",
              "L 172 3500 \n",
              "L 594 3500 \n",
              "L 594 4494 \n",
              "L 1172 4494 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \n",
              "L 544 3500 \n",
              "L 1119 3500 \n",
              "L 1119 1403 \n",
              "Q 1119 906 1312 657 \n",
              "Q 1506 409 1894 409 \n",
              "Q 2359 409 2629 706 \n",
              "Q 2900 1003 2900 1516 \n",
              "L 2900 3500 \n",
              "L 3475 3500 \n",
              "L 3475 0 \n",
              "L 2900 0 \n",
              "L 2900 538 \n",
              "Q 2691 219 2414 64 \n",
              "Q 2138 -91 1772 -91 \n",
              "Q 1169 -91 856 284 \n",
              "Q 544 659 544 1381 \n",
              "z\n",
              "M 1991 3584 \n",
              "L 1991 3584 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      </defs>\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-31\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_21\">\n",
              "     <path d=\"M 39.103125 50.094688 \n",
              "L 49.103125 50.094688 \n",
              "L 59.103125 50.094688 \n",
              "\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_16\">\n",
              "     <!-- feature 2 -->\n",
              "     <g transform=\"translate(67.103125 53.594688) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-32\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_22\">\n",
              "     <path d=\"M 39.103125 64.772813 \n",
              "L 49.103125 64.772813 \n",
              "L 59.103125 64.772813 \n",
              "\" style=\"fill: none; stroke: #2ca02c; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_17\">\n",
              "     <!-- feature 3 -->\n",
              "     <g transform=\"translate(67.103125 68.272813) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-33\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_23\">\n",
              "     <path d=\"M 39.103125 79.450938 \n",
              "L 49.103125 79.450938 \n",
              "L 59.103125 79.450938 \n",
              "\" style=\"fill: none; stroke: #d62728; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_18\">\n",
              "     <!-- feature 4 -->\n",
              "     <g transform=\"translate(67.103125 82.950938) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-34\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_24\">\n",
              "     <path d=\"M 39.103125 94.129063 \n",
              "L 49.103125 94.129063 \n",
              "L 59.103125 94.129063 \n",
              "\" style=\"fill: none; stroke: #9467bd; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_19\">\n",
              "     <!-- feature 5 -->\n",
              "     <g transform=\"translate(67.103125 97.629063) scale(0.1 -0.1)\">\n",
              "      <defs>\n",
              "       <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
              "L 3169 4666 \n",
              "L 3169 4134 \n",
              "L 1269 4134 \n",
              "L 1269 2991 \n",
              "Q 1406 3038 1543 3061 \n",
              "Q 1681 3084 1819 3084 \n",
              "Q 2600 3084 3056 2656 \n",
              "Q 3513 2228 3513 1497 \n",
              "Q 3513 744 3044 326 \n",
              "Q 2575 -91 1722 -91 \n",
              "Q 1428 -91 1123 -41 \n",
              "Q 819 9 494 109 \n",
              "L 494 744 \n",
              "Q 775 591 1075 516 \n",
              "Q 1375 441 1709 441 \n",
              "Q 2250 441 2565 725 \n",
              "Q 2881 1009 2881 1497 \n",
              "Q 2881 1984 2565 2268 \n",
              "Q 2250 2553 1709 2553 \n",
              "Q 1456 2553 1204 2497 \n",
              "Q 953 2441 691 2322 \n",
              "L 691 4666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      </defs>\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-35\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_25\">\n",
              "     <path d=\"M 39.103125 108.807188 \n",
              "L 49.103125 108.807188 \n",
              "L 59.103125 108.807188 \n",
              "\" style=\"fill: none; stroke: #8c564b; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_20\">\n",
              "     <!-- feature 6 -->\n",
              "     <g transform=\"translate(67.103125 112.307188) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-36\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "  </g>\n",
              "  <g id=\"axes_2\">\n",
              "   <g id=\"patch_8\">\n",
              "    <path d=\"M 30.103125 332.958125 \n",
              "L 1065.663125 332.958125 \n",
              "L 1065.663125 199.618125 \n",
              "L 30.103125 199.618125 \n",
              "z\n",
              "\" style=\"fill: #ffffff\"/>\n",
              "   </g>\n",
              "   <g id=\"matplotlib.axis_3\">\n",
              "    <g id=\"xtick_8\">\n",
              "     <g id=\"line2d_26\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"77.174034\" y=\"332.958125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_21\">\n",
              "      <!-- 0 -->\n",
              "      <g transform=\"translate(73.992784 347.556562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_9\">\n",
              "     <g id=\"line2d_27\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"236.736438\" y=\"332.958125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_22\">\n",
              "      <!-- 20 -->\n",
              "      <g transform=\"translate(230.373938 347.556562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_10\">\n",
              "     <g id=\"line2d_28\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"396.298841\" y=\"332.958125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_23\">\n",
              "      <!-- 40 -->\n",
              "      <g transform=\"translate(389.936341 347.556562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_11\">\n",
              "     <g id=\"line2d_29\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"555.861245\" y=\"332.958125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_24\">\n",
              "      <!-- 60 -->\n",
              "      <g transform=\"translate(549.498745 347.556562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_12\">\n",
              "     <g id=\"line2d_30\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"715.423649\" y=\"332.958125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_25\">\n",
              "      <!-- 80 -->\n",
              "      <g transform=\"translate(709.061149 347.556562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_13\">\n",
              "     <g id=\"line2d_31\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"874.986053\" y=\"332.958125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_26\">\n",
              "      <!-- 100 -->\n",
              "      <g transform=\"translate(865.442303 347.556562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_14\">\n",
              "     <g id=\"line2d_32\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"1034.548456\" y=\"332.958125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_27\">\n",
              "      <!-- 120 -->\n",
              "      <g transform=\"translate(1025.004706 347.556562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"matplotlib.axis_4\">\n",
              "    <g id=\"ytick_7\">\n",
              "     <g id=\"line2d_33\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"326.897216\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_28\">\n",
              "      <!-- 0.0 -->\n",
              "      <g transform=\"translate(7.2 330.696435) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_8\">\n",
              "     <g id=\"line2d_34\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"302.65358\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_29\">\n",
              "      <!-- 0.2 -->\n",
              "      <g transform=\"translate(7.2 306.452798) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_9\">\n",
              "     <g id=\"line2d_35\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"278.409943\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_30\">\n",
              "      <!-- 0.4 -->\n",
              "      <g transform=\"translate(7.2 282.209162) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_10\">\n",
              "     <g id=\"line2d_36\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"254.166307\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_31\">\n",
              "      <!-- 0.6 -->\n",
              "      <g transform=\"translate(7.2 257.965526) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_11\">\n",
              "     <g id=\"line2d_37\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"229.92267\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_32\">\n",
              "      <!-- 0.8 -->\n",
              "      <g transform=\"translate(7.2 233.721889) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_12\">\n",
              "     <g id=\"line2d_38\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"205.679034\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_33\">\n",
              "      <!-- 1.0 -->\n",
              "      <g transform=\"translate(7.2 209.478253) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"line2d_39\">\n",
              "    <path d=\"M 77.174034 266.560864 \n",
              "L 85.152154 268.136702 \n",
              "L 93.130274 270.651981 \n",
              "L 101.108395 274.273372 \n",
              "L 109.086515 280.682785 \n",
              "L 117.064635 286.864912 \n",
              "L 125.042755 294.562265 \n",
              "L 133.020875 302.380838 \n",
              "L 140.998996 308.472053 \n",
              "L 148.977116 313.714739 \n",
              "L 156.955236 317.124 \n",
              "L 164.933356 318.154354 \n",
              "L 172.911476 317.881613 \n",
              "L 180.889596 315.7906 \n",
              "L 188.867717 313.078343 \n",
              "L 196.845837 309.032686 \n",
              "L 204.823957 304.487005 \n",
              "L 212.802077 298.213964 \n",
              "L 220.780197 291.607573 \n",
              "L 228.758318 283.955673 \n",
              "L 236.736438 277.303827 \n",
              "L 244.714558 271.000483 \n",
              "L 252.692678 267.636677 \n",
              "L 260.670798 264.015283 \n",
              "L 268.648919 262.303077 \n",
              "L 276.627039 261.878815 \n",
              "L 284.605159 261.77275 \n",
              "L 292.583279 261.560619 \n",
              "L 300.561399 261.227264 \n",
              "L 308.539519 260.787851 \n",
              "L 316.51764 260.560569 \n",
              "L 324.49576 260.363589 \n",
              "L 332.47388 262.197012 \n",
              "L 340.452 263.833454 \n",
              "L 348.43012 265.818402 \n",
              "L 356.408241 268.136702 \n",
              "L 364.386361 270.894414 \n",
              "L 372.364481 273.773347 \n",
              "L 380.342601 276.606823 \n",
              "L 388.320721 278.98573 \n",
              "L 396.298841 281.440398 \n",
              "L 404.276962 283.985979 \n",
              "L 412.255082 286.425495 \n",
              "L 420.233202 288.501358 \n",
              "L 428.211322 290.395392 \n",
              "L 436.189442 291.85001 \n",
              "L 444.167563 292.925819 \n",
              "L 452.145683 293.986481 \n",
              "L 460.123803 294.744093 \n",
              "L 468.101923 295.38049 \n",
              "L 476.080043 295.395641 \n",
              "L 484.058164 294.98653 \n",
              "L 492.036284 293.350084 \n",
              "L 500.014404 291.001482 \n",
              "L 507.992524 288.395293 \n",
              "L 515.970644 284.879964 \n",
              "L 523.948764 280.773699 \n",
              "L 531.926885 277.819003 \n",
              "L 539.905005 273.455151 \n",
              "L 547.883125 271.439896 \n",
              "L 555.861245 270.500459 \n",
              "L 563.839365 270.288324 \n",
              "L 571.817486 270.697435 \n",
              "L 579.795606 270.970178 \n",
              "L 587.773726 271.182308 \n",
              "L 595.751846 271.773248 \n",
              "L 603.729966 272.773297 \n",
              "L 611.708086 274.227915 \n",
              "L 619.686207 276.076492 \n",
              "L 627.664327 278.4554 \n",
              "L 635.642447 281.561614 \n",
              "L 643.620567 285.364837 \n",
              "L 651.598687 289.258971 \n",
              "L 659.576808 293.304627 \n",
              "L 667.554928 297.138152 \n",
              "L 675.533048 300.017083 \n",
              "L 683.511168 301.986879 \n",
              "L 691.489288 300.380739 \n",
              "L 699.467409 299.698887 \n",
              "L 707.445529 295.456249 \n",
              "L 715.423649 290.774197 \n",
              "L 723.401769 285.076943 \n",
              "L 731.379889 278.591771 \n",
              "L 739.358009 271.606574 \n",
              "L 747.33613 266.939672 \n",
              "L 755.31425 263.727389 \n",
              "L 763.29237 261.348481 \n",
              "L 771.27049 259.378691 \n",
              "L 779.24861 258.318029 \n",
              "L 787.226731 257.757392 \n",
              "L 795.204851 257.363433 \n",
              "L 803.182971 258.227115 \n",
              "L 811.161091 259.151402 \n",
              "L 819.139211 260.348431 \n",
              "L 827.117331 261.454554 \n",
              "L 835.095452 262.060644 \n",
              "L 843.073572 262.863714 \n",
              "L 851.051692 263.515258 \n",
              "L 859.029812 263.894066 \n",
              "L 867.007932 263.894066 \n",
              "L 874.986053 263.515258 \n",
              "L 882.964173 263.439495 \n",
              "L 890.942293 263.424343 \n",
              "L 898.920413 263.242515 \n",
              "L 906.898533 263.090996 \n",
              "L 914.876654 262.93947 \n",
              "L 922.854774 262.7728 \n",
              "L 930.832894 262.636425 \n",
              "L 938.811014 262.560669 \n",
              "L 946.789134 262.363689 \n",
              "L 954.767254 262.318228 \n",
              "L 962.745375 262.287926 \n",
              "L 970.723495 262.287926 \n",
              "L 978.701615 262.348531 \n",
              "L 986.679735 262.484906 \n",
              "L 994.657855 262.439445 \n",
              "L 1002.635976 262.409143 \n",
              "L 1010.614096 262.257624 \n",
              "L 1018.592216 262.18186 \n",
              "\" clip-path=\"url(#p56f081b087)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_40\">\n",
              "    <path d=\"M 77.174034 312.881363 \n",
              "L 85.152154 325.806252 \n",
              "L 93.130274 326.897216 \n",
              "L 101.108395 326.897216 \n",
              "L 109.086515 326.897216 \n",
              "L 117.064635 326.897216 \n",
              "L 125.042755 326.897216 \n",
              "L 133.020875 326.897216 \n",
              "L 140.998996 320.063541 \n",
              "L 148.977116 306.229516 \n",
              "L 156.955236 293.001582 \n",
              "L 164.933356 281.031287 \n",
              "L 172.911476 268.19731 \n",
              "L 180.889596 258.424095 \n",
              "L 188.867717 247.756895 \n",
              "L 196.845837 238.559467 \n",
              "L 204.823957 228.36199 \n",
              "L 212.802077 218.028137 \n",
              "L 220.780197 207.845811 \n",
              "L 228.758318 205.679034 \n",
              "L 236.736438 205.679034 \n",
              "L 244.714558 205.679034 \n",
              "L 252.692678 205.679034 \n",
              "L 260.670798 205.679034 \n",
              "L 268.648919 205.679034 \n",
              "L 276.627039 208.891314 \n",
              "L 284.605159 214.346134 \n",
              "L 292.583279 214.603726 \n",
              "L 300.561399 210.876263 \n",
              "L 308.539519 205.876014 \n",
              "L 316.51764 205.679034 \n",
              "L 324.49576 205.679034 \n",
              "L 332.47388 205.679034 \n",
              "L 340.452 205.679034 \n",
              "L 348.43012 205.679034 \n",
              "L 356.408241 205.679034 \n",
              "L 364.386361 205.679034 \n",
              "L 372.364481 210.633829 \n",
              "L 380.342601 216.679582 \n",
              "L 388.320721 221.543463 \n",
              "L 396.298841 224.755743 \n",
              "L 404.276962 227.604373 \n",
              "L 412.255082 231.922769 \n",
              "L 420.233202 236.892715 \n",
              "L 428.211322 241.695984 \n",
              "L 436.189442 246.438649 \n",
              "L 444.167563 251.514661 \n",
              "L 452.145683 256.454297 \n",
              "L 460.123803 261.287876 \n",
              "L 468.101923 268.106396 \n",
              "L 476.080043 276.076492 \n",
              "L 484.058164 285.1224 \n",
              "L 492.036284 295.319878 \n",
              "L 500.014404 306.532562 \n",
              "L 507.992524 318.214963 \n",
              "L 515.970644 326.897216 \n",
              "L 523.948764 326.897216 \n",
              "L 531.926885 326.897216 \n",
              "L 539.905005 326.897216 \n",
              "L 547.883125 326.897216 \n",
              "L 555.861245 326.897216 \n",
              "L 563.839365 321.730291 \n",
              "L 571.817486 310.441848 \n",
              "L 579.795606 301.350484 \n",
              "L 587.773726 295.410792 \n",
              "L 595.751846 292.622774 \n",
              "L 603.729966 294.213763 \n",
              "L 611.708086 298.956425 \n",
              "L 619.686207 304.805203 \n",
              "L 627.664327 309.108447 \n",
              "L 635.642447 311.002481 \n",
              "L 643.620567 310.229716 \n",
              "L 651.598687 307.123501 \n",
              "L 659.576808 301.562615 \n",
              "L 667.554928 293.728893 \n",
              "L 675.533048 284.682984 \n",
              "L 683.511168 273.364236 \n",
              "L 691.489288 261.636375 \n",
              "L 699.467409 249.10545 \n",
              "L 707.445529 235.953277 \n",
              "L 715.423649 224.104199 \n",
              "L 723.401769 213.967326 \n",
              "L 731.379889 205.951777 \n",
              "L 739.358009 205.679034 \n",
              "L 747.33613 205.694185 \n",
              "L 755.31425 207.588219 \n",
              "L 763.29237 208.43675 \n",
              "L 771.27049 207.891265 \n",
              "L 779.24861 206.99728 \n",
              "L 787.226731 206.527565 \n",
              "L 795.204851 209.60347 \n",
              "L 803.182971 215.724993 \n",
              "L 811.161091 220.846458 \n",
              "L 819.139211 226.96798 \n",
              "L 827.117331 235.968428 \n",
              "L 835.095452 245.65073 \n",
              "L 843.073572 254.12085 \n",
              "L 851.051692 260.439345 \n",
              "L 859.029812 266.075994 \n",
              "L 867.007932 270.561067 \n",
              "L 874.986053 272.833906 \n",
              "L 882.964173 273.894567 \n",
              "L 890.942293 273.015734 \n",
              "L 898.920413 271.939921 \n",
              "L 906.898533 270.31863 \n",
              "L 914.876654 268.560967 \n",
              "L 922.854774 267.136652 \n",
              "L 930.832894 265.485055 \n",
              "L 938.811014 263.57587 \n",
              "L 946.789134 261.727289 \n",
              "L 954.767254 260.090847 \n",
              "L 962.745375 258.772601 \n",
              "L 970.723495 258.181661 \n",
              "L 978.701615 258.227115 \n",
              "L 986.679735 259.302928 \n",
              "L 994.657855 260.818154 \n",
              "L 1002.635976 261.984881 \n",
              "L 1010.614096 262.74249 \n",
              "L 1018.592216 263.409192 \n",
              "\" clip-path=\"url(#p56f081b087)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_41\">\n",
              "    <path d=\"M 77.174034 277.076542 \n",
              "L 85.152154 278.788751 \n",
              "L 93.130274 280.213062 \n",
              "L 101.108395 281.197961 \n",
              "L 109.086515 283.228366 \n",
              "L 117.064635 274.970377 \n",
              "L 125.042755 270.758047 \n",
              "L 133.020875 261.787901 \n",
              "L 140.998996 254.029936 \n",
              "L 148.977116 248.544814 \n",
              "L 156.955236 245.681032 \n",
              "L 164.933356 243.771847 \n",
              "L 172.911476 238.8019 \n",
              "L 180.889596 231.362139 \n",
              "L 188.867717 221.467699 \n",
              "L 196.845837 213.027888 \n",
              "L 204.823957 208.345836 \n",
              "L 212.802077 208.330685 \n",
              "L 220.780197 215.331033 \n",
              "L 228.758318 226.907369 \n",
              "L 236.736438 242.529364 \n",
              "L 244.714558 255.939121 \n",
              "L 252.692678 264.075895 \n",
              "L 260.670798 266.879064 \n",
              "L 268.648919 265.636574 \n",
              "L 276.627039 260.999982 \n",
              "L 284.605159 255.014835 \n",
              "L 292.583279 249.620626 \n",
              "L 300.561399 246.302281 \n",
              "L 308.539519 244.105194 \n",
              "L 316.51764 242.059641 \n",
              "L 324.49576 244.059741 \n",
              "L 332.47388 246.165906 \n",
              "L 340.452 250.060039 \n",
              "L 348.43012 254.696638 \n",
              "L 356.408241 259.16656 \n",
              "L 364.386361 262.303077 \n",
              "L 372.364481 263.697086 \n",
              "L 380.342601 264.000131 \n",
              "L 388.320721 262.969779 \n",
              "L 396.298841 259.499908 \n",
              "L 404.276962 254.242067 \n",
              "L 412.255082 248.423597 \n",
              "L 420.233202 243.786998 \n",
              "L 428.211322 242.21116 \n",
              "L 436.189442 243.786998 \n",
              "L 444.167563 246.938673 \n",
              "L 452.145683 250.135803 \n",
              "L 460.123803 251.484351 \n",
              "L 468.101923 252.166204 \n",
              "L 476.080043 251.090399 \n",
              "L 484.058164 250.757044 \n",
              "L 492.036284 250.044888 \n",
              "L 500.014404 250.514611 \n",
              "L 507.992524 252.302579 \n",
              "L 515.970644 254.060238 \n",
              "L 523.948764 257.333131 \n",
              "L 531.926885 263.272825 \n",
              "L 539.905005 264.863813 \n",
              "L 547.883125 272.167207 \n",
              "L 555.861245 272.742995 \n",
              "L 563.839365 271.773248 \n",
              "L 571.817486 269.803454 \n",
              "L 579.795606 268.030637 \n",
              "L 587.773726 267.227566 \n",
              "L 595.751846 266.409342 \n",
              "L 603.729966 265.651732 \n",
              "L 611.708086 266.121448 \n",
              "L 619.686207 267.348783 \n",
              "L 627.664327 268.303376 \n",
              "L 635.642447 267.454849 \n",
              "L 643.620567 266.439648 \n",
              "L 651.598687 265.575969 \n",
              "L 659.576808 262.484906 \n",
              "L 667.554928 256.878566 \n",
              "L 675.533048 248.514511 \n",
              "L 683.511168 239.377688 \n",
              "L 691.489288 228.574121 \n",
              "L 699.467409 218.406945 \n",
              "L 707.445529 207.83066 \n",
              "L 715.423649 205.679034 \n",
              "L 723.401769 206.39119 \n",
              "L 731.379889 214.982527 \n",
              "L 739.358009 225.619425 \n",
              "L 747.33613 235.680534 \n",
              "L 755.31425 241.4384 \n",
              "L 763.29237 246.135603 \n",
              "L 771.27049 249.69639 \n",
              "L 779.24861 251.393444 \n",
              "L 787.226731 251.590424 \n",
              "L 795.204851 251.681331 \n",
              "L 803.182971 253.408695 \n",
              "L 811.161091 250.954024 \n",
              "L 819.139211 249.86306 \n",
              "L 827.117331 251.30253 \n",
              "L 835.095452 253.817805 \n",
              "L 843.073572 254.726941 \n",
              "L 851.051692 253.166254 \n",
              "L 859.029812 251.4692 \n",
              "L 867.007932 250.71159 \n",
              "L 874.986053 250.878261 \n",
              "L 882.964173 252.060139 \n",
              "L 890.942293 252.46925 \n",
              "L 898.920413 253.242017 \n",
              "L 906.898533 254.439047 \n",
              "L 914.876654 255.999733 \n",
              "L 922.854774 256.817955 \n",
              "L 930.832894 257.499808 \n",
              "L 938.811014 257.802853 \n",
              "L 946.789134 257.575571 \n",
              "L 954.767254 256.408844 \n",
              "L 962.745375 254.999684 \n",
              "L 970.723495 253.696589 \n",
              "L 978.701615 252.302579 \n",
              "L 986.679735 251.726791 \n",
              "L 994.657855 251.984383 \n",
              "L 1002.635976 252.635927 \n",
              "L 1010.614096 253.484458 \n",
              "L 1018.592216 254.423896 \n",
              "\" clip-path=\"url(#p56f081b087)\" style=\"fill: none; stroke: #2ca02c; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_42\">\n",
              "    <path d=\"M 77.174034 267.262901 \n",
              "L 85.152154 267.033527 \n",
              "L 93.130274 266.606264 \n",
              "L 101.108395 266.552624 \n",
              "L 109.086515 266.752389 \n",
              "L 117.064635 266.772724 \n",
              "L 125.042755 265.278227 \n",
              "L 133.020875 265.472418 \n",
              "L 140.998996 265.687006 \n",
              "L 148.977116 265.627788 \n",
              "L 156.955236 265.466869 \n",
              "L 164.933356 265.330017 \n",
              "L 172.911476 264.91754 \n",
              "L 180.889596 264.484731 \n",
              "L 188.867717 264.45143 \n",
              "L 196.845837 264.329361 \n",
              "L 204.823957 264.388542 \n",
              "L 212.802077 264.5661 \n",
              "L 220.780197 264.882389 \n",
              "L 228.758318 265.230129 \n",
              "L 236.736438 265.339258 \n",
              "L 244.714558 265.248619 \n",
              "L 252.692678 265.803526 \n",
              "L 260.670798 265.668487 \n",
              "L 268.648919 265.261559 \n",
              "L 276.627039 264.94342 \n",
              "L 284.605159 264.752929 \n",
              "L 292.583279 264.654891 \n",
              "L 300.561399 264.87684 \n",
              "L 308.539519 265.348499 \n",
              "L 316.51764 265.864557 \n",
              "L 324.49576 266.46753 \n",
              "L 332.47388 266.704298 \n",
              "L 340.452 266.979888 \n",
              "L 348.43012 267.020587 \n",
              "L 356.408241 266.878154 \n",
              "L 364.386361 266.626595 \n",
              "L 372.364481 266.476799 \n",
              "L 380.342601 266.404645 \n",
              "L 388.320721 266.339915 \n",
              "L 396.298841 266.321429 \n",
              "L 404.276962 266.34916 \n",
              "L 412.255082 266.537834 \n",
              "L 420.233202 266.802333 \n",
              "L 428.211322 267.064982 \n",
              "L 436.189442 267.248082 \n",
              "L 444.167563 267.492246 \n",
              "L 452.145683 267.767836 \n",
              "L 460.123803 267.925055 \n",
              "L 468.101923 267.99718 \n",
              "L 476.080043 268.03788 \n",
              "L 484.058164 267.99718 \n",
              "L 492.036284 267.9713 \n",
              "L 500.014404 267.999059 \n",
              "L 507.992524 267.730832 \n",
              "L 515.970644 267.608766 \n",
              "L 523.948764 268.226554 \n",
              "L 531.926885 268.491053 \n",
              "L 539.905005 268.25798 \n",
              "L 547.883125 266.769028 \n",
              "L 555.861245 266.770878 \n",
              "L 563.839365 267.127863 \n",
              "L 571.817486 267.183352 \n",
              "L 579.795606 267.120471 \n",
              "L 587.773726 266.837454 \n",
              "L 595.751846 266.478649 \n",
              "L 603.729966 266.088356 \n",
              "L 611.708086 265.620397 \n",
              "L 619.686207 264.963788 \n",
              "L 627.664327 264.394091 \n",
              "L 635.642447 264.013072 \n",
              "L 643.620567 263.792971 \n",
              "L 651.598687 263.757814 \n",
              "L 659.576808 263.859551 \n",
              "L 667.554928 264.048193 \n",
              "L 675.533048 264.351542 \n",
              "L 683.511168 264.45143 \n",
              "L 691.489288 264.36821 \n",
              "L 699.467409 264.477339 \n",
              "L 707.445529 264.69744 \n",
              "L 715.423649 265.037759 \n",
              "L 723.401769 265.339258 \n",
              "L 731.379889 265.653698 \n",
              "L 739.358009 265.820165 \n",
              "L 747.33613 266.284426 \n",
              "L 755.31425 266.430555 \n",
              "L 763.29237 266.282576 \n",
              "L 771.27049 266.045807 \n",
              "L 779.24861 265.840497 \n",
              "L 787.226731 265.651848 \n",
              "L 795.204851 265.383657 \n",
              "L 803.182971 265.09879 \n",
              "L 811.161091 264.830599 \n",
              "L 819.139211 264.575341 \n",
              "L 827.117331 264.481031 \n",
              "L 835.095452 264.691891 \n",
              "L 843.073572 264.93048 \n",
              "L 851.051692 265.167249 \n",
              "L 859.029812 265.433597 \n",
              "L 867.007932 265.714736 \n",
              "L 874.986053 265.877497 \n",
              "L 882.964173 265.982927 \n",
              "L 890.942293 266.036566 \n",
              "L 898.920413 266.178996 \n",
              "L 906.898533 266.301065 \n",
              "L 914.876654 266.41389 \n",
              "L 922.854774 266.48974 \n",
              "L 930.832894 266.521166 \n",
              "L 938.811014 266.510075 \n",
              "L 946.789134 266.506379 \n",
              "L 954.767254 266.476799 \n",
              "L 962.745375 266.456435 \n",
              "L 970.723495 266.408345 \n",
              "L 978.701615 266.352855 \n",
              "L 986.679735 266.284426 \n",
              "L 994.657855 266.236335 \n",
              "L 1002.635976 266.214154 \n",
              "L 1010.614096 266.217846 \n",
              "L 1018.592216 266.249275 \n",
              "\" clip-path=\"url(#p56f081b087)\" style=\"fill: none; stroke: #d62728; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_43\">\n",
              "    <path d=\"M 77.174034 268.740762 \n",
              "L 85.152154 269.079236 \n",
              "L 93.130274 269.536105 \n",
              "L 101.108395 270.018858 \n",
              "L 109.086515 270.610736 \n",
              "L 117.064635 271.583663 \n",
              "L 125.042755 271.892557 \n",
              "L 133.020875 272.338306 \n",
              "L 140.998996 272.480736 \n",
              "L 148.977116 272.447431 \n",
              "L 156.955236 272.199572 \n",
              "L 164.933356 271.938773 \n",
              "L 172.911476 271.877738 \n",
              "L 180.889596 271.938773 \n",
              "L 188.867717 271.750127 \n",
              "L 196.845837 271.431988 \n",
              "L 204.823957 270.355478 \n",
              "L 212.802077 269.097721 \n",
              "L 220.780197 267.888055 \n",
              "L 228.758318 266.709844 \n",
              "L 236.736438 265.587118 \n",
              "L 244.714558 265.228287 \n",
              "L 252.692678 265.975535 \n",
              "L 260.670798 266.245576 \n",
              "L 268.648919 266.868913 \n",
              "L 276.627039 267.333177 \n",
              "L 284.605159 267.638375 \n",
              "L 292.583279 267.732681 \n",
              "L 300.561399 267.59398 \n",
              "L 308.539519 267.349813 \n",
              "L 316.51764 267.096408 \n",
              "L 324.49576 266.670994 \n",
              "L 332.47388 266.273335 \n",
              "L 340.452 265.997717 \n",
              "L 348.43012 265.796127 \n",
              "L 356.408241 265.722127 \n",
              "L 364.386361 265.820165 \n",
              "L 372.364481 266.008836 \n",
              "L 380.342601 266.210454 \n",
              "L 388.320721 266.45089 \n",
              "L 396.298841 266.706144 \n",
              "L 404.276962 266.907763 \n",
              "L 412.255082 266.926248 \n",
              "L 420.233202 266.780119 \n",
              "L 428.211322 266.478649 \n",
              "L 436.189442 266.129056 \n",
              "L 444.167563 265.822008 \n",
              "L 452.145683 265.675879 \n",
              "L 460.123803 265.685156 \n",
              "L 468.101923 265.740645 \n",
              "L 476.080043 265.846075 \n",
              "L 484.058164 265.899714 \n",
              "L 492.036284 265.910805 \n",
              "L 500.014404 265.862707 \n",
              "L 507.992524 265.781308 \n",
              "L 515.970644 265.738796 \n",
              "L 523.948764 265.683306 \n",
              "L 531.926885 265.605607 \n",
              "L 539.905005 265.866406 \n",
              "L 547.883125 265.914497 \n",
              "L 555.861245 266.326975 \n",
              "L 563.839365 266.654354 \n",
              "L 571.817486 267.055738 \n",
              "L 579.795606 267.342421 \n",
              "L 587.773726 267.584735 \n",
              "L 595.751846 267.875115 \n",
              "L 603.729966 268.165523 \n",
              "L 611.708086 268.444808 \n",
              "L 619.686207 268.755552 \n",
              "L 627.664327 269.129176 \n",
              "L 635.642447 269.576804 \n",
              "L 643.620567 270.009613 \n",
              "L 651.598687 270.412817 \n",
              "L 659.576808 270.851201 \n",
              "L 667.554928 271.28401 \n",
              "L 675.533048 271.62433 \n",
              "L 683.511168 271.757518 \n",
              "L 691.489288 271.927678 \n",
              "L 699.467409 271.62433 \n",
              "L 707.445529 271.099031 \n",
              "L 715.423649 269.795058 \n",
              "L 723.401769 268.583542 \n",
              "L 731.379889 267.305418 \n",
              "L 739.358009 266.388009 \n",
              "L 747.33613 265.622246 \n",
              "L 755.31425 265.370717 \n",
              "L 763.29237 265.304108 \n",
              "L 771.27049 265.368867 \n",
              "L 779.24861 265.553817 \n",
              "L 787.226731 265.701795 \n",
              "L 795.204851 265.833106 \n",
              "L 803.182971 265.873798 \n",
              "L 811.161091 266.075416 \n",
              "L 819.139211 266.062476 \n",
              "L 827.117331 265.973686 \n",
              "L 835.095452 265.855316 \n",
              "L 843.073572 265.899714 \n",
              "L 851.051692 266.040266 \n",
              "L 859.029812 266.095755 \n",
              "L 867.007932 266.034717 \n",
              "L 874.986053 265.936686 \n",
              "L 882.964173 265.838647 \n",
              "L 890.942293 265.799827 \n",
              "L 898.920413 265.759127 \n",
              "L 906.898533 265.740645 \n",
              "L 914.876654 265.748037 \n",
              "L 922.854774 265.805375 \n",
              "L 930.832894 265.888588 \n",
              "L 938.811014 265.995867 \n",
              "L 946.789134 266.116115 \n",
              "L 954.767254 266.245576 \n",
              "L 962.745375 266.343614 \n",
              "L 970.723495 266.3991 \n",
              "L 978.701615 266.419435 \n",
              "L 986.679735 266.39725 \n",
              "L 994.657855 266.34916 \n",
              "L 1002.635976 266.304761 \n",
              "L 1010.614096 266.273335 \n",
              "L 1018.592216 266.267793 \n",
              "\" clip-path=\"url(#p56f081b087)\" style=\"fill: none; stroke: #9467bd; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_44\">\n",
              "    <path d=\"M 77.174034 268.407808 \n",
              "L 85.152154 267.664256 \n",
              "L 93.130274 266.619204 \n",
              "L 101.108395 265.520509 \n",
              "L 109.086515 264.680771 \n",
              "L 117.064635 262.080188 \n",
              "L 125.042755 258.865509 \n",
              "L 133.020875 256.997355 \n",
              "L 140.998996 255.365971 \n",
              "L 148.977116 254.043483 \n",
              "L 156.955236 253.009555 \n",
              "L 164.933356 252.325187 \n",
              "L 172.911476 251.8868 \n",
              "L 180.889596 251.748098 \n",
              "L 188.867717 251.85722 \n",
              "L 196.845837 252.056989 \n",
              "L 204.823957 252.486099 \n",
              "L 212.802077 252.985488 \n",
              "L 220.780197 253.638433 \n",
              "L 228.758318 254.261734 \n",
              "L 236.736438 254.89989 \n",
              "L 244.714558 256.381446 \n",
              "L 252.692678 259.100399 \n",
              "L 260.670798 260.474713 \n",
              "L 268.648919 261.715808 \n",
              "L 276.627039 262.773797 \n",
              "L 284.605159 263.535864 \n",
              "L 292.583279 264.05932 \n",
              "L 300.561399 264.536521 \n",
              "L 308.539519 265.095098 \n",
              "L 316.51764 265.759127 \n",
              "L 324.49576 266.571109 \n",
              "L 332.47388 267.534795 \n",
              "L 340.452 268.579847 \n",
              "L 348.43012 269.77654 \n",
              "L 356.408241 270.917781 \n",
              "L 364.386361 272.001682 \n",
              "L 372.364481 272.967185 \n",
              "L 380.342601 273.768076 \n",
              "L 388.320721 274.422864 \n",
              "L 396.298841 274.974043 \n",
              "L 404.276962 275.497496 \n",
              "L 412.255082 276.050553 \n",
              "L 420.233202 276.566578 \n",
              "L 428.211322 276.990147 \n",
              "L 436.189442 277.321251 \n",
              "L 444.167563 277.602389 \n",
              "L 452.145683 277.794759 \n",
              "L 460.123803 277.900189 \n",
              "L 468.101923 277.942738 \n",
              "L 476.080043 277.935314 \n",
              "L 484.058164 277.798459 \n",
              "L 492.036284 277.517291 \n",
              "L 500.014404 277.056755 \n",
              "L 507.992524 276.381629 \n",
              "L 515.970644 275.591831 \n",
              "L 523.948764 274.831614 \n",
              "L 531.926885 274.01224 \n",
              "L 539.905005 271.659484 \n",
              "L 547.883125 268.681548 \n",
              "L 555.861245 266.900368 \n",
              "L 563.839365 265.387356 \n",
              "L 571.817486 264.255353 \n",
              "L 579.795606 263.474833 \n",
              "L 587.773726 262.916226 \n",
              "L 595.751846 262.555546 \n",
              "L 603.729966 262.261438 \n",
              "L 611.708086 261.895238 \n",
              "L 619.686207 261.353271 \n",
              "L 627.664327 260.628204 \n",
              "L 635.642447 259.768135 \n",
              "L 643.620567 258.821118 \n",
              "L 651.598687 257.870401 \n",
              "L 659.576808 256.949265 \n",
              "L 667.554928 256.083646 \n",
              "L 675.533048 255.351181 \n",
              "L 683.511168 254.726001 \n",
              "L 691.489288 254.357923 \n",
              "L 699.467409 254.263584 \n",
              "L 707.445529 254.385682 \n",
              "L 715.423649 254.855491 \n",
              "L 723.401769 255.502859 \n",
              "L 731.379889 256.301897 \n",
              "L 739.358009 257.309952 \n",
              "L 747.33613 258.810027 \n",
              "L 755.31425 260.156545 \n",
              "L 763.29237 261.183111 \n",
              "L 771.27049 262.096827 \n",
              "L 779.24861 263.025355 \n",
              "L 787.226731 263.983463 \n",
              "L 795.204851 265.04885 \n",
              "L 803.182971 266.090206 \n",
              "L 811.161091 266.915157 \n",
              "L 819.139211 267.688315 \n",
              "L 827.117331 268.4152 \n",
              "L 835.095452 268.953471 \n",
              "L 843.073572 269.192057 \n",
              "L 851.051692 269.184665 \n",
              "L 859.029812 269.057051 \n",
              "L 867.007932 268.823978 \n",
              "L 874.986053 268.463294 \n",
              "L 882.964173 268.041575 \n",
              "L 890.942293 267.599525 \n",
              "L 898.920413 267.227747 \n",
              "L 906.898533 266.900368 \n",
              "L 914.876654 266.62105 \n",
              "L 922.854774 266.425009 \n",
              "L 930.832894 266.260366 \n",
              "L 938.811014 266.123514 \n",
              "L 946.789134 266.043958 \n",
              "L 954.767254 266.016235 \n",
              "L 962.745375 266.034717 \n",
              "L 970.723495 266.093905 \n",
              "L 978.701615 266.177146 \n",
              "L 986.679735 266.258516 \n",
              "L 994.657855 266.315884 \n",
              "L 1002.635976 266.338065 \n",
              "L 1010.614096 266.330674 \n",
              "L 1018.592216 266.29737 \n",
              "\" clip-path=\"url(#p56f081b087)\" style=\"fill: none; stroke: #8c564b; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_9\">\n",
              "    <path d=\"M 30.103125 332.958125 \n",
              "L 30.103125 199.618125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_10\">\n",
              "    <path d=\"M 1065.663125 332.958125 \n",
              "L 1065.663125 199.618125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_11\">\n",
              "    <path d=\"M 30.103125 332.958125 \n",
              "L 1065.663125 332.958125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_12\">\n",
              "    <path d=\"M 30.103125 199.618125 \n",
              "L 1065.663125 199.618125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"text_34\">\n",
              "    <!-- Sample 53 Class:['AvadaKedavra'] -->\n",
              "    <g transform=\"translate(445.177187 193.618125) scale(0.12 -0.12)\">\n",
              "     <use xlink:href=\"#DejaVuSans-53\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"63.476562\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6d\" x=\"124.755859\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-70\" x=\"222.167969\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6c\" x=\"285.644531\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-65\" x=\"313.427734\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-20\" x=\"374.951172\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-35\" x=\"406.738281\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-33\" x=\"470.361328\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-20\" x=\"533.984375\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-43\" x=\"565.771484\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6c\" x=\"635.595703\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"663.378906\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-73\" x=\"724.658203\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-73\" x=\"776.757812\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-3a\" x=\"828.857422\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-5b\" x=\"862.548828\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-27\" x=\"901.5625\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-41\" x=\"929.052734\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-76\" x=\"991.585938\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"1050.765625\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-64\" x=\"1112.044922\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"1175.521484\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-4b\" x=\"1236.800781\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-65\" x=\"1297.376953\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-64\" x=\"1358.900391\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"1422.376953\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-76\" x=\"1483.65625\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-72\" x=\"1542.835938\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"1583.949219\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-27\" x=\"1645.228516\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-5d\" x=\"1672.71875\"/>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"legend_2\">\n",
              "    <g id=\"patch_13\">\n",
              "     <path d=\"M 37.103125 295.686875 \n",
              "L 114.742188 295.686875 \n",
              "Q 116.742188 295.686875 116.742188 293.686875 \n",
              "L 116.742188 206.618125 \n",
              "Q 116.742188 204.618125 114.742188 204.618125 \n",
              "L 37.103125 204.618125 \n",
              "Q 35.103125 204.618125 35.103125 206.618125 \n",
              "L 35.103125 293.686875 \n",
              "Q 35.103125 295.686875 37.103125 295.686875 \n",
              "z\n",
              "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
              "    </g>\n",
              "    <g id=\"line2d_45\">\n",
              "     <path d=\"M 39.103125 212.716562 \n",
              "L 49.103125 212.716562 \n",
              "L 59.103125 212.716562 \n",
              "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_35\">\n",
              "     <!-- feature 1 -->\n",
              "     <g transform=\"translate(67.103125 216.216562) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-31\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_46\">\n",
              "     <path d=\"M 39.103125 227.394687 \n",
              "L 49.103125 227.394687 \n",
              "L 59.103125 227.394687 \n",
              "\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_36\">\n",
              "     <!-- feature 2 -->\n",
              "     <g transform=\"translate(67.103125 230.894687) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-32\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_47\">\n",
              "     <path d=\"M 39.103125 242.072812 \n",
              "L 49.103125 242.072812 \n",
              "L 59.103125 242.072812 \n",
              "\" style=\"fill: none; stroke: #2ca02c; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_37\">\n",
              "     <!-- feature 3 -->\n",
              "     <g transform=\"translate(67.103125 245.572812) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-33\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_48\">\n",
              "     <path d=\"M 39.103125 256.750937 \n",
              "L 49.103125 256.750937 \n",
              "L 59.103125 256.750937 \n",
              "\" style=\"fill: none; stroke: #d62728; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_38\">\n",
              "     <!-- feature 4 -->\n",
              "     <g transform=\"translate(67.103125 260.250937) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-34\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_49\">\n",
              "     <path d=\"M 39.103125 271.429062 \n",
              "L 49.103125 271.429062 \n",
              "L 59.103125 271.429062 \n",
              "\" style=\"fill: none; stroke: #9467bd; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_39\">\n",
              "     <!-- feature 5 -->\n",
              "     <g transform=\"translate(67.103125 274.929062) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-35\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_50\">\n",
              "     <path d=\"M 39.103125 286.107187 \n",
              "L 49.103125 286.107187 \n",
              "L 59.103125 286.107187 \n",
              "\" style=\"fill: none; stroke: #8c564b; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_40\">\n",
              "     <!-- feature 6 -->\n",
              "     <g transform=\"translate(67.103125 289.607187) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-36\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "  </g>\n",
              "  <g id=\"axes_3\">\n",
              "   <g id=\"patch_14\">\n",
              "    <path d=\"M 30.103125 510.258125 \n",
              "L 1065.663125 510.258125 \n",
              "L 1065.663125 376.918125 \n",
              "L 30.103125 376.918125 \n",
              "z\n",
              "\" style=\"fill: #ffffff\"/>\n",
              "   </g>\n",
              "   <g id=\"matplotlib.axis_5\">\n",
              "    <g id=\"xtick_15\">\n",
              "     <g id=\"line2d_51\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"77.174034\" y=\"510.258125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_41\">\n",
              "      <!-- 0 -->\n",
              "      <g transform=\"translate(73.992784 524.856562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_16\">\n",
              "     <g id=\"line2d_52\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"236.736438\" y=\"510.258125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_42\">\n",
              "      <!-- 20 -->\n",
              "      <g transform=\"translate(230.373938 524.856562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_17\">\n",
              "     <g id=\"line2d_53\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"396.298841\" y=\"510.258125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_43\">\n",
              "      <!-- 40 -->\n",
              "      <g transform=\"translate(389.936341 524.856562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_18\">\n",
              "     <g id=\"line2d_54\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"555.861245\" y=\"510.258125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_44\">\n",
              "      <!-- 60 -->\n",
              "      <g transform=\"translate(549.498745 524.856562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_19\">\n",
              "     <g id=\"line2d_55\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"715.423649\" y=\"510.258125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_45\">\n",
              "      <!-- 80 -->\n",
              "      <g transform=\"translate(709.061149 524.856562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_20\">\n",
              "     <g id=\"line2d_56\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"874.986053\" y=\"510.258125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_46\">\n",
              "      <!-- 100 -->\n",
              "      <g transform=\"translate(865.442303 524.856562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_21\">\n",
              "     <g id=\"line2d_57\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"1034.548456\" y=\"510.258125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_47\">\n",
              "      <!-- 120 -->\n",
              "      <g transform=\"translate(1025.004706 524.856562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"matplotlib.axis_6\">\n",
              "    <g id=\"ytick_13\">\n",
              "     <g id=\"line2d_58\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"504.197216\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_48\">\n",
              "      <!-- 0.0 -->\n",
              "      <g transform=\"translate(7.2 507.996435) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_14\">\n",
              "     <g id=\"line2d_59\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"479.95358\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_49\">\n",
              "      <!-- 0.2 -->\n",
              "      <g transform=\"translate(7.2 483.752798) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_15\">\n",
              "     <g id=\"line2d_60\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"455.709943\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_50\">\n",
              "      <!-- 0.4 -->\n",
              "      <g transform=\"translate(7.2 459.509162) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_16\">\n",
              "     <g id=\"line2d_61\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"431.466307\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_51\">\n",
              "      <!-- 0.6 -->\n",
              "      <g transform=\"translate(7.2 435.265526) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_17\">\n",
              "     <g id=\"line2d_62\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"407.22267\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_52\">\n",
              "      <!-- 0.8 -->\n",
              "      <g transform=\"translate(7.2 411.021889) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_18\">\n",
              "     <g id=\"line2d_63\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"382.979034\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_53\">\n",
              "      <!-- 1.0 -->\n",
              "      <g transform=\"translate(7.2 386.778253) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"line2d_64\">\n",
              "    <path d=\"M 77.174034 441.800156 \n",
              "L 85.152154 443.497211 \n",
              "L 93.130274 446.057947 \n",
              "L 101.108395 449.042942 \n",
              "L 109.086515 454.240174 \n",
              "L 117.064635 459.785905 \n",
              "L 125.042755 464.649786 \n",
              "L 133.020875 469.55912 \n",
              "L 140.998996 473.407797 \n",
              "L 148.977116 476.998887 \n",
              "L 156.955236 479.438403 \n",
              "L 164.933356 481.211219 \n",
              "L 172.911476 481.574872 \n",
              "L 180.889596 480.650584 \n",
              "L 188.867717 479.01414 \n",
              "L 196.845837 476.407948 \n",
              "L 204.823957 472.119853 \n",
              "L 212.802077 466.649885 \n",
              "L 220.780197 460.073799 \n",
              "L 228.758318 452.255225 \n",
              "L 236.736438 446.436752 \n",
              "L 244.714558 443.48206 \n",
              "L 252.692678 440.315233 \n",
              "L 260.670798 438.542415 \n",
              "L 268.648919 437.63328 \n",
              "L 276.627039 437.224169 \n",
              "L 284.605159 437.345386 \n",
              "L 292.583279 437.375695 \n",
              "L 300.561399 437.572675 \n",
              "L 308.539519 438.118154 \n",
              "L 316.51764 438.951526 \n",
              "L 324.49576 440.315233 \n",
              "L 332.47388 442.194116 \n",
              "L 340.452 444.451803 \n",
              "L 348.43012 447.027691 \n",
              "L 356.408241 449.891469 \n",
              "L 364.386361 452.937079 \n",
              "L 372.364481 455.725097 \n",
              "L 380.342601 458.467659 \n",
              "L 388.320721 461.164763 \n",
              "L 396.298841 463.755801 \n",
              "L 404.276962 466.02864 \n",
              "L 412.255082 467.725694 \n",
              "L 420.233202 468.75605 \n",
              "L 428.211322 469.392446 \n",
              "L 436.189442 470.165211 \n",
              "L 444.167563 470.55917 \n",
              "L 452.145683 470.983435 \n",
              "L 460.123803 471.347089 \n",
              "L 468.101923 471.241023 \n",
              "L 476.080043 470.119753 \n",
              "L 484.058164 467.816609 \n",
              "L 492.036284 464.861917 \n",
              "L 500.014404 460.801106 \n",
              "L 507.992524 456.67969 \n",
              "L 515.970644 453.361341 \n",
              "L 523.948764 451.467307 \n",
              "L 531.926885 450.22482 \n",
              "L 539.905005 449.83086 \n",
              "L 547.883125 449.770252 \n",
              "L 555.861245 449.952081 \n",
              "L 563.839365 450.376342 \n",
              "L 571.817486 451.937029 \n",
              "L 579.795606 451.785503 \n",
              "L 587.773726 454.103802 \n",
              "L 595.751846 458.240373 \n",
              "L 603.729966 463.513365 \n",
              "L 611.708086 470.301582 \n",
              "L 619.686207 477.211018 \n",
              "L 627.664327 484.226521 \n",
              "L 635.642447 490.272277 \n",
              "L 643.620567 494.317934 \n",
              "L 651.598687 495.924075 \n",
              "L 659.576808 494.863416 \n",
              "L 667.554928 492.484509 \n",
              "L 675.533048 487.22667 \n",
              "L 683.511168 481.393046 \n",
              "L 691.489288 474.438152 \n",
              "L 699.467409 467.104453 \n",
              "L 707.445529 461.285979 \n",
              "L 715.423649 455.467506 \n",
              "L 723.401769 452.058246 \n",
              "L 731.379889 446.906474 \n",
              "L 739.358009 442.966883 \n",
              "L 747.33613 439.163664 \n",
              "L 755.31425 436.163515 \n",
              "L 763.29237 435.087702 \n",
              "L 771.27049 434.845261 \n",
              "L 779.24861 435.648332 \n",
              "L 787.226731 436.739296 \n",
              "L 795.204851 438.057549 \n",
              "L 803.182971 439.087901 \n",
              "L 811.161091 440.194016 \n",
              "L 819.139211 440.936474 \n",
              "L 827.117331 441.209217 \n",
              "L 835.095452 441.527414 \n",
              "L 843.073572 441.739544 \n",
              "L 851.051692 441.133454 \n",
              "L 859.029812 441.254678 \n",
              "L 867.007932 441.451658 \n",
              "L 874.986053 441.300131 \n",
              "L 882.964173 441.360743 \n",
              "L 890.942293 440.997086 \n",
              "L 898.920413 440.891021 \n",
              "L 906.898533 440.921323 \n",
              "L 914.876654 440.815258 \n",
              "L 922.854774 440.67889 \n",
              "L 930.832894 440.769804 \n",
              "L 938.811014 440.860719 \n",
              "L 946.789134 440.87587 \n",
              "L 954.767254 440.906172 \n",
              "L 962.745375 440.891021 \n",
              "L 970.723495 440.830409 \n",
              "L 978.701615 440.800107 \n",
              "L 986.679735 440.724343 \n",
              "L 994.657855 440.663739 \n",
              "L 1002.635976 440.497061 \n",
              "L 1010.614096 440.421298 \n",
              "L 1018.592216 440.436449 \n",
              "\" clip-path=\"url(#peda403c841)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_65\">\n",
              "    <path d=\"M 77.174034 480.62028 \n",
              "L 85.152154 487.741848 \n",
              "L 93.130274 494.28763 \n",
              "L 101.108395 498.863616 \n",
              "L 109.086515 501.151609 \n",
              "L 117.064635 498.363591 \n",
              "L 125.042755 493.408798 \n",
              "L 133.020875 487.393346 \n",
              "L 140.998996 481.135457 \n",
              "L 148.977116 474.438152 \n",
              "L 156.955236 467.740849 \n",
              "L 164.933356 459.770753 \n",
              "L 172.911476 451.118804 \n",
              "L 180.889596 443.997236 \n",
              "L 188.867717 431.481462 \n",
              "L 196.845837 417.723199 \n",
              "L 204.823957 403.313384 \n",
              "L 212.802077 391.918877 \n",
              "L 220.780197 383.054797 \n",
              "L 228.758318 382.979034 \n",
              "L 236.736438 382.979034 \n",
              "L 244.714558 382.979034 \n",
              "L 252.692678 382.979034 \n",
              "L 260.670798 382.979034 \n",
              "L 268.648919 382.979034 \n",
              "L 276.627039 382.979034 \n",
              "L 284.605159 382.979034 \n",
              "L 292.583279 382.979034 \n",
              "L 300.561399 382.979034 \n",
              "L 308.539519 382.979034 \n",
              "L 316.51764 382.979034 \n",
              "L 324.49576 382.979034 \n",
              "L 332.47388 382.979034 \n",
              "L 340.452 382.979034 \n",
              "L 348.43012 383.069948 \n",
              "L 356.408241 386.812556 \n",
              "L 364.386361 391.115807 \n",
              "L 372.364481 396.252424 \n",
              "L 380.342601 401.237522 \n",
              "L 388.320721 406.404448 \n",
              "L 396.298841 412.328983 \n",
              "L 404.276962 418.950531 \n",
              "L 412.255082 425.950879 \n",
              "L 420.233202 433.42095 \n",
              "L 428.211322 439.300032 \n",
              "L 436.189442 442.224418 \n",
              "L 444.167563 443.997236 \n",
              "L 452.145683 448.270178 \n",
              "L 460.123803 452.664336 \n",
              "L 468.101923 459.785905 \n",
              "L 476.080043 468.740899 \n",
              "L 484.058164 478.529266 \n",
              "L 492.036284 489.529816 \n",
              "L 500.014404 498.409048 \n",
              "L 507.992524 503.272927 \n",
              "L 515.970644 504.197216 \n",
              "L 523.948764 504.106302 \n",
              "L 531.926885 498.136307 \n",
              "L 539.905005 493.378493 \n",
              "L 547.883125 492.878468 \n",
              "L 555.861245 496.590775 \n",
              "L 563.839365 501.95468 \n",
              "L 571.817486 504.197216 \n",
              "L 579.795606 504.197216 \n",
              "L 587.773726 504.197216 \n",
              "L 595.751846 504.197216 \n",
              "L 603.729966 504.197216 \n",
              "L 611.708086 504.197216 \n",
              "L 619.686207 499.393945 \n",
              "L 627.664327 487.302432 \n",
              "L 635.642447 474.998786 \n",
              "L 643.620567 461.01324 \n",
              "L 651.598687 447.921675 \n",
              "L 659.576808 438.299982 \n",
              "L 667.554928 426.920626 \n",
              "L 675.533048 415.617027 \n",
              "L 683.511168 407.23782 \n",
              "L 691.489288 402.464853 \n",
              "L 699.467409 400.146558 \n",
              "L 707.445529 397.222171 \n",
              "L 715.423649 392.055245 \n",
              "L 723.401769 384.236676 \n",
              "L 731.379889 382.979034 \n",
              "L 739.358009 382.979034 \n",
              "L 747.33613 382.979034 \n",
              "L 755.31425 382.979034 \n",
              "L 763.29237 382.979034 \n",
              "L 771.27049 382.979034 \n",
              "L 779.24861 383.857867 \n",
              "L 787.226731 393.691688 \n",
              "L 795.204851 405.752897 \n",
              "L 803.182971 417.223174 \n",
              "L 811.161091 426.117556 \n",
              "L 819.139211 432.739097 \n",
              "L 827.117331 438.709093 \n",
              "L 835.095452 442.800206 \n",
              "L 843.073572 444.785154 \n",
              "L 851.051692 444.588175 \n",
              "L 859.029812 443.997236 \n",
              "L 867.007932 444.163913 \n",
              "L 874.986053 444.451803 \n",
              "L 882.964173 444.482109 \n",
              "L 890.942293 444.618481 \n",
              "L 898.920413 444.209367 \n",
              "L 906.898533 444.027542 \n",
              "L 914.876654 444.360893 \n",
              "L 922.854774 444.754849 \n",
              "L 930.832894 444.315436 \n",
              "L 938.811014 443.012337 \n",
              "L 946.789134 441.451658 \n",
              "L 954.767254 439.784906 \n",
              "L 962.745375 438.906072 \n",
              "L 970.723495 438.587876 \n",
              "L 978.701615 438.769705 \n",
              "L 986.679735 439.163664 \n",
              "L 994.657855 439.557624 \n",
              "L 1002.635976 439.921273 \n",
              "L 1010.614096 440.04249 \n",
              "L 1018.592216 439.663689 \n",
              "\" clip-path=\"url(#peda403c841)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_66\">\n",
              "    <path d=\"M 77.174034 463.028491 \n",
              "L 85.152154 466.013489 \n",
              "L 93.130274 468.922724 \n",
              "L 101.108395 469.331835 \n",
              "L 109.086515 465.952881 \n",
              "L 117.064635 459.770753 \n",
              "L 125.042755 454.012888 \n",
              "L 133.020875 447.239822 \n",
              "L 140.998996 441.209217 \n",
              "L 148.977116 436.921124 \n",
              "L 156.955236 433.360338 \n",
              "L 164.933356 428.102505 \n",
              "L 172.911476 419.450556 \n",
              "L 180.889596 412.177464 \n",
              "L 188.867717 401.22237 \n",
              "L 196.845837 391.585523 \n",
              "L 204.823957 385.418547 \n",
              "L 212.802077 387.358041 \n",
              "L 220.780197 398.20707 \n",
              "L 228.758318 412.677489 \n",
              "L 236.736438 429.4056 \n",
              "L 244.714558 437.057492 \n",
              "L 252.692678 442.027438 \n",
              "L 260.670798 441.739544 \n",
              "L 268.648919 438.815158 \n",
              "L 276.627039 433.830061 \n",
              "L 284.605159 428.693444 \n",
              "L 292.583279 425.299335 \n",
              "L 300.561399 423.314387 \n",
              "L 308.539519 422.405251 \n",
              "L 316.51764 422.723448 \n",
              "L 324.49576 423.920477 \n",
              "L 332.47388 425.481156 \n",
              "L 340.452 426.935778 \n",
              "L 348.43012 428.860114 \n",
              "L 356.408241 430.466254 \n",
              "L 364.386361 432.769399 \n",
              "L 372.364481 433.61793 \n",
              "L 380.342601 433.011839 \n",
              "L 388.320721 431.905724 \n",
              "L 396.298841 430.845062 \n",
              "L 404.276962 430.481413 \n",
              "L 412.255082 429.935927 \n",
              "L 420.233202 427.753999 \n",
              "L 428.211322 424.087147 \n",
              "L 436.189442 421.238524 \n",
              "L 444.167563 421.071847 \n",
              "L 452.145683 423.041644 \n",
              "L 460.123803 424.708396 \n",
              "L 468.101923 427.496414 \n",
              "L 476.080043 431.875422 \n",
              "L 484.058164 436.254422 \n",
              "L 492.036284 439.390946 \n",
              "L 500.014404 442.375944 \n",
              "L 507.992524 443.785105 \n",
              "L 515.970644 444.936677 \n",
              "L 523.948764 446.588274 \n",
              "L 531.926885 447.224671 \n",
              "L 539.905005 447.01254 \n",
              "L 547.883125 447.133756 \n",
              "L 555.861245 447.542867 \n",
              "L 563.839365 449.61873 \n",
              "L 571.817486 453.012838 \n",
              "L 579.795606 454.118954 \n",
              "L 587.773726 460.134407 \n",
              "L 595.751846 464.028541 \n",
              "L 603.729966 467.074147 \n",
              "L 611.708086 468.574222 \n",
              "L 619.686207 466.468057 \n",
              "L 627.664327 459.104051 \n",
              "L 635.642447 448.936876 \n",
              "L 643.620567 436.542316 \n",
              "L 651.598687 423.647734 \n",
              "L 659.576808 410.813757 \n",
              "L 667.554928 401.237522 \n",
              "L 675.533048 390.55517 \n",
              "L 683.511168 382.979034 \n",
              "L 691.489288 382.979034 \n",
              "L 699.467409 382.979034 \n",
              "L 707.445529 382.979034 \n",
              "L 715.423649 385.782204 \n",
              "L 723.401769 395.343288 \n",
              "L 731.379889 404.298283 \n",
              "L 739.358009 417.10195 \n",
              "L 747.33613 423.268926 \n",
              "L 755.31425 428.451003 \n",
              "L 763.29237 432.557268 \n",
              "L 771.27049 429.01164 \n",
              "L 779.24861 426.814561 \n",
              "L 787.226731 426.344838 \n",
              "L 795.204851 427.617631 \n",
              "L 803.182971 427.920676 \n",
              "L 811.161091 426.314536 \n",
              "L 819.139211 425.223572 \n",
              "L 827.117331 425.344789 \n",
              "L 835.095452 425.60238 \n",
              "L 843.073572 425.905426 \n",
              "L 851.051692 426.79941 \n",
              "L 859.029812 428.511615 \n",
              "L 867.007932 429.557119 \n",
              "L 874.986053 430.905674 \n",
              "L 882.964173 432.22392 \n",
              "L 890.942293 434.345237 \n",
              "L 898.920413 435.496813 \n",
              "L 906.898533 436.299883 \n",
              "L 914.876654 436.754447 \n",
              "L 922.854774 436.693842 \n",
              "L 930.832894 435.708943 \n",
              "L 938.811014 433.784607 \n",
              "L 946.789134 431.587528 \n",
              "L 954.767254 429.723796 \n",
              "L 962.745375 428.723746 \n",
              "L 970.723495 427.723696 \n",
              "L 978.701615 426.950929 \n",
              "L 986.679735 427.450954 \n",
              "L 994.657855 428.587378 \n",
              "L 1002.635976 429.481356 \n",
              "L 1010.614096 429.451053 \n",
              "L 1018.592216 429.632882 \n",
              "\" clip-path=\"url(#peda403c841)\" style=\"fill: none; stroke: #2ca02c; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_67\">\n",
              "    <path d=\"M 77.174034 444.265098 \n",
              "L 85.152154 443.832289 \n",
              "L 93.130274 443.405025 \n",
              "L 101.108395 443.075767 \n",
              "L 109.086515 442.657748 \n",
              "L 117.064635 442.524588 \n",
              "L 125.042755 442.663289 \n",
              "L 133.020875 442.927788 \n",
              "L 140.998996 443.144225 \n",
              "L 148.977116 443.199714 \n",
              "L 156.955236 443.343958 \n",
              "L 164.933356 443.538185 \n",
              "L 172.911476 443.665796 \n",
              "L 180.889596 443.747194 \n",
              "L 188.867717 443.356934 \n",
              "L 196.845837 443.306987 \n",
              "L 204.823957 443.501185 \n",
              "L 212.802077 443.715736 \n",
              "L 220.780197 444.137454 \n",
              "L 228.758318 444.786701 \n",
              "L 236.736438 444.810732 \n",
              "L 244.714558 445.533949 \n",
              "L 252.692678 445.262059 \n",
              "L 260.670798 444.629481 \n",
              "L 268.648919 443.81562 \n",
              "L 276.627039 443.112767 \n",
              "L 284.605159 442.674416 \n",
              "L 292.583279 442.482039 \n",
              "L 300.561399 442.441339 \n",
              "L 308.539519 442.500528 \n",
              "L 316.51764 442.622619 \n",
              "L 324.49576 442.826087 \n",
              "L 332.47388 442.990698 \n",
              "L 340.452 443.062826 \n",
              "L 348.43012 443.077616 \n",
              "L 356.408241 443.029518 \n",
              "L 364.386361 442.875998 \n",
              "L 372.364481 442.739146 \n",
              "L 380.342601 442.646657 \n",
              "L 388.320721 442.517189 \n",
              "L 396.298841 442.511647 \n",
              "L 404.276962 442.567137 \n",
              "L 412.255082 442.676258 \n",
              "L 420.233202 442.998096 \n",
              "L 428.211322 443.377266 \n",
              "L 436.189442 443.436454 \n",
              "L 444.167563 443.525244 \n",
              "L 452.145683 443.747194 \n",
              "L 460.123803 443.835984 \n",
              "L 468.101923 443.976539 \n",
              "L 476.080043 444.122668 \n",
              "L 484.058164 444.085664 \n",
              "L 492.036284 444.155973 \n",
              "L 500.014404 444.339073 \n",
              "L 507.992524 444.300252 \n",
              "L 515.970644 444.081969 \n",
              "L 523.948764 443.874805 \n",
              "L 531.926885 443.834138 \n",
              "L 539.905005 444.109728 \n",
              "L 547.883125 444.246612 \n",
              "L 555.861245 444.205913 \n",
              "L 563.839365 443.970994 \n",
              "L 571.817486 443.689859 \n",
              "L 579.795606 443.497485 \n",
              "L 587.773726 443.133106 \n",
              "L 595.751846 442.480189 \n",
              "L 603.729966 441.73664 \n",
              "L 611.708086 441.368561 \n",
              "L 619.686207 441.455473 \n",
              "L 627.664327 441.584962 \n",
              "L 635.642447 441.864251 \n",
              "L 643.620567 441.747731 \n",
              "L 651.598687 441.372253 \n",
              "L 659.576808 441.109604 \n",
              "L 667.554928 440.809954 \n",
              "L 675.533048 440.554704 \n",
              "L 683.511168 440.737833 \n",
              "L 691.489288 441.433291 \n",
              "L 699.467409 442.322969 \n",
              "L 707.445529 443.203407 \n",
              "L 715.423649 443.787894 \n",
              "L 723.401769 444.109728 \n",
              "L 731.379889 444.438957 \n",
              "L 739.358009 444.400104 \n",
              "L 747.33613 444.305797 \n",
              "L 755.31425 443.63437 \n",
              "L 763.29237 443.059127 \n",
              "L 771.27049 442.467249 \n",
              "L 779.24861 441.718122 \n",
              "L 787.226731 441.213191 \n",
              "L 795.204851 441.181733 \n",
              "L 803.182971 441.486931 \n",
              "L 811.161091 441.76437 \n",
              "L 819.139211 442.22863 \n",
              "L 827.117331 442.809418 \n",
              "L 835.095452 443.029518 \n",
              "L 843.073572 443.147924 \n",
              "L 851.051692 443.216347 \n",
              "L 859.029812 443.208955 \n",
              "L 867.007932 443.306987 \n",
              "L 874.986053 443.421664 \n",
              "L 882.964173 443.488244 \n",
              "L 890.942293 443.610306 \n",
              "L 898.920413 443.663946 \n",
              "L 906.898533 443.704645 \n",
              "L 914.876654 443.693555 \n",
              "L 922.854774 443.675069 \n",
              "L 930.832894 443.64731 \n",
              "L 938.811014 443.669524 \n",
              "L 946.789134 443.688009 \n",
              "L 954.767254 443.680614 \n",
              "L 962.745375 443.68431 \n",
              "L 970.723495 443.6991 \n",
              "L 978.701615 443.710191 \n",
              "L 986.679735 443.702796 \n",
              "L 994.657855 443.69725 \n",
              "L 1002.635976 443.676919 \n",
              "L 1010.614096 443.68431 \n",
              "L 1018.592216 443.675069 \n",
              "\" clip-path=\"url(#peda403c841)\" style=\"fill: none; stroke: #d62728; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_68\">\n",
              "    <path d=\"M 77.174034 445.32309 \n",
              "L 85.152154 445.933486 \n",
              "L 93.130274 446.603032 \n",
              "L 101.108395 447.418742 \n",
              "L 109.086515 448.386091 \n",
              "L 117.064635 449.253591 \n",
              "L 125.042755 449.83068 \n",
              "L 133.020875 450.307884 \n",
              "L 140.998996 450.576082 \n",
              "L 148.977116 450.703693 \n",
              "L 156.955236 450.759179 \n",
              "L 164.933356 450.859063 \n",
              "L 172.911476 450.958947 \n",
              "L 180.889596 450.513198 \n",
              "L 188.867717 450.124755 \n",
              "L 196.845837 449.699341 \n",
              "L 204.823957 448.504461 \n",
              "L 212.802077 446.92302 \n",
              "L 220.780197 445.496949 \n",
              "L 228.758318 444.133759 \n",
              "L 236.736438 443.277385 \n",
              "L 244.714558 443.626975 \n",
              "L 252.692678 443.80268 \n",
              "L 260.670798 444.327978 \n",
              "L 268.648919 444.768183 \n",
              "L 276.627039 445.093745 \n",
              "L 284.605159 445.252814 \n",
              "L 292.583279 445.169569 \n",
              "L 300.561399 444.962406 \n",
              "L 308.539519 444.708998 \n",
              "L 316.51764 444.400104 \n",
              "L 324.49576 444.100483 \n",
              "L 332.47388 443.834138 \n",
              "L 340.452 443.652855 \n",
              "L 348.43012 443.477146 \n",
              "L 356.408241 443.358784 \n",
              "L 364.386361 443.271836 \n",
              "L 372.364481 443.273686 \n",
              "L 380.342601 443.303294 \n",
              "L 388.320721 443.327325 \n",
              "L 396.298841 443.273686 \n",
              "L 404.276962 443.173798 \n",
              "L 412.255082 443.099827 \n",
              "L 420.233202 443.044337 \n",
              "L 428.211322 442.985156 \n",
              "L 436.189442 442.787237 \n",
              "L 444.167563 442.422857 \n",
              "L 452.145683 442.036289 \n",
              "L 460.123803 441.777339 \n",
              "L 468.101923 441.518382 \n",
              "L 476.080043 441.331561 \n",
              "L 484.058164 441.239072 \n",
              "L 492.036284 441.281613 \n",
              "L 500.014404 441.438833 \n",
              "L 507.992524 441.63306 \n",
              "L 515.970644 441.912342 \n",
              "L 523.948764 442.156509 \n",
              "L 531.926885 442.432098 \n",
              "L 539.905005 442.691048 \n",
              "L 547.883125 442.966638 \n",
              "L 555.861245 443.208955 \n",
              "L 563.839365 443.454936 \n",
              "L 571.817486 443.689859 \n",
              "L 579.795606 444.061634 \n",
              "L 587.773726 444.327978 \n",
              "L 595.751846 444.834795 \n",
              "L 603.729966 445.877997 \n",
              "L 611.708086 446.819436 \n",
              "L 619.686207 447.975467 \n",
              "L 627.664327 449.114857 \n",
              "L 635.642447 450.048934 \n",
              "L 643.620567 450.835032 \n",
              "L 651.598687 451.641466 \n",
              "L 659.576808 452.050244 \n",
              "L 667.554928 451.317785 \n",
              "L 675.533048 451.278932 \n",
              "L 683.511168 450.511348 \n",
              "L 691.489288 449.212892 \n",
              "L 699.467409 448.029106 \n",
              "L 707.445529 446.691825 \n",
              "L 715.423649 445.367488 \n",
              "L 723.401769 444.239188 \n",
              "L 731.379889 443.506726 \n",
              "L 739.358009 442.642958 \n",
              "L 747.33613 442.663289 \n",
              "L 755.31425 442.763177 \n",
              "L 763.29237 443.064676 \n",
              "L 771.27049 443.432755 \n",
              "L 779.24861 443.719435 \n",
              "L 787.226731 443.725009 \n",
              "L 795.204851 443.636219 \n",
              "L 803.182971 443.604761 \n",
              "L 811.161091 443.667674 \n",
              "L 819.139211 443.610306 \n",
              "L 827.117331 443.458664 \n",
              "L 835.095452 443.349507 \n",
              "L 843.073572 443.258896 \n",
              "L 851.051692 443.164557 \n",
              "L 859.029812 443.046187 \n",
              "L 867.007932 443.001795 \n",
              "L 874.986053 442.970337 \n",
              "L 882.964173 442.966638 \n",
              "L 890.942293 442.988855 \n",
              "L 898.920413 443.060977 \n",
              "L 906.898533 443.192287 \n",
              "L 914.876654 443.331025 \n",
              "L 922.854774 443.488244 \n",
              "L 930.832894 443.656551 \n",
              "L 938.811014 443.784194 \n",
              "L 946.789134 443.878533 \n",
              "L 954.767254 443.902564 \n",
              "L 962.745375 443.876655 \n",
              "L 970.723495 443.834138 \n",
              "L 978.701615 443.774953 \n",
              "L 986.679735 443.6991 \n",
              "L 994.657855 443.617734 \n",
              "L 1002.635976 443.578884 \n",
              "L 1010.614096 443.584426 \n",
              "L 1018.592216 443.569636 \n",
              "\" clip-path=\"url(#peda403c841)\" style=\"fill: none; stroke: #9467bd; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_69\">\n",
              "    <path d=\"M 77.174034 443.793439 \n",
              "L 85.152154 443.027676 \n",
              "L 93.130274 442.056621 \n",
              "L 101.108395 440.969024 \n",
              "L 109.086515 439.726086 \n",
              "L 117.064635 438.361042 \n",
              "L 125.042755 437.099586 \n",
              "L 133.020875 435.995349 \n",
              "L 140.998996 434.981723 \n",
              "L 148.977116 434.053224 \n",
              "L 156.955236 433.280066 \n",
              "L 164.933356 432.62715 \n",
              "L 172.911476 432.142522 \n",
              "L 180.889596 431.815142 \n",
              "L 188.867717 431.511794 \n",
              "L 196.845837 431.428574 \n",
              "L 204.823957 431.706013 \n",
              "L 212.802077 432.349682 \n",
              "L 220.780197 433.161697 \n",
              "L 228.758318 433.888613 \n",
              "L 236.736438 435.2518 \n",
              "L 244.714558 437.132865 \n",
              "L 252.692678 438.386923 \n",
              "L 260.670798 439.587348 \n",
              "L 268.648919 440.645344 \n",
              "L 276.627039 441.573871 \n",
              "L 284.605159 442.43949 \n",
              "L 292.583279 443.277385 \n",
              "L 300.561399 444.076423 \n",
              "L 308.539519 444.862522 \n",
              "L 316.51764 445.661564 \n",
              "L 324.49576 446.501301 \n",
              "L 332.47388 447.376193 \n",
              "L 340.452 448.293601 \n",
              "L 348.43012 449.244347 \n",
              "L 356.408241 450.146969 \n",
              "L 364.386361 450.979283 \n",
              "L 372.364481 451.757989 \n",
              "L 380.342601 452.433113 \n",
              "L 388.320721 453.021295 \n",
              "L 396.298841 453.555835 \n",
              "L 404.276962 454.005312 \n",
              "L 412.255082 454.323451 \n",
              "L 420.233202 454.549097 \n",
              "L 428.211322 454.608282 \n",
              "L 436.189442 454.50658 \n",
              "L 444.167563 454.404846 \n",
              "L 452.145683 454.391877 \n",
              "L 460.123803 454.340087 \n",
              "L 468.101923 454.267962 \n",
              "L 476.080043 454.094106 \n",
              "L 484.058164 453.726027 \n",
              "L 492.036284 453.160029 \n",
              "L 500.014404 452.360987 \n",
              "L 507.992524 451.249356 \n",
              "L 515.970644 449.913896 \n",
              "L 523.948764 448.539615 \n",
              "L 531.926885 447.185669 \n",
              "L 539.905005 446.081432 \n",
              "L 547.883125 445.17881 \n",
              "L 555.861245 444.333527 \n",
              "L 563.839365 443.436454 \n",
              "L 571.817486 442.435798 \n",
              "L 579.795606 441.259432 \n",
              "L 587.773726 440.160744 \n",
              "L 595.751846 438.932589 \n",
              "L 603.729966 437.188347 \n",
              "L 611.708086 435.519991 \n",
              "L 619.686207 433.879336 \n",
              "L 627.664327 432.53836 \n",
              "L 635.642447 431.554343 \n",
              "L 643.620567 430.734965 \n",
              "L 651.598687 430.220757 \n",
              "L 659.576808 430.135667 \n",
              "L 667.554928 430.218908 \n",
              "L 675.533048 430.457497 \n",
              "L 683.511168 431.014254 \n",
              "L 691.489288 431.815142 \n",
              "L 699.467409 432.643789 \n",
              "L 707.445529 433.411405 \n",
              "L 715.423649 433.999585 \n",
              "L 723.401769 434.621072 \n",
              "L 731.379889 435.090852 \n",
              "L 739.358009 435.945409 \n",
              "L 747.33613 437.963362 \n",
              "L 755.31425 439.335789 \n",
              "L 763.29237 440.815503 \n",
              "L 771.27049 442.173148 \n",
              "L 779.24861 443.347657 \n",
              "L 787.226731 444.422317 \n",
              "L 795.204851 445.363789 \n",
              "L 803.182971 446.016702 \n",
              "L 811.161091 446.290442 \n",
              "L 819.139211 446.355201 \n",
              "L 827.117331 446.329292 \n",
              "L 835.095452 446.136918 \n",
              "L 843.073572 445.826207 \n",
              "L 851.051692 445.49325 \n",
              "L 859.029812 445.202874 \n",
              "L 867.007932 444.992015 \n",
              "L 874.986053 444.807036 \n",
              "L 882.964173 444.622086 \n",
              "L 890.942293 444.444502 \n",
              "L 898.920413 444.278038 \n",
              "L 906.898533 444.124514 \n",
              "L 914.876654 443.987659 \n",
              "L 922.854774 443.861865 \n",
              "L 930.832894 443.734254 \n",
              "L 938.811014 443.623279 \n",
              "L 946.789134 443.525244 \n",
              "L 954.767254 443.471605 \n",
              "L 962.745375 443.464206 \n",
              "L 970.723495 443.482695 \n",
              "L 978.701615 443.516003 \n",
              "L 986.679735 443.532636 \n",
              "L 994.657855 443.545576 \n",
              "L 1002.635976 443.545576 \n",
              "L 1010.614096 443.538185 \n",
              "L 1018.592216 443.527094 \n",
              "\" clip-path=\"url(#peda403c841)\" style=\"fill: none; stroke: #8c564b; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_15\">\n",
              "    <path d=\"M 30.103125 510.258125 \n",
              "L 30.103125 376.918125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_16\">\n",
              "    <path d=\"M 1065.663125 510.258125 \n",
              "L 1065.663125 376.918125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_17\">\n",
              "    <path d=\"M 30.103125 510.258125 \n",
              "L 1065.663125 510.258125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_18\">\n",
              "    <path d=\"M 30.103125 376.918125 \n",
              "L 1065.663125 376.918125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"text_54\">\n",
              "    <!-- Sample 70 Class:['AvadaKedavra'] -->\n",
              "    <g transform=\"translate(445.177187 370.918125) scale(0.12 -0.12)\">\n",
              "     <defs>\n",
              "      <path id=\"DejaVuSans-37\" d=\"M 525 4666 \n",
              "L 3525 4666 \n",
              "L 3525 4397 \n",
              "L 1831 0 \n",
              "L 1172 0 \n",
              "L 2766 4134 \n",
              "L 525 4134 \n",
              "L 525 4666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "     </defs>\n",
              "     <use xlink:href=\"#DejaVuSans-53\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"63.476562\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6d\" x=\"124.755859\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-70\" x=\"222.167969\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6c\" x=\"285.644531\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-65\" x=\"313.427734\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-20\" x=\"374.951172\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-37\" x=\"406.738281\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-30\" x=\"470.361328\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-20\" x=\"533.984375\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-43\" x=\"565.771484\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6c\" x=\"635.595703\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"663.378906\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-73\" x=\"724.658203\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-73\" x=\"776.757812\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-3a\" x=\"828.857422\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-5b\" x=\"862.548828\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-27\" x=\"901.5625\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-41\" x=\"929.052734\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-76\" x=\"991.585938\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"1050.765625\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-64\" x=\"1112.044922\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"1175.521484\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-4b\" x=\"1236.800781\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-65\" x=\"1297.376953\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-64\" x=\"1358.900391\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"1422.376953\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-76\" x=\"1483.65625\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-72\" x=\"1542.835938\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"1583.949219\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-27\" x=\"1645.228516\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-5d\" x=\"1672.71875\"/>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"legend_3\">\n",
              "    <g id=\"patch_19\">\n",
              "     <path d=\"M 37.103125 472.986875 \n",
              "L 114.742188 472.986875 \n",
              "Q 116.742188 472.986875 116.742188 470.986875 \n",
              "L 116.742188 383.918125 \n",
              "Q 116.742188 381.918125 114.742188 381.918125 \n",
              "L 37.103125 381.918125 \n",
              "Q 35.103125 381.918125 35.103125 383.918125 \n",
              "L 35.103125 470.986875 \n",
              "Q 35.103125 472.986875 37.103125 472.986875 \n",
              "z\n",
              "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
              "    </g>\n",
              "    <g id=\"line2d_70\">\n",
              "     <path d=\"M 39.103125 390.016562 \n",
              "L 49.103125 390.016562 \n",
              "L 59.103125 390.016562 \n",
              "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_55\">\n",
              "     <!-- feature 1 -->\n",
              "     <g transform=\"translate(67.103125 393.516562) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-31\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_71\">\n",
              "     <path d=\"M 39.103125 404.694687 \n",
              "L 49.103125 404.694687 \n",
              "L 59.103125 404.694687 \n",
              "\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_56\">\n",
              "     <!-- feature 2 -->\n",
              "     <g transform=\"translate(67.103125 408.194687) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-32\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_72\">\n",
              "     <path d=\"M 39.103125 419.372812 \n",
              "L 49.103125 419.372812 \n",
              "L 59.103125 419.372812 \n",
              "\" style=\"fill: none; stroke: #2ca02c; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_57\">\n",
              "     <!-- feature 3 -->\n",
              "     <g transform=\"translate(67.103125 422.872812) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-33\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_73\">\n",
              "     <path d=\"M 39.103125 434.050937 \n",
              "L 49.103125 434.050937 \n",
              "L 59.103125 434.050937 \n",
              "\" style=\"fill: none; stroke: #d62728; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_58\">\n",
              "     <!-- feature 4 -->\n",
              "     <g transform=\"translate(67.103125 437.550937) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-34\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_74\">\n",
              "     <path d=\"M 39.103125 448.729062 \n",
              "L 49.103125 448.729062 \n",
              "L 59.103125 448.729062 \n",
              "\" style=\"fill: none; stroke: #9467bd; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_59\">\n",
              "     <!-- feature 5 -->\n",
              "     <g transform=\"translate(67.103125 452.229062) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-35\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_75\">\n",
              "     <path d=\"M 39.103125 463.407187 \n",
              "L 49.103125 463.407187 \n",
              "L 59.103125 463.407187 \n",
              "\" style=\"fill: none; stroke: #8c564b; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_60\">\n",
              "     <!-- feature 6 -->\n",
              "     <g transform=\"translate(67.103125 466.907187) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-36\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "  </g>\n",
              "  <g id=\"axes_4\">\n",
              "   <g id=\"patch_20\">\n",
              "    <path d=\"M 30.103125 687.558125 \n",
              "L 1065.663125 687.558125 \n",
              "L 1065.663125 554.218125 \n",
              "L 30.103125 554.218125 \n",
              "z\n",
              "\" style=\"fill: #ffffff\"/>\n",
              "   </g>\n",
              "   <g id=\"matplotlib.axis_7\">\n",
              "    <g id=\"xtick_22\">\n",
              "     <g id=\"line2d_76\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"77.174034\" y=\"687.558125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_61\">\n",
              "      <!-- 0 -->\n",
              "      <g transform=\"translate(73.992784 702.156562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_23\">\n",
              "     <g id=\"line2d_77\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"236.736438\" y=\"687.558125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_62\">\n",
              "      <!-- 20 -->\n",
              "      <g transform=\"translate(230.373938 702.156562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_24\">\n",
              "     <g id=\"line2d_78\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"396.298841\" y=\"687.558125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_63\">\n",
              "      <!-- 40 -->\n",
              "      <g transform=\"translate(389.936341 702.156562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_25\">\n",
              "     <g id=\"line2d_79\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"555.861245\" y=\"687.558125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_64\">\n",
              "      <!-- 60 -->\n",
              "      <g transform=\"translate(549.498745 702.156562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_26\">\n",
              "     <g id=\"line2d_80\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"715.423649\" y=\"687.558125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_65\">\n",
              "      <!-- 80 -->\n",
              "      <g transform=\"translate(709.061149 702.156562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_27\">\n",
              "     <g id=\"line2d_81\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"874.986053\" y=\"687.558125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_66\">\n",
              "      <!-- 100 -->\n",
              "      <g transform=\"translate(865.442303 702.156562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"xtick_28\">\n",
              "     <g id=\"line2d_82\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m75345596d3\" x=\"1034.548456\" y=\"687.558125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_67\">\n",
              "      <!-- 120 -->\n",
              "      <g transform=\"translate(1025.004706 702.156562) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"matplotlib.axis_8\">\n",
              "    <g id=\"ytick_19\">\n",
              "     <g id=\"line2d_83\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"681.497216\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_68\">\n",
              "      <!-- 0.0 -->\n",
              "      <g transform=\"translate(7.2 685.296435) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_20\">\n",
              "     <g id=\"line2d_84\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"657.25358\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_69\">\n",
              "      <!-- 0.2 -->\n",
              "      <g transform=\"translate(7.2 661.052798) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_21\">\n",
              "     <g id=\"line2d_85\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"633.009943\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_70\">\n",
              "      <!-- 0.4 -->\n",
              "      <g transform=\"translate(7.2 636.809162) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_22\">\n",
              "     <g id=\"line2d_86\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"608.766307\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_71\">\n",
              "      <!-- 0.6 -->\n",
              "      <g transform=\"translate(7.2 612.565526) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_23\">\n",
              "     <g id=\"line2d_87\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"584.52267\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_72\">\n",
              "      <!-- 0.8 -->\n",
              "      <g transform=\"translate(7.2 588.321889) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"ytick_24\">\n",
              "     <g id=\"line2d_88\">\n",
              "      <g>\n",
              "       <use xlink:href=\"#m953c48f76d\" x=\"30.103125\" y=\"560.279034\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "     <g id=\"text_73\">\n",
              "      <!-- 1.0 -->\n",
              "      <g transform=\"translate(7.2 564.078253) scale(0.1 -0.1)\">\n",
              "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
              "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
              "      </g>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"line2d_89\">\n",
              "    <path d=\"M 77.174034 599.765856 \n",
              "L 85.152154 596.780858 \n",
              "L 93.130274 595.023199 \n",
              "L 101.108395 593.553427 \n",
              "L 109.086515 593.417051 \n",
              "L 117.064635 594.811061 \n",
              "L 125.042755 597.84152 \n",
              "L 133.020875 602.220527 \n",
              "L 140.998996 606.932882 \n",
              "L 148.977116 611.372501 \n",
              "L 156.955236 614.690847 \n",
              "L 164.933356 617.797061 \n",
              "L 172.911476 618.888025 \n",
              "L 180.889596 620.19112 \n",
              "L 188.867717 621.054799 \n",
              "L 196.845837 621.524521 \n",
              "L 204.823957 621.857869 \n",
              "L 212.802077 621.979089 \n",
              "L 220.780197 621.963938 \n",
              "L 228.758318 621.933632 \n",
              "L 236.736438 621.842718 \n",
              "L 244.714558 621.948783 \n",
              "L 252.692678 621.857869 \n",
              "L 260.670798 621.721501 \n",
              "L 268.648919 621.463913 \n",
              "L 276.627039 621.282084 \n",
              "L 284.605159 621.176019 \n",
              "L 292.583279 620.751757 \n",
              "L 300.561399 620.3881 \n",
              "L 308.539519 620.024443 \n",
              "L 316.51764 619.554728 \n",
              "L 324.49576 618.918328 \n",
              "L 332.47388 618.372849 \n",
              "L 340.452 618.024343 \n",
              "L 348.43012 617.872825 \n",
              "L 356.408241 617.842515 \n",
              "L 364.386361 618.084955 \n",
              "L 372.364481 618.372849 \n",
              "L 380.342601 618.812262 \n",
              "L 388.320721 619.175919 \n",
              "L 396.298841 619.448662 \n",
              "L 404.276962 619.812312 \n",
              "L 412.255082 619.797161 \n",
              "L 420.233202 619.918378 \n",
              "L 428.211322 619.736549 \n",
              "L 436.189442 619.58503 \n",
              "L 444.167563 619.539569 \n",
              "L 452.145683 619.100156 \n",
              "L 460.123803 618.78196 \n",
              "L 468.101923 618.100107 \n",
              "L 476.080043 617.221273 \n",
              "L 484.058164 616.130309 \n",
              "L 492.036284 614.630235 \n",
              "L 500.014404 613.175621 \n",
              "L 507.992524 611.417955 \n",
              "L 515.970644 609.690598 \n",
              "L 523.948764 607.87232 \n",
              "L 531.926885 606.387403 \n",
              "L 539.905005 605.129762 \n",
              "L 547.883125 604.0691 \n",
              "L 555.861245 603.326642 \n",
              "L 563.839365 602.917532 \n",
              "L 571.817486 602.811466 \n",
              "L 579.795606 603.053899 \n",
              "L 587.773726 603.432708 \n",
              "L 595.751846 603.826667 \n",
              "L 603.729966 604.584276 \n",
              "L 611.708086 605.67524 \n",
              "L 619.686207 606.372245 \n",
              "L 627.664327 607.220776 \n",
              "L 635.642447 608.160214 \n",
              "L 643.620567 609.463309 \n",
              "L 651.598687 610.539121 \n",
              "L 659.576808 612.145261 \n",
              "L 667.554928 613.448356 \n",
              "L 675.533048 614.781761 \n",
              "L 683.511168 616.387901 \n",
              "L 691.489288 618.236474 \n",
              "L 699.467409 620.175969 \n",
              "L 707.445529 622.403351 \n",
              "L 715.423649 624.873173 \n",
              "L 723.401769 627.388448 \n",
              "L 731.379889 629.403703 \n",
              "L 739.358009 630.267381 \n",
              "L 747.33613 630.373447 \n",
              "L 755.31425 629.691597 \n",
              "L 763.29237 628.691547 \n",
              "L 771.27049 628.494567 \n",
              "L 779.24861 628.146065 \n",
              "L 787.226731 627.570277 \n",
              "L 795.204851 626.070202 \n",
              "L 803.182971 623.054898 \n",
              "L 811.161091 620.539626 \n",
              "L 819.139211 618.206172 \n",
              "L 827.117331 616.130309 \n",
              "L 835.095452 613.796862 \n",
              "L 843.073572 611.705849 \n",
              "L 851.051692 609.796663 \n",
              "L 859.029812 608.220826 \n",
              "L 867.007932 606.735902 \n",
              "L 874.986053 605.67524 \n",
              "L 882.964173 605.205525 \n",
              "L 890.942293 605.008545 \n",
              "L 898.920413 605.326742 \n",
              "L 906.898533 605.841918 \n",
              "L 914.876654 606.538922 \n",
              "L 922.854774 607.129861 \n",
              "L 930.832894 607.720801 \n",
              "L 938.811014 608.11476 \n",
              "L 946.789134 608.296589 \n",
              "L 954.767254 608.266279 \n",
              "L 962.745375 608.31174 \n",
              "L 970.723495 608.357193 \n",
              "L 978.701615 608.326891 \n",
              "L 986.679735 608.251128 \n",
              "L 994.657855 608.008695 \n",
              "L 1002.635976 607.842017 \n",
              "L 1010.614096 607.614735 \n",
              "L 1018.592216 607.281388 \n",
              "\" clip-path=\"url(#pf584ed0481)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_90\">\n",
              "    <path d=\"M 77.174034 627.827865 \n",
              "L 85.152154 623.933731 \n",
              "L 93.130274 616.97884 \n",
              "L 101.108395 609.281487 \n",
              "L 109.086515 601.993238 \n",
              "L 117.064635 598.311242 \n",
              "L 125.042755 597.886973 \n",
              "L 133.020875 600.084052 \n",
              "L 140.998996 602.569026 \n",
              "L 148.977116 603.932732 \n",
              "L 156.955236 604.023647 \n",
              "L 164.933356 604.29639 \n",
              "L 172.911476 604.538823 \n",
              "L 180.889596 605.887378 \n",
              "L 188.867717 608.251128 \n",
              "L 196.845837 611.054297 \n",
              "L 204.823957 613.690797 \n",
              "L 212.802077 616.493966 \n",
              "L 220.780197 618.918328 \n",
              "L 228.758318 620.872974 \n",
              "L 236.736438 622.842767 \n",
              "L 244.714558 626.130811 \n",
              "L 252.692678 630.994692 \n",
              "L 260.670798 635.767659 \n",
              "L 268.648919 638.419306 \n",
              "L 276.627039 638.419306 \n",
              "L 284.605159 636.085855 \n",
              "L 292.583279 633.312988 \n",
              "L 300.561399 630.964386 \n",
              "L 308.539519 629.146115 \n",
              "L 316.51764 627.191469 \n",
              "L 324.49576 625.52472 \n",
              "L 332.47388 625.221675 \n",
              "L 340.452 626.297488 \n",
              "L 348.43012 628.024845 \n",
              "L 356.408241 630.509818 \n",
              "L 364.386361 634.46456 \n",
              "L 372.364481 638.737502 \n",
              "L 380.342601 642.101308 \n",
              "L 388.320721 645.040849 \n",
              "L 396.298841 647.086406 \n",
              "L 404.276962 647.753105 \n",
              "L 412.255082 646.010593 \n",
              "L 420.233202 642.798313 \n",
              "L 428.211322 641.025495 \n",
              "L 436.189442 642.010394 \n",
              "L 444.167563 644.874172 \n",
              "L 452.145683 645.32874 \n",
              "L 460.123803 642.949835 \n",
              "L 468.101923 637.858669 \n",
              "L 476.080043 629.555225 \n",
              "L 484.058164 620.418402 \n",
              "L 492.036284 613.342291 \n",
              "L 500.014404 606.87227 \n",
              "L 507.992524 599.523423 \n",
              "L 515.970644 594.583779 \n",
              "L 523.948764 590.522968 \n",
              "L 531.926885 587.34099 \n",
              "L 539.905005 584.265085 \n",
              "L 547.883125 580.992192 \n",
              "L 555.861245 579.067849 \n",
              "L 563.839365 579.598183 \n",
              "L 571.817486 581.174021 \n",
              "L 579.795606 581.674046 \n",
              "L 587.773726 581.52252 \n",
              "L 595.751846 581.734651 \n",
              "L 603.729966 581.719499 \n",
              "L 611.708086 581.977091 \n",
              "L 619.686207 581.749802 \n",
              "L 627.664327 581.158863 \n",
              "L 635.642447 579.689098 \n",
              "L 643.620567 577.885978 \n",
              "L 651.598687 576.810165 \n",
              "L 659.576808 577.91628 \n",
              "L 667.554928 579.098158 \n",
              "L 675.533048 579.340592 \n",
              "L 683.511168 578.810264 \n",
              "L 691.489288 578.446607 \n",
              "L 699.467409 577.704149 \n",
              "L 707.445529 577.7193 \n",
              "L 715.423649 581.916479 \n",
              "L 723.401769 592.689745 \n",
              "L 731.379889 607.538972 \n",
              "L 739.358009 621.009342 \n",
              "L 747.33613 632.025044 \n",
              "L 755.31425 641.964937 \n",
              "L 763.29237 650.480515 \n",
              "L 771.27049 658.268782 \n",
              "L 779.24861 666.799511 \n",
              "L 787.226731 678.633436 \n",
              "L 795.204851 681.497216 \n",
              "L 803.182971 681.497216 \n",
              "L 811.161091 681.497216 \n",
              "L 819.139211 681.497216 \n",
              "L 827.117331 671.769457 \n",
              "L 835.095452 657.435406 \n",
              "L 843.073572 644.146865 \n",
              "L 851.051692 630.206773 \n",
              "L 859.029812 617.327339 \n",
              "L 867.007932 609.129961 \n",
              "L 874.986053 604.160015 \n",
              "L 882.964173 602.705401 \n",
              "L 890.942293 603.311491 \n",
              "L 898.920413 606.31164 \n",
              "L 906.898533 610.508819 \n",
              "L 914.876654 613.13016 \n",
              "L 922.854774 615.13026 \n",
              "L 930.832894 618.130409 \n",
              "L 938.811014 620.812362 \n",
              "L 946.789134 621.766958 \n",
              "L 954.767254 621.99424 \n",
              "L 962.745375 622.706396 \n",
              "L 970.723495 624.433756 \n",
              "L 978.701615 626.11566 \n",
              "L 986.679735 627.115709 \n",
              "L 994.657855 627.433906 \n",
              "L 1002.635976 626.812664 \n",
              "L 1010.614096 624.91863 \n",
              "L 1018.592216 621.842718 \n",
              "\" clip-path=\"url(#pf584ed0481)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_91\">\n",
              "    <path d=\"M 77.174034 576.294989 \n",
              "L 85.152154 560.279034 \n",
              "L 93.130274 560.279034 \n",
              "L 101.108395 560.279034 \n",
              "L 109.086515 560.279034 \n",
              "L 117.064635 560.279034 \n",
              "L 125.042755 560.279034 \n",
              "L 133.020875 560.279034 \n",
              "L 140.998996 565.461111 \n",
              "L 148.977116 582.371051 \n",
              "L 156.955236 597.720303 \n",
              "L 164.933356 614.660544 \n",
              "L 172.911476 624.842867 \n",
              "L 180.889596 632.312938 \n",
              "L 188.867717 637.631387 \n",
              "L 196.845837 641.040647 \n",
              "L 204.823957 644.162016 \n",
              "L 212.802077 646.146964 \n",
              "L 220.780197 646.813663 \n",
              "L 228.758318 646.813663 \n",
              "L 236.736438 645.843919 \n",
              "L 244.714558 643.661991 \n",
              "L 252.692678 641.813414 \n",
              "L 260.670798 640.661842 \n",
              "L 268.648919 638.025346 \n",
              "L 276.627039 633.631188 \n",
              "L 284.605159 630.888626 \n",
              "L 292.583279 630.661341 \n",
              "L 300.561399 630.494667 \n",
              "L 308.539519 629.827965 \n",
              "L 316.51764 629.524919 \n",
              "L 324.49576 630.555275 \n",
              "L 332.47388 631.070451 \n",
              "L 340.452 631.267431 \n",
              "L 348.43012 632.343244 \n",
              "L 356.408241 632.97964 \n",
              "L 364.386361 632.115958 \n",
              "L 372.364481 629.827965 \n",
              "L 380.342601 626.388399 \n",
              "L 388.320721 622.691245 \n",
              "L 396.298841 619.206222 \n",
              "L 404.276962 616.130309 \n",
              "L 412.255082 613.008943 \n",
              "L 420.233202 610.099708 \n",
              "L 428.211322 607.463209 \n",
              "L 436.189442 604.553974 \n",
              "L 444.167563 600.008296 \n",
              "L 452.145683 595.765657 \n",
              "L 460.123803 592.007891 \n",
              "L 468.101923 588.734999 \n",
              "L 476.080043 586.58338 \n",
              "L 484.058164 585.56818 \n",
              "L 492.036284 584.522669 \n",
              "L 500.014404 586.310638 \n",
              "L 507.992524 590.477514 \n",
              "L 515.970644 597.220278 \n",
              "L 523.948764 603.06905 \n",
              "L 531.926885 608.008695 \n",
              "L 539.905005 612.402853 \n",
              "L 547.883125 617.403102 \n",
              "L 555.861245 622.024546 \n",
              "L 563.839365 624.751956 \n",
              "L 571.817486 625.11561 \n",
              "L 579.795606 624.676193 \n",
              "L 587.773726 624.676193 \n",
              "L 595.751846 624.070103 \n",
              "L 603.729966 622.160918 \n",
              "L 611.708086 621.236627 \n",
              "L 619.686207 621.691195 \n",
              "L 627.664327 623.91858 \n",
              "L 635.642447 624.706499 \n",
              "L 643.620567 623.767058 \n",
              "L 651.598687 624.388299 \n",
              "L 659.576808 623.130661 \n",
              "L 667.554928 619.660793 \n",
              "L 675.533048 617.251583 \n",
              "L 683.511168 616.645485 \n",
              "L 691.489288 617.524319 \n",
              "L 699.467409 619.38805 \n",
              "L 707.445529 618.766809 \n",
              "L 715.423649 614.554472 \n",
              "L 723.401769 608.902679 \n",
              "L 731.379889 604.796414 \n",
              "L 739.358009 602.175066 \n",
              "L 747.33613 601.326543 \n",
              "L 755.31425 599.993138 \n",
              "L 763.29237 594.40195 \n",
              "L 771.27049 582.310439 \n",
              "L 779.24861 568.44611 \n",
              "L 787.226731 562.83977 \n",
              "L 795.204851 568.491563 \n",
              "L 803.182971 577.188973 \n",
              "L 811.161091 586.234875 \n",
              "L 819.139211 593.659492 \n",
              "L 827.117331 598.629438 \n",
              "L 835.095452 603.190267 \n",
              "L 843.073572 606.826816 \n",
              "L 851.051692 608.751153 \n",
              "L 859.029812 611.296738 \n",
              "L 867.007932 614.205973 \n",
              "L 874.986053 618.706197 \n",
              "L 882.964173 622.888225 \n",
              "L 890.942293 627.342995 \n",
              "L 898.920413 629.93403 \n",
              "L 906.898533 629.040049 \n",
              "L 914.876654 627.282383 \n",
              "L 922.854774 624.858022 \n",
              "L 930.832894 622.11546 \n",
              "L 938.811014 620.221423 \n",
              "L 946.789134 619.009242 \n",
              "L 954.767254 618.812262 \n",
              "L 962.745375 618.494066 \n",
              "L 970.723495 617.130359 \n",
              "L 978.701615 616.115158 \n",
              "L 986.679735 615.145411 \n",
              "L 994.657855 614.630235 \n",
              "L 1002.635976 614.387802 \n",
              "L 1010.614096 613.978691 \n",
              "L 1018.592216 613.069555 \n",
              "\" clip-path=\"url(#pf584ed0481)\" style=\"fill: none; stroke: #2ca02c; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_92\">\n",
              "    <path d=\"M 77.174034 620.496015 \n",
              "L 85.152154 620.579227 \n",
              "L 93.130274 620.588476 \n",
              "L 101.108395 620.532986 \n",
              "L 109.086515 620.629175 \n",
              "L 117.064635 620.734605 \n",
              "L 125.042755 620.899216 \n",
              "L 133.020875 621.045345 \n",
              "L 140.998996 621.182229 \n",
              "L 148.977116 621.370878 \n",
              "L 156.955236 621.563248 \n",
              "L 164.933356 621.615042 \n",
              "L 172.911476 621.618737 \n",
              "L 180.889596 621.522552 \n",
              "L 188.867717 621.431909 \n",
              "L 196.845837 621.224749 \n",
              "L 204.823957 621.098984 \n",
              "L 212.802077 620.989859 \n",
              "L 220.780197 620.847426 \n",
              "L 228.758318 620.719815 \n",
              "L 236.736438 620.594017 \n",
              "L 244.714558 620.503407 \n",
              "L 252.692678 620.525595 \n",
              "L 260.670798 620.605144 \n",
              "L 268.648919 620.610686 \n",
              "L 276.627039 620.623626 \n",
              "L 284.605159 620.655084 \n",
              "L 292.583279 620.710574 \n",
              "L 300.561399 620.814154 \n",
              "L 308.539519 620.93437 \n",
              "L 316.51764 621.045345 \n",
              "L 324.49576 621.128593 \n",
              "L 332.47388 621.171109 \n",
              "L 340.452 621.163715 \n",
              "L 348.43012 621.08974 \n",
              "L 356.408241 620.965796 \n",
              "L 364.386361 620.816003 \n",
              "L 372.364481 620.640266 \n",
              "L 380.342601 620.501557 \n",
              "L 388.320721 620.388736 \n",
              "L 396.298841 620.264788 \n",
              "L 404.276962 620.102027 \n",
              "L 412.255082 619.9078 \n",
              "L 420.233202 619.676609 \n",
              "L 428.211322 619.432449 \n",
              "L 436.189442 619.20495 \n",
              "L 444.167563 619.068062 \n",
              "L 452.145683 618.890511 \n",
              "L 460.123803 618.72405 \n",
              "L 468.101923 618.622313 \n",
              "L 476.080043 618.574222 \n",
              "L 484.058164 618.633403 \n",
              "L 492.036284 618.822081 \n",
              "L 500.014404 619.025549 \n",
              "L 507.992524 619.143919 \n",
              "L 515.970644 619.312229 \n",
              "L 523.948764 619.45281 \n",
              "L 531.926885 619.511998 \n",
              "L 539.905005 619.389929 \n",
              "L 547.883125 619.03849 \n",
              "L 555.861245 618.897902 \n",
              "L 563.839365 618.981151 \n",
              "L 571.817486 619.084731 \n",
              "L 579.795606 619.164251 \n",
              "L 587.773726 619.339989 \n",
              "L 595.751846 619.585969 \n",
              "L 603.729966 619.846769 \n",
              "L 611.708086 620.170449 \n",
              "L 619.686207 620.568137 \n",
              "L 627.664327 620.943614 \n",
              "L 635.642447 621.250659 \n",
              "L 643.620567 621.537339 \n",
              "L 651.598687 621.812961 \n",
              "L 659.576808 622.07561 \n",
              "L 667.554928 622.432566 \n",
              "L 675.533048 622.734065 \n",
              "L 683.511168 623.030018 \n",
              "L 691.489288 623.377733 \n",
              "L 699.467409 623.749511 \n",
              "L 707.445529 624.14165 \n",
              "L 715.423649 624.592945 \n",
              "L 723.401769 625.129366 \n",
              "L 731.379889 625.684245 \n",
              "L 739.358009 626.004229 \n",
              "L 747.33613 626.218784 \n",
              "L 755.31425 626.248393 \n",
              "L 763.29237 625.810039 \n",
              "L 771.27049 625.345771 \n",
              "L 779.24861 625.083122 \n",
              "L 787.226731 625.097912 \n",
              "L 795.204851 625.112702 \n",
              "L 803.182971 625.323557 \n",
              "L 811.161091 624.0658 \n",
              "L 819.139211 622.874648 \n",
              "L 827.117331 622.404836 \n",
              "L 835.095452 621.768562 \n",
              "L 843.073572 620.788244 \n",
              "L 851.051692 619.835678 \n",
              "L 859.029812 619.230831 \n",
              "L 867.007932 619.85601 \n",
              "L 874.986053 620.185275 \n",
              "L 882.964173 620.427557 \n",
              "L 890.942293 620.453466 \n",
              "L 898.920413 620.416466 \n",
              "L 906.898533 620.336946 \n",
              "L 914.876654 620.225938 \n",
              "L 922.854774 620.137177 \n",
              "L 930.832894 620.209306 \n",
              "L 938.811014 620.407225 \n",
              "L 946.789134 620.569986 \n",
              "L 954.767254 620.653235 \n",
              "L 962.745375 620.725356 \n",
              "L 970.723495 620.771605 \n",
              "L 978.701615 620.808576 \n",
              "L 986.679735 620.841877 \n",
              "L 994.657855 620.871485 \n",
              "L 1002.635976 620.917734 \n",
              "L 1010.614096 620.96025 \n",
              "L 1018.592216 620.971373 \n",
              "\" clip-path=\"url(#pf584ed0481)\" style=\"fill: none; stroke: #d62728; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_93\">\n",
              "    <path d=\"M 77.174034 625.010968 \n",
              "L 85.152154 624.809382 \n",
              "L 93.130274 623.174269 \n",
              "L 101.108395 621.783352 \n",
              "L 109.086515 620.146418 \n",
              "L 117.064635 618.444761 \n",
              "L 125.042755 616.826317 \n",
              "L 133.020875 615.372483 \n",
              "L 140.998996 614.029664 \n",
              "L 148.977116 613.017881 \n",
              "L 156.955236 612.339091 \n",
              "L 164.933356 611.541873 \n",
              "L 172.911476 611.791582 \n",
              "L 180.889596 612.679411 \n",
              "L 188.867717 613.08449 \n",
              "L 196.845837 613.781798 \n",
              "L 204.823957 614.360736 \n",
              "L 212.802077 615.045104 \n",
              "L 220.780197 615.86451 \n",
              "L 228.758318 616.643188 \n",
              "L 236.736438 617.364556 \n",
              "L 244.714558 618.061864 \n",
              "L 252.692678 618.655621 \n",
              "L 260.670798 619.1661 \n",
              "L 268.648919 619.652578 \n",
              "L 276.627039 620.109418 \n",
              "L 284.605159 620.359127 \n",
              "L 292.583279 620.484896 \n",
              "L 300.561399 620.647657 \n",
              "L 308.539519 620.840034 \n",
              "L 316.51764 620.995404 \n",
              "L 324.49576 621.124865 \n",
              "L 332.47388 621.341298 \n",
              "L 340.452 621.615042 \n",
              "L 348.43012 621.879537 \n",
              "L 356.408241 622.210616 \n",
              "L 364.386361 622.608304 \n",
              "L 372.364481 623.035567 \n",
              "L 380.342601 623.440646 \n",
              "L 388.320721 623.762481 \n",
              "L 396.298841 623.991825 \n",
              "L 404.276962 624.147195 \n",
              "L 412.255082 624.258174 \n",
              "L 420.233202 624.335873 \n",
              "L 428.211322 624.372845 \n",
              "L 436.189442 624.415394 \n",
              "L 444.167563 624.500488 \n",
              "L 452.145683 624.396908 \n",
              "L 460.123803 624.100951 \n",
              "L 468.101923 623.788361 \n",
              "L 476.080043 623.377733 \n",
              "L 484.058164 622.848739 \n",
              "L 492.036284 622.251315 \n",
              "L 500.014404 621.640919 \n",
              "L 507.992524 621.002796 \n",
              "L 515.970644 620.444225 \n",
              "L 523.948764 620.079846 \n",
              "L 531.926885 619.867137 \n",
              "L 539.905005 619.79128 \n",
              "L 547.883125 619.756129 \n",
              "L 555.861245 619.824588 \n",
              "L 563.839365 620.057628 \n",
              "L 571.817486 620.405375 \n",
              "L 579.795606 620.668025 \n",
              "L 587.773726 620.841877 \n",
              "L 595.751846 620.98616 \n",
              "L 603.729966 621.10268 \n",
              "L 611.708086 621.15632 \n",
              "L 619.686207 621.141533 \n",
              "L 627.664327 621.113774 \n",
              "L 635.642447 621.198869 \n",
              "L 643.620567 621.363483 \n",
              "L 651.598687 621.452273 \n",
              "L 659.576808 621.615042 \n",
              "L 667.554928 621.809261 \n",
              "L 675.533048 621.879537 \n",
              "L 683.511168 621.853628 \n",
              "L 691.489288 621.831446 \n",
              "L 699.467409 621.849932 \n",
              "L 707.445529 621.999757 \n",
              "L 715.423649 622.24577 \n",
              "L 723.401769 622.404836 \n",
              "L 731.379889 622.432566 \n",
              "L 739.358009 622.358591 \n",
              "L 747.33613 622.304955 \n",
              "L 755.31425 622.330832 \n",
              "L 763.29237 622.526905 \n",
              "L 771.27049 622.80804 \n",
              "L 779.24861 622.991169 \n",
              "L 787.226731 622.186585 \n",
              "L 795.204851 620.771605 \n",
              "L 803.182971 619.939258 \n",
              "L 811.161091 619.406568 \n",
              "L 819.139211 619.008881 \n",
              "L 827.117331 618.699983 \n",
              "L 835.095452 618.561282 \n",
              "L 843.073572 618.642652 \n",
              "L 851.051692 618.725893 \n",
              "L 859.029812 618.788781 \n",
              "L 867.007932 618.857203 \n",
              "L 874.986053 618.849812 \n",
              "L 882.964173 618.992241 \n",
              "L 890.942293 619.188311 \n",
              "L 898.920413 619.52863 \n",
              "L 906.898533 620.015079 \n",
              "L 914.876654 620.397977 \n",
              "L 922.854774 620.673566 \n",
              "L 930.832894 620.886275 \n",
              "L 938.811014 620.991705 \n",
              "L 946.789134 621.03795 \n",
              "L 954.767254 621.05274 \n",
              "L 962.745375 621.095289 \n",
              "L 970.723495 621.176655 \n",
              "L 978.701615 621.226595 \n",
              "L 986.679735 621.237718 \n",
              "L 994.657855 621.235869 \n",
              "L 1002.635976 621.209959 \n",
              "L 1010.614096 621.198869 \n",
              "L 1018.592216 621.184079 \n",
              "\" clip-path=\"url(#pf584ed0481)\" style=\"fill: none; stroke: #9467bd; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"line2d_94\">\n",
              "    <path d=\"M 77.174034 619.21789 \n",
              "L 85.152154 618.97006 \n",
              "L 93.130274 618.833172 \n",
              "L 101.108395 618.770291 \n",
              "L 109.086515 618.910843 \n",
              "L 117.064635 619.230831 \n",
              "L 125.042755 619.719158 \n",
              "L 133.020875 620.212998 \n",
              "L 140.998996 620.632867 \n",
              "L 148.977116 620.971373 \n",
              "L 156.955236 621.267295 \n",
              "L 164.933356 621.592828 \n",
              "L 172.911476 621.912813 \n",
              "L 180.889596 622.253161 \n",
              "L 188.867717 622.565755 \n",
              "L 196.845837 622.832099 \n",
              "L 204.823957 623.022627 \n",
              "L 212.802077 623.159483 \n",
              "L 220.780197 623.226059 \n",
              "L 228.758318 623.235332 \n",
              "L 236.736438 623.214968 \n",
              "L 244.714558 623.168724 \n",
              "L 252.692678 623.083658 \n",
              "L 260.670798 622.891284 \n",
              "L 268.648919 622.552814 \n",
              "L 276.627039 622.151431 \n",
              "L 284.605159 621.735258 \n",
              "L 292.583279 621.396788 \n",
              "L 300.561399 621.160019 \n",
              "L 308.539519 621.004645 \n",
              "L 316.51764 620.882576 \n",
              "L 324.49576 620.790087 \n",
              "L 332.47388 620.756815 \n",
              "L 340.452 620.747545 \n",
              "L 348.43012 620.708724 \n",
              "L 356.408241 620.642115 \n",
              "L 364.386361 620.527437 \n",
              "L 372.364481 620.329518 \n",
              "L 380.342601 620.039146 \n",
              "L 388.320721 619.67291 \n",
              "L 396.298841 619.236409 \n",
              "L 404.276962 618.740683 \n",
              "L 412.255082 618.233902 \n",
              "L 420.233202 617.765935 \n",
              "L 428.211322 617.405255 \n",
              "L 436.189442 617.129666 \n",
              "L 444.167563 616.833708 \n",
              "L 452.145683 616.399049 \n",
              "L 460.123803 615.886691 \n",
              "L 468.101923 615.372483 \n",
              "L 476.080043 614.921192 \n",
              "L 484.058164 614.604903 \n",
              "L 492.036284 614.497624 \n",
              "L 500.014404 614.554963 \n",
              "L 507.992524 614.680724 \n",
              "L 515.970644 614.950765 \n",
              "L 523.948764 615.355851 \n",
              "L 531.926885 615.792352 \n",
              "L 539.905005 616.278801 \n",
              "L 547.883125 616.761587 \n",
              "L 555.861245 617.346067 \n",
              "L 563.839365 618.026742 \n",
              "L 571.817486 618.70926 \n",
              "L 579.795606 619.29559 \n",
              "L 587.773726 619.837528 \n",
              "L 595.751846 620.372067 \n",
              "L 603.729966 620.89737 \n",
              "L 611.708086 621.381969 \n",
              "L 619.686207 621.872142 \n",
              "L 627.664327 622.33641 \n",
              "L 635.642447 622.800645 \n",
              "L 643.620567 623.296367 \n",
              "L 651.598687 623.819816 \n",
              "L 659.576808 624.402453 \n",
              "L 667.554928 624.966602 \n",
              "L 675.533048 625.458596 \n",
              "L 683.511168 625.928408 \n",
              "L 691.489288 626.427798 \n",
              "L 699.467409 626.956792 \n",
              "L 707.445529 627.519094 \n",
              "L 715.423649 628.157217 \n",
              "L 723.401769 628.813855 \n",
              "L 731.379889 629.372429 \n",
              "L 739.358009 629.570348 \n",
              "L 747.33613 629.398338 \n",
              "L 755.31425 629.006196 \n",
              "L 763.29237 628.449471 \n",
              "L 771.27049 627.816897 \n",
              "L 779.24861 627.199106 \n",
              "L 787.226731 626.603532 \n",
              "L 795.204851 626.05417 \n",
              "L 803.182971 624.715043 \n",
              "L 811.161091 622.882043 \n",
              "L 819.139211 621.252508 \n",
              "L 827.117331 619.989199 \n",
              "L 835.095452 618.9867 \n",
              "L 843.073572 618.274573 \n",
              "L 851.051692 617.919463 \n",
              "L 859.029812 617.865823 \n",
              "L 867.007932 618.246842 \n",
              "L 874.986053 618.71111 \n",
              "L 882.964173 619.284499 \n",
              "L 890.942293 619.828287 \n",
              "L 898.920413 620.338796 \n",
              "L 906.898533 620.758664 \n",
              "L 914.876654 621.008345 \n",
              "L 922.854774 621.163715 \n",
              "L 930.832894 621.313539 \n",
              "L 938.811014 621.400483 \n",
              "L 946.789134 621.393088 \n",
              "L 954.767254 621.343148 \n",
              "L 962.745375 621.302449 \n",
              "L 970.723495 621.269144 \n",
              "L 978.701615 621.197019 \n",
              "L 986.679735 621.087894 \n",
              "L 994.657855 620.952855 \n",
              "L 1002.635976 620.791936 \n",
              "L 1010.614096 620.642115 \n",
              "L 1018.592216 620.525595 \n",
              "\" clip-path=\"url(#pf584ed0481)\" style=\"fill: none; stroke: #8c564b; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_21\">\n",
              "    <path d=\"M 30.103125 687.558125 \n",
              "L 30.103125 554.218125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_22\">\n",
              "    <path d=\"M 1065.663125 687.558125 \n",
              "L 1065.663125 554.218125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_23\">\n",
              "    <path d=\"M 30.103125 687.558125 \n",
              "L 1065.663125 687.558125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"patch_24\">\n",
              "    <path d=\"M 30.103125 554.218125 \n",
              "L 1065.663125 554.218125 \n",
              "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
              "   </g>\n",
              "   <g id=\"text_74\">\n",
              "    <!-- Sample 45 Class:['LocomotorCharm'] -->\n",
              "    <g transform=\"translate(436.39 548.218125) scale(0.12 -0.12)\">\n",
              "     <defs>\n",
              "      <path id=\"DejaVuSans-4c\" d=\"M 628 4666 \n",
              "L 1259 4666 \n",
              "L 1259 531 \n",
              "L 3531 531 \n",
              "L 3531 0 \n",
              "L 628 0 \n",
              "L 628 4666 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
              "Q 1497 3097 1228 2736 \n",
              "Q 959 2375 959 1747 \n",
              "Q 959 1119 1226 758 \n",
              "Q 1494 397 1959 397 \n",
              "Q 2419 397 2687 759 \n",
              "Q 2956 1122 2956 1747 \n",
              "Q 2956 2369 2687 2733 \n",
              "Q 2419 3097 1959 3097 \n",
              "z\n",
              "M 1959 3584 \n",
              "Q 2709 3584 3137 3096 \n",
              "Q 3566 2609 3566 1747 \n",
              "Q 3566 888 3137 398 \n",
              "Q 2709 -91 1959 -91 \n",
              "Q 1206 -91 779 398 \n",
              "Q 353 888 353 1747 \n",
              "Q 353 2609 779 3096 \n",
              "Q 1206 3584 1959 3584 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
              "L 3122 2828 \n",
              "Q 2878 2963 2633 3030 \n",
              "Q 2388 3097 2138 3097 \n",
              "Q 1578 3097 1268 2742 \n",
              "Q 959 2388 959 1747 \n",
              "Q 959 1106 1268 751 \n",
              "Q 1578 397 2138 397 \n",
              "Q 2388 397 2633 464 \n",
              "Q 2878 531 3122 666 \n",
              "L 3122 134 \n",
              "Q 2881 22 2623 -34 \n",
              "Q 2366 -91 2075 -91 \n",
              "Q 1284 -91 818 406 \n",
              "Q 353 903 353 1747 \n",
              "Q 353 2603 823 3093 \n",
              "Q 1294 3584 2113 3584 \n",
              "Q 2378 3584 2631 3529 \n",
              "Q 2884 3475 3122 3366 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "      <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
              "L 3513 0 \n",
              "L 2938 0 \n",
              "L 2938 2094 \n",
              "Q 2938 2591 2744 2837 \n",
              "Q 2550 3084 2163 3084 \n",
              "Q 1697 3084 1428 2787 \n",
              "Q 1159 2491 1159 1978 \n",
              "L 1159 0 \n",
              "L 581 0 \n",
              "L 581 4863 \n",
              "L 1159 4863 \n",
              "L 1159 2956 \n",
              "Q 1366 3272 1645 3428 \n",
              "Q 1925 3584 2291 3584 \n",
              "Q 2894 3584 3203 3211 \n",
              "Q 3513 2838 3513 2113 \n",
              "z\n",
              "\" transform=\"scale(0.015625)\"/>\n",
              "     </defs>\n",
              "     <use xlink:href=\"#DejaVuSans-53\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"63.476562\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6d\" x=\"124.755859\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-70\" x=\"222.167969\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6c\" x=\"285.644531\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-65\" x=\"313.427734\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-20\" x=\"374.951172\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-34\" x=\"406.738281\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-35\" x=\"470.361328\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-20\" x=\"533.984375\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-43\" x=\"565.771484\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6c\" x=\"635.595703\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"663.378906\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-73\" x=\"724.658203\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-73\" x=\"776.757812\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-3a\" x=\"828.857422\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-5b\" x=\"862.548828\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-27\" x=\"901.5625\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-4c\" x=\"929.052734\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6f\" x=\"983.015625\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-63\" x=\"1044.197266\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6f\" x=\"1099.177734\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6d\" x=\"1160.359375\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6f\" x=\"1257.771484\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-74\" x=\"1318.953125\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6f\" x=\"1358.162109\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-72\" x=\"1419.34375\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-43\" x=\"1460.457031\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-68\" x=\"1530.28125\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-61\" x=\"1593.660156\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-72\" x=\"1654.939453\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-6d\" x=\"1694.302734\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-27\" x=\"1791.714844\"/>\n",
              "     <use xlink:href=\"#DejaVuSans-5d\" x=\"1819.205078\"/>\n",
              "    </g>\n",
              "   </g>\n",
              "   <g id=\"legend_4\">\n",
              "    <g id=\"patch_25\">\n",
              "     <path d=\"M 37.103125 682.558125 \n",
              "L 114.742188 682.558125 \n",
              "Q 116.742188 682.558125 116.742188 680.558125 \n",
              "L 116.742188 593.489375 \n",
              "Q 116.742188 591.489375 114.742188 591.489375 \n",
              "L 37.103125 591.489375 \n",
              "Q 35.103125 591.489375 35.103125 593.489375 \n",
              "L 35.103125 680.558125 \n",
              "Q 35.103125 682.558125 37.103125 682.558125 \n",
              "z\n",
              "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n",
              "    </g>\n",
              "    <g id=\"line2d_95\">\n",
              "     <path d=\"M 39.103125 599.587812 \n",
              "L 49.103125 599.587812 \n",
              "L 59.103125 599.587812 \n",
              "\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_75\">\n",
              "     <!-- feature 1 -->\n",
              "     <g transform=\"translate(67.103125 603.087812) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-31\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_96\">\n",
              "     <path d=\"M 39.103125 614.265937 \n",
              "L 49.103125 614.265937 \n",
              "L 59.103125 614.265937 \n",
              "\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_76\">\n",
              "     <!-- feature 2 -->\n",
              "     <g transform=\"translate(67.103125 617.765937) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-32\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_97\">\n",
              "     <path d=\"M 39.103125 628.944062 \n",
              "L 49.103125 628.944062 \n",
              "L 59.103125 628.944062 \n",
              "\" style=\"fill: none; stroke: #2ca02c; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_77\">\n",
              "     <!-- feature 3 -->\n",
              "     <g transform=\"translate(67.103125 632.444062) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-33\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_98\">\n",
              "     <path d=\"M 39.103125 643.622187 \n",
              "L 49.103125 643.622187 \n",
              "L 59.103125 643.622187 \n",
              "\" style=\"fill: none; stroke: #d62728; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_78\">\n",
              "     <!-- feature 4 -->\n",
              "     <g transform=\"translate(67.103125 647.122187) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-34\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_99\">\n",
              "     <path d=\"M 39.103125 658.300313 \n",
              "L 49.103125 658.300313 \n",
              "L 59.103125 658.300313 \n",
              "\" style=\"fill: none; stroke: #9467bd; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_79\">\n",
              "     <!-- feature 5 -->\n",
              "     <g transform=\"translate(67.103125 661.800313) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-35\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "    <g id=\"line2d_100\">\n",
              "     <path d=\"M 39.103125 672.978437 \n",
              "L 49.103125 672.978437 \n",
              "L 59.103125 672.978437 \n",
              "\" style=\"fill: none; stroke: #8c564b; stroke-width: 1.5; stroke-linecap: square\"/>\n",
              "    </g>\n",
              "    <g id=\"text_80\">\n",
              "     <!-- feature 6 -->\n",
              "     <g transform=\"translate(67.103125 676.478437) scale(0.1 -0.1)\">\n",
              "      <use xlink:href=\"#DejaVuSans-66\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"35.205078\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-61\" x=\"96.728516\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-74\" x=\"158.007812\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-75\" x=\"197.216797\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-72\" x=\"260.595703\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-65\" x=\"299.458984\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-20\" x=\"360.982422\"/>\n",
              "      <use xlink:href=\"#DejaVuSans-36\" x=\"392.769531\"/>\n",
              "     </g>\n",
              "    </g>\n",
              "   </g>\n",
              "  </g>\n",
              " </g>\n",
              " <defs>\n",
              "  <clipPath id=\"pc9aabe8b1d\">\n",
              "   <rect x=\"30.103125\" y=\"22.318125\" width=\"1035.56\" height=\"133.34\"/>\n",
              "  </clipPath>\n",
              "  <clipPath id=\"p56f081b087\">\n",
              "   <rect x=\"30.103125\" y=\"199.618125\" width=\"1035.56\" height=\"133.34\"/>\n",
              "  </clipPath>\n",
              "  <clipPath id=\"peda403c841\">\n",
              "   <rect x=\"30.103125\" y=\"376.918125\" width=\"1035.56\" height=\"133.34\"/>\n",
              "  </clipPath>\n",
              "  <clipPath id=\"pf584ed0481\">\n",
              "   <rect x=\"30.103125\" y=\"554.218125\" width=\"1035.56\" height=\"133.34\"/>\n",
              "  </clipPath>\n",
              " </defs>\n",
              "</svg>\n"
            ],
            "text/plain": [
              "<Figure size 1500x1000 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "sample = next(iter(train_loader))\n",
        "sample_data = sample[0].permute(0, 2, 1)\n",
        "sample_label = sample[1]\n",
        "\n",
        "num_samples_to_plot = 4\n",
        "indices = np.random.choice(sample_data.shape[0], num_samples_to_plot, replace=False)\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, index in enumerate(indices, 1):\n",
        "    plt.subplot(num_samples_to_plot, 1, i)\n",
        "    for j in range(sample_data.shape[2]):\n",
        "        plt.plot(sample_data[index, :, j].numpy(), label=f'feature {j + 1}')\n",
        "    plt.legend()\n",
        "    plt.title(f'Sample {index} Class:{encoder.inverse_transform([sample_label[index]])}')\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wuuieya0smzW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVqOOX3zA4aQ"
      },
      "source": [
        "## Define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CN9xfw6aA6Ob"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "from torch.nn.parameter import Parameter\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleTimeSeriesCNN(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super(SimpleTimeSeriesCNN, self).__init__()\n",
        "\n",
        "        self.conv_block= nn.Sequential(\n",
        "            nn.Conv1d(in_channels=6, out_channels=32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2),\n",
        "            #\n",
        "            nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2),\n",
        "            #\n",
        "            nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3),\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=2),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(16 * 13, num_classes), # 59\n",
        "            # nn.ReLU(),\n",
        "            # nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAJDan9OBGBh"
      },
      "source": [
        "## Define training functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gy4hJZsgBGiG"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "def train(train_loader, model, criterion, optimizer, epoch, device):\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "\n",
        "    for inputs, labels in tqdm(train_loader, \"training\"):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        train_total += labels.size(0)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    train_accuracy = 100 * train_correct / train_total\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%\")\n",
        "\n",
        "def test(test_loader, model, criterion, optimizer, epoch, device):\n",
        "\n",
        "    test_loss = 0.0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    with torch.no_grad():\n",
        "      for inputs,  labels in tqdm(test_loader, \"testing\"):\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          outputs = model(inputs)\n",
        "\n",
        "          loss = criterion(outputs, labels)\n",
        "          test_loss += loss.item()\n",
        "\n",
        "          _, predicted = outputs.max(1)\n",
        "          test_total += labels.size(0)\n",
        "          test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "      test_accuracy = 100 * test_correct / test_total\n",
        "      avg_test_loss = test_loss / len(test_loader)\n",
        "      print(f\"Epoch {epoch+1}, Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\\n\")\n",
        "      return test_accuracy/100\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IVmZLC3qNdx"
      },
      "source": [
        "## Define helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0DG0rl_qPc5"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZPVLvYhBR92",
        "outputId": "f1a5f2c5-7784-4a91-dc6c-cdd083f5330b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SimpleTimeSeriesCNN(\n",
            "  (conv_block): Sequential(\n",
            "    (0): Conv1d(6, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv1d(32, 32, kernel_size=(3,), stride=(1,))\n",
            "    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv1d(32, 16, kernel_size=(3,), stride=(1,))\n",
            "    (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU()\n",
            "    (11): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=208, out_features=5, bias=True)\n",
            "  )\n",
            ")\n",
            "The number of model parameters:6853\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 14.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Training Loss: 1.9429, Training Accuracy: 25.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 63.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Test Loss: 1.5386, Test Accuracy: 44.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 16.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Training Loss: 1.6744, Training Accuracy: 31.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 126.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Test Loss: 1.4075, Test Accuracy: 60.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 18.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Training Loss: 1.4586, Training Accuracy: 41.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 88.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Test Loss: 1.3066, Test Accuracy: 68.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 17.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Training Loss: 1.2950, Training Accuracy: 60.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 86.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Test Loss: 1.2271, Test Accuracy: 68.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 16.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Training Loss: 1.1708, Training Accuracy: 66.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 83.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Test Loss: 1.1619, Test Accuracy: 76.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 22.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Training Loss: 1.0708, Training Accuracy: 67.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 124.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Test Loss: 1.1053, Test Accuracy: 72.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 23.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Training Loss: 0.9862, Training Accuracy: 76.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 130.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Test Loss: 1.0528, Test Accuracy: 76.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 26.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Training Loss: 0.9131, Training Accuracy: 82.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 128.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Test Loss: 1.0070, Test Accuracy: 76.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 23.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Training Loss: 0.8501, Training Accuracy: 83.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 91.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Test Loss: 0.9685, Test Accuracy: 76.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 23.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Training Loss: 0.7959, Training Accuracy: 84.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 78.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Test Loss: 0.9377, Test Accuracy: 76.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 26.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11, Training Loss: 0.7495, Training Accuracy: 85.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 102.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11, Test Loss: 0.9089, Test Accuracy: 76.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 27.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12, Training Loss: 0.7089, Training Accuracy: 86.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 103.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12, Test Loss: 0.8835, Test Accuracy: 80.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 25.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13, Training Loss: 0.6727, Training Accuracy: 87.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 97.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13, Test Loss: 0.8610, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 23.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14, Training Loss: 0.6403, Training Accuracy: 88.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 115.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14, Test Loss: 0.8408, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 24.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15, Training Loss: 0.6108, Training Accuracy: 89.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 130.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15, Test Loss: 0.8231, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 25.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16, Training Loss: 0.5837, Training Accuracy: 89.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 119.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16, Test Loss: 0.8069, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 23.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17, Training Loss: 0.5589, Training Accuracy: 89.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 119.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17, Test Loss: 0.7924, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 22.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18, Training Loss: 0.5364, Training Accuracy: 89.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 144.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18, Test Loss: 0.7804, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 25.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19, Training Loss: 0.5159, Training Accuracy: 89.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 107.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19, Test Loss: 0.7698, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 25.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20, Training Loss: 0.4964, Training Accuracy: 90.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 86.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20, Test Loss: 0.7604, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 20.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21, Training Loss: 0.4781, Training Accuracy: 90.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 137.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21, Test Loss: 0.7514, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 26.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22, Training Loss: 0.4609, Training Accuracy: 90.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 142.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22, Test Loss: 0.7424, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 29.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23, Training Loss: 0.4447, Training Accuracy: 90.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 85.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23, Test Loss: 0.7331, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 29.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24, Training Loss: 0.4292, Training Accuracy: 91.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 91.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24, Test Loss: 0.7235, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 28.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25, Training Loss: 0.4144, Training Accuracy: 91.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 96.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25, Test Loss: 0.7139, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 27.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26, Training Loss: 0.4003, Training Accuracy: 91.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 131.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26, Test Loss: 0.7050, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 22.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27, Training Loss: 0.3867, Training Accuracy: 91.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 123.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27, Test Loss: 0.6962, Test Accuracy: 84.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 26.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28, Training Loss: 0.3739, Training Accuracy: 91.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 139.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28, Test Loss: 0.6871, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 24.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29, Training Loss: 0.3616, Training Accuracy: 91.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 119.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29, Test Loss: 0.6787, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 27.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30, Training Loss: 0.3500, Training Accuracy: 92.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 114.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30, Test Loss: 0.6704, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 23.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31, Training Loss: 0.3390, Training Accuracy: 92.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 135.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31, Test Loss: 0.6627, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 22.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32, Training Loss: 0.3284, Training Accuracy: 92.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 91.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32, Test Loss: 0.6554, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 28.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33, Training Loss: 0.3184, Training Accuracy: 92.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 119.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33, Test Loss: 0.6479, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 23.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34, Training Loss: 0.3092, Training Accuracy: 92.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 125.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34, Test Loss: 0.6408, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 26.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35, Training Loss: 0.3007, Training Accuracy: 92.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 137.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35, Test Loss: 0.6342, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 19.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36, Training Loss: 0.2925, Training Accuracy: 92.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 90.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36, Test Loss: 0.6284, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 19.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37, Training Loss: 0.2845, Training Accuracy: 92.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 100.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37, Test Loss: 0.6234, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 24.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38, Training Loss: 0.2770, Training Accuracy: 92.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 132.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38, Test Loss: 0.6195, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 24.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39, Training Loss: 0.2697, Training Accuracy: 92.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 93.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39, Test Loss: 0.6163, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 26.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40, Training Loss: 0.2628, Training Accuracy: 92.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 98.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40, Test Loss: 0.6135, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 25.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41, Training Loss: 0.2562, Training Accuracy: 92.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 130.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41, Test Loss: 0.6102, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 26.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42, Training Loss: 0.2499, Training Accuracy: 92.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 119.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42, Test Loss: 0.6068, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 22.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43, Training Loss: 0.2439, Training Accuracy: 93.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 119.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43, Test Loss: 0.6033, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 21.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44, Training Loss: 0.2380, Training Accuracy: 93.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 122.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44, Test Loss: 0.5995, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 23.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45, Training Loss: 0.2322, Training Accuracy: 94.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 137.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45, Test Loss: 0.5960, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 20.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46, Training Loss: 0.2266, Training Accuracy: 95.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 116.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46, Test Loss: 0.5924, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 22.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47, Training Loss: 0.2212, Training Accuracy: 95.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 129.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47, Test Loss: 0.5889, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 20.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48, Training Loss: 0.2160, Training Accuracy: 95.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 140.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48, Test Loss: 0.5853, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 23.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49, Training Loss: 0.2109, Training Accuracy: 95.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 143.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49, Test Loss: 0.5812, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 18.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50, Training Loss: 0.2059, Training Accuracy: 95.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 127.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50, Test Loss: 0.5771, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 22.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 51, Training Loss: 0.2011, Training Accuracy: 95.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 138.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 51, Test Loss: 0.5736, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 22.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 52, Training Loss: 0.1964, Training Accuracy: 95.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 127.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 52, Test Loss: 0.5707, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 23.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 53, Training Loss: 0.1919, Training Accuracy: 95.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 131.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 53, Test Loss: 0.5684, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 24.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 54, Training Loss: 0.1875, Training Accuracy: 95.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 133.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 54, Test Loss: 0.5664, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 23.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 55, Training Loss: 0.1832, Training Accuracy: 95.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 125.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 55, Test Loss: 0.5641, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 22.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 56, Training Loss: 0.1790, Training Accuracy: 95.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 124.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 56, Test Loss: 0.5607, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 19.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 57, Training Loss: 0.1749, Training Accuracy: 96.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 122.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 57, Test Loss: 0.5559, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 21.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 58, Training Loss: 0.1709, Training Accuracy: 96.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 127.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 58, Test Loss: 0.5506, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 22.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 59, Training Loss: 0.1670, Training Accuracy: 96.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 138.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 59, Test Loss: 0.5451, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 20.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 60, Training Loss: 0.1631, Training Accuracy: 96.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 126.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 60, Test Loss: 0.5400, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 19.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 61, Training Loss: 0.1595, Training Accuracy: 96.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 127.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 61, Test Loss: 0.5367, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 21.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 62, Training Loss: 0.1560, Training Accuracy: 96.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 129.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 62, Test Loss: 0.5352, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 22.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 63, Training Loss: 0.1524, Training Accuracy: 96.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 134.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 63, Test Loss: 0.5356, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 21.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 64, Training Loss: 0.1490, Training Accuracy: 97.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 125.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 64, Test Loss: 0.5364, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 17.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 65, Training Loss: 0.1457, Training Accuracy: 97.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 95.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 65, Test Loss: 0.5349, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 21.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 66, Training Loss: 0.1424, Training Accuracy: 97.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 121.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 66, Test Loss: 0.5322, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 21.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 67, Training Loss: 0.1389, Training Accuracy: 97.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 136.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 67, Test Loss: 0.5299, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 21.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 68, Training Loss: 0.1357, Training Accuracy: 97.00%"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 114.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 68, Test Loss: 0.5289, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 21.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 69, Training Loss: 0.1325, Training Accuracy: 97.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 134.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 69, Test Loss: 0.5293, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 21.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 70, Training Loss: 0.1294, Training Accuracy: 97.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 125.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 70, Test Loss: 0.5306, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 22.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 71, Training Loss: 0.1263, Training Accuracy: 97.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 128.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 71, Test Loss: 0.5319, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 22.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 72, Training Loss: 0.1233, Training Accuracy: 97.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 135.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 72, Test Loss: 0.5329, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 20.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 73, Training Loss: 0.1204, Training Accuracy: 97.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 136.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 73, Test Loss: 0.5338, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 22.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 74, Training Loss: 0.1175, Training Accuracy: 97.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 135.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 74, Test Loss: 0.5348, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 20.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 75, Training Loss: 0.1146, Training Accuracy: 97.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 133.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 75, Test Loss: 0.5354, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 21.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 76, Training Loss: 0.1118, Training Accuracy: 97.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 119.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 76, Test Loss: 0.5343, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 21.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 77, Training Loss: 0.1089, Training Accuracy: 97.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 137.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 77, Test Loss: 0.5349, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 20.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 78, Training Loss: 0.1061, Training Accuracy: 97.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 132.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 78, Test Loss: 0.5368, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 18.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 79, Training Loss: 0.1034, Training Accuracy: 97.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 74.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 79, Test Loss: 0.5365, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 17.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 80, Training Loss: 0.1007, Training Accuracy: 97.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 106.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 80, Test Loss: 0.5354, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 20.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 81, Training Loss: 0.0980, Training Accuracy: 97.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 128.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 81, Test Loss: 0.5352, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 21.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 82, Training Loss: 0.0954, Training Accuracy: 98.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 139.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 82, Test Loss: 0.5335, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 21.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 83, Training Loss: 0.0929, Training Accuracy: 99.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 133.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 83, Test Loss: 0.5325, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 21.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 84, Training Loss: 0.0904, Training Accuracy: 100.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 134.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 84, Test Loss: 0.5319, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 21.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 85, Training Loss: 0.0879, Training Accuracy: 100.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 132.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 85, Test Loss: 0.5323, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 86, Training Loss: 0.0854, Training Accuracy: 100.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 127.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 86, Test Loss: 0.5330, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 18.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 87, Training Loss: 0.0830, Training Accuracy: 100.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 130.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 87, Test Loss: 0.5333, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 17.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 88, Training Loss: 0.0807, Training Accuracy: 100.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 117.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 88, Test Loss: 0.5343, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 19.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 89, Training Loss: 0.0784, Training Accuracy: 100.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 122.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 89, Test Loss: 0.5359, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 21.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 90, Training Loss: 0.0760, Training Accuracy: 100.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 121.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 90, Test Loss: 0.5364, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 19.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 91, Training Loss: 0.0738, Training Accuracy: 100.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 84.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 91, Test Loss: 0.5350, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 19.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 92, Training Loss: 0.0717, Training Accuracy: 100.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 129.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 92, Test Loss: 0.5347, Test Accuracy: 84.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 17.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 93, Training Loss: 0.0696, Training Accuracy: 100.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 121.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 93, Test Loss: 0.5370, Test Accuracy: 88.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 18.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 94, Training Loss: 0.0676, Training Accuracy: 100.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 138.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 94, Test Loss: 0.5392, Test Accuracy: 88.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 21.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 95, Training Loss: 0.0656, Training Accuracy: 100.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 119.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 95, Test Loss: 0.5406, Test Accuracy: 88.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 18.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 96, Training Loss: 0.0637, Training Accuracy: 100.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 137.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 96, Test Loss: 0.5402, Test Accuracy: 88.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 20.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 97, Training Loss: 0.0618, Training Accuracy: 100.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 124.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 97, Test Loss: 0.5402, Test Accuracy: 88.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 21.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 98, Training Loss: 0.0600, Training Accuracy: 100.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 141.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 98, Test Loss: 0.5408, Test Accuracy: 88.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 19.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 99, Training Loss: 0.0583, Training Accuracy: 100.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 131.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 99, Test Loss: 0.5410, Test Accuracy: 88.00%\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "training: 100%|██████████| 1/1 [00:00<00:00, 20.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 100, Training Loss: 0.0565, Training Accuracy: 100.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing: 100%|██████████| 1/1 [00:00<00:00, 127.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 100, Test Loss: 0.5412, Test Accuracy: 88.00%\n",
            "\n",
            "0.88\n",
            "Done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "\n",
        "\n",
        "lr = 1e-3\n",
        "epochs = 100\n",
        "\n",
        "acc_list=[]\n",
        "for i in range(1):\n",
        "  set_seed(42)\n",
        "  model = SimpleTimeSeriesCNN(num_classes=num_classes).to(device)\n",
        "  print(model)\n",
        "  print(f'The number of model parameters:{count_parameters(model)}')\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    train(train_loader, model, criterion, optimizer, epoch, device)\n",
        "    test_accuracy = test(test_loader, model, criterion, optimizer, epoch, device)\n",
        "\n",
        "  print(test_accuracy)\n",
        "  acc_list.append(test_accuracy)\n",
        "  print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPQk9orrNiCr",
        "outputId": "b2a95c0b-c680-4ea3-b92b-f74a6cf32294"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.88]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acc_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muNxmPi6roqy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snog5BsGNir1"
      },
      "source": [
        "Todo: M5: https://pytorch.org/tutorials/intermediate/speech_command_classification_with_torchaudio_tutorial.html#define-the-network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEMuhawBumWF"
      },
      "source": [
        "## Model profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbed6LwCsTok"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgMnf8VOsZ75",
        "outputId": "48e5af8f-12ea-4107-e66b-f31a69b242f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "------------------------------------- Calculate Flops Results -------------------------------------\n",
            "Notations:\n",
            "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
            "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
            "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
            "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
            "\n",
            "Total Training Params:                                                  6.85 K  \n",
            "fwd MACs:                                                               330.32 KMACs\n",
            "fwd FLOPs:                                                              690.88 KFLOPS\n",
            "fwd+bwd MACs:                                                           990.96 KMACs\n",
            "fwd+bwd FLOPs:                                                          2.0726 MFLOPS\n",
            "\n",
            "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
            "Each module caculated is listed after its name in the following order: \n",
            "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
            "\n",
            "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
            " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
            "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
            "\n",
            "SimpleTimeSeriesCNN(\n",
            "  6.85 K = 100% Params, 330.32 KMACs = 100% MACs, 690.88 KFLOPS = 47.8115% FLOPs\n",
            "  (conv_block): Sequential(\n",
            "    5.81 K = 84.7512% Params, 329.28 KMACs = 99.6852% MACs, 688.8 KFLOPS = 47.661% FLOPs\n",
            "    (0): Conv1d(992 = 14.4754% Params, 114.24 KMACs = 34.5846% MACs, 232.29 KFLOPS = 16.5354% FLOPs, 6, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "    (1): BatchNorm1d(64 = 0.9339% Params, 0 MACs = 0% MACs, 7.62 KFLOPS = 0% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 3.81 KFLOPS = 0% FLOPs)\n",
            "    (3): MaxPool1d(0 = 0% Params, 0 MACs = 0% MACs, 3.81 KFLOPS = 0% FLOPs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv1d(3.1 K = 45.294% Params, 175.1 KMACs = 53.0104% MACs, 352.03 KFLOPS = 25.3451% FLOPs, 32, 32, kernel_size=(3,), stride=(1,))\n",
            "    (5): BatchNorm1d(64 = 0.9339% Params, 0 MACs = 0% MACs, 3.65 KFLOPS = 0% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 1.82 KFLOPS = 0% FLOPs)\n",
            "    (7): MaxPool1d(0 = 0% Params, 0 MACs = 0% MACs, 1.82 KFLOPS = 0% FLOPs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv1d(1.55 K = 22.647% Params, 39.94 KMACs = 12.0901% MACs, 80.29 KFLOPS = 5.7805% FLOPs, 32, 16, kernel_size=(3,), stride=(1,))\n",
            "    (9): BatchNorm1d(32 = 0.4669% Params, 0 MACs = 0% MACs, 832 FLOPS = 0% FLOPs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 416 FLOPS = 0% FLOPs)\n",
            "    (11): MaxPool1d(0 = 0% Params, 0 MACs = 0% MACs, 416 FLOPS = 0% FLOPs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    1.04 K = 15.2488% Params, 1.04 KMACs = 0.3148% MACs, 2.08 KFLOPS = 0.1505% FLOPs\n",
            "    (0): Linear(1.04 K = 15.2488% Params, 1.04 KMACs = 0.3148% MACs, 2.08 KFLOPS = 0.1505% FLOPs, in_features=208, out_features=5, bias=True)\n",
            "  )\n",
            ")\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Model FLOPs:690.88 KFLOPS   MACs:330.32 KMACs   Params:6.853 K \n",
            "\n"
          ]
        }
      ],
      "source": [
        "from calflops import calculate_flops\n",
        "batch_size = 1\n",
        "input_shape = (batch_size, 6, 119)\n",
        "flops, macs, params = calculate_flops(model=model,\n",
        "                                      input_shape=input_shape,\n",
        "                                      output_as_string=True,\n",
        "                                      output_precision=4)\n",
        "print(\"Model FLOPs:%s   MACs:%s   Params:%s \\n\" %(flops, macs, params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eriA9AvFyaIn"
      },
      "source": [
        "## Model Conversion : pytorch->ONNX->TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGmiynT-zbkv"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "from onnx import helper\n",
        "from onnx_tf.backend import prepare\n",
        "# import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xF47ZK-Wzd_T",
        "outputId": "cffb5c5e-993f-4a81-ab9d-3ee7c303b2f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ONNX model successfully converted\n"
          ]
        }
      ],
      "source": [
        "dummy_input = torch.randn(1, 6, 119, dtype=torch.float32)\n",
        "torch.onnx.export(\n",
        "        model=model.cpu(),\n",
        "        args=dummy_input,\n",
        "        f=\"model.onnx\",\n",
        "        verbose=False,\n",
        "        export_params=True,\n",
        "        do_constant_folding=False,\n",
        "        input_names=['input'],\n",
        "        opset_version=11,\n",
        "        output_names=['output'])\n",
        "print('ONNX model successfully converted')\n",
        "onnx_model = onnx.load(\"model.onnx\")\n",
        "\n",
        "# add softmax\n",
        "last_node_output = onnx_model.graph.node[-1].output[0]\n",
        "softmax_input = [last_node_output]\n",
        "\n",
        "softmax_output = last_node_output + \"_softmax\"\n",
        "softmax_node = helper.make_node(\n",
        "    \"Softmax\",\n",
        "    inputs=softmax_input,\n",
        "    outputs=[softmax_output],\n",
        "    axis=1\n",
        ")\n",
        "onnx_model.graph.node.append(softmax_node)\n",
        "onnx_model.graph.output[0].name = softmax_output\n",
        "onnx.save(onnx_model, \"model.onnx\")\n",
        "# add softmax\n",
        "\n",
        "onnx.checker.check_model(onnx_model)\n",
        "\n",
        "# tf_rep = prepare(onnx_model)\n",
        "# tf_rep.export_graph(\"model.pb\")\n",
        "# print('TensorFlow model successfully converted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2vx6E8Pzuf9",
        "outputId": "6ca0ec89-bb7a-467f-ad49-a67a3cbaeb73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[07mModel optimizing started\u001b[0m ============================================================\n",
            "Simplifying...\n",
            "Finish! Here is the difference:\n",
            "┏━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
            "┃                    ┃ Original Model ┃ Simplified Model ┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
            "│ BatchNormalization │ 3              │ 0                │\n",
            "│ Constant           │ 20             │ 8                │\n",
            "│ Conv               │ 3              │ 3                │\n",
            "│ Flatten            │ 1              │ 1                │\n",
            "│ Gemm               │ 1              │ 1                │\n",
            "│ MaxPool            │ 3              │ 3                │\n",
            "│ Relu               │ 3              │ 3                │\n",
            "│ Softmax            │ 1              │ 1                │\n",
            "│ Model Size         │ 30.9KiB        │ 28.8KiB          │\n",
            "└────────────────────┴────────────────┴──────────────────┘\n",
            "\n",
            "Simplifying...\n",
            "Finish! Here is the difference:\n",
            "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
            "┃            ┃ Original Model ┃ Simplified Model ┃\n",
            "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
            "│ Constant   │ 8              │ 8                │\n",
            "│ Conv       │ 3              │ 3                │\n",
            "│ Flatten    │ 1              │ 1                │\n",
            "│ Gemm       │ 1              │ 1                │\n",
            "│ MaxPool    │ 3              │ 3                │\n",
            "│ Relu       │ 3              │ 3                │\n",
            "│ Softmax    │ 1              │ 1                │\n",
            "│ Model Size │ 28.8KiB        │ 28.8KiB          │\n",
            "└────────────┴────────────────┴──────────────────┘\n",
            "\n",
            "Simplifying...\n",
            "Finish! Here is the difference:\n",
            "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
            "┃            ┃ Original Model ┃ Simplified Model ┃\n",
            "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
            "│ Constant   │ 8              │ 8                │\n",
            "│ Conv       │ 3              │ 3                │\n",
            "│ Flatten    │ 1              │ 1                │\n",
            "│ Gemm       │ 1              │ 1                │\n",
            "│ MaxPool    │ 3              │ 3                │\n",
            "│ Relu       │ 3              │ 3                │\n",
            "│ Softmax    │ 1              │ 1                │\n",
            "│ Model Size │ 28.8KiB        │ 28.8KiB          │\n",
            "└────────────┴────────────────┴──────────────────┘\n",
            "\n",
            "\u001b[32mModel optimizing complete!\u001b[0m\n",
            "\n",
            "\u001b[07mAutomatic generation of each OP name started\u001b[0m ========================================\n",
            "\u001b[32mAutomatic generation of each OP name complete!\u001b[0m\n",
            "\n",
            "\u001b[07mModel loaded\u001b[0m ========================================================================\n",
            "\n",
            "\u001b[07mModel conversion started\u001b[0m ============================================================\n",
            "\u001b[07msaved_model output started\u001b[0m ==========================================================\n",
            "\u001b[32msaved_model output complete!\u001b[0m\n",
            "Summary on the non-converted ops:\n",
            "---------------------------------\n",
            " * Accepted dialects: tfl, builtin, func\n",
            " * Non-Converted Ops: 12, Total Ops 27, % non-converted = 44.44 %\n",
            " * 12 ARITH ops\n",
            "\n",
            "- arith.constant:   12 occurrences  (f32: 8, i32: 4)\n",
            "\n",
            "\n",
            "\n",
            "  (f32: 3)\n",
            "  (f32: 1)\n",
            "  (f32: 3)\n",
            "  (f32: 3)\n",
            "  (f32: 1)\n",
            "  (f32: 1)\n",
            "\u001b[32mFloat32 tflite output complete!\u001b[0m\n",
            "Summary on the non-converted ops:\n",
            "---------------------------------\n",
            " * Accepted dialects: tfl, builtin, func\n",
            " * Non-Converted Ops: 12, Total Ops 35, % non-converted = 34.29 %\n",
            " * 12 ARITH ops\n",
            "\n",
            "- arith.constant:   12 occurrences  (f16: 8, i32: 4)\n",
            "\n",
            "\n",
            "\n",
            "  (f32: 3)\n",
            "  (f32: 8)\n",
            "  (f32: 1)\n",
            "  (f32: 3)\n",
            "  (f32: 3)\n",
            "  (f32: 1)\n",
            "  (f32: 1)\n",
            "\u001b[32mFloat16 tflite output complete!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!onnx2tf -i model.onnx  -v info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgK8E1xz0WVR"
      },
      "outputs": [],
      "source": [
        "!cp saved_model/model_float32.tflite model.tflite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1MvOJkFz2fT"
      },
      "outputs": [],
      "source": [
        "!xxd -i model.tflite > model_data.cc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1za2LoKk0fMH",
        "outputId": "4e37cae2-dca6-48c6-806e-64128b9be96b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unsigned int model_tflite_len = 31024;\n"
          ]
        }
      ],
      "source": [
        "!tail -n1 model_data.cc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6Jp3zNz14Ri"
      },
      "source": [
        "### TFLite float32 model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2aS78Zr16md",
        "outputId": "80135f8d-e927-4db4-e1ac-32a6629f2d71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.88\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_shape = input_details[0]['shape']\n",
        "\n",
        "\n",
        "def test_tflite_on_onebatch(inputs, labels):\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for i in range(len(inputs)):\n",
        "      # test_sample = np.array(X_test[i][:3], dtype=np.float32).reshape(input_shape)\n",
        "      # expected_output = y_test[i]\n",
        "      test_sample = inputs[i].unsqueeze(0)\n",
        "      expected_output = labels[i]\n",
        "\n",
        "      interpreter.set_tensor(input_details[0]['index'], test_sample)\n",
        "      interpreter.invoke()\n",
        "      output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "      predicted_output = np.argmax(output_data)\n",
        "\n",
        "      if predicted_output == expected_output:\n",
        "          correct_predictions += 1\n",
        "      total_predictions += 1\n",
        "\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    # print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy\n",
        "\n",
        "ts_list=[]\n",
        "for inputs, labels in test_loader:\n",
        "  test_accuracy = test_tflite_on_onebatch(inputs.permute(0,2,1), labels)\n",
        "  ts_list.append(test_accuracy)\n",
        "\n",
        "print(np.mean(ts_list))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbXDW_Jtaaue"
      },
      "source": [
        "AVG Runtime:114.18704 milliseconds\n",
        "\n",
        "RAM Usage: 24.3K\n",
        "Flash Usage: 49.9K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqWpdzMNPlh3"
      },
      "source": [
        "### Quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi5Woxu7UF84",
        "outputId": "c75529b8-6fdd-4eb2-df40-581e978587ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[07mModel optimizing started\u001b[0m ============================================================\n",
            "Simplifying...\n",
            "Finish! Here is the difference:\n",
            "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
            "┃            ┃ Original Model ┃ Simplified Model ┃\n",
            "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
            "│ Constant   │ 8              │ 8                │\n",
            "│ Conv       │ 3              │ 3                │\n",
            "│ Flatten    │ 1              │ 1                │\n",
            "│ Gemm       │ 1              │ 1                │\n",
            "│ MaxPool    │ 3              │ 3                │\n",
            "│ Relu       │ 3              │ 3                │\n",
            "│ Softmax    │ 1              │ 1                │\n",
            "│ Model Size │ 28.8KiB        │ 28.8KiB          │\n",
            "└────────────┴────────────────┴──────────────────┘\n",
            "\n",
            "Simplifying...\n",
            "Finish! Here is the difference:\n",
            "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
            "┃            ┃ Original Model ┃ Simplified Model ┃\n",
            "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
            "│ Constant   │ 8              │ 8                │\n",
            "│ Conv       │ 3              │ 3                │\n",
            "│ Flatten    │ 1              │ 1                │\n",
            "│ Gemm       │ 1              │ 1                │\n",
            "│ MaxPool    │ 3              │ 3                │\n",
            "│ Relu       │ 3              │ 3                │\n",
            "│ Softmax    │ 1              │ 1                │\n",
            "│ Model Size │ 28.8KiB        │ 28.8KiB          │\n",
            "└────────────┴────────────────┴──────────────────┘\n",
            "\n",
            "Simplifying...\n",
            "Finish! Here is the difference:\n",
            "┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
            "┃            ┃ Original Model ┃ Simplified Model ┃\n",
            "┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
            "│ Constant   │ 8              │ 8                │\n",
            "│ Conv       │ 3              │ 3                │\n",
            "│ Flatten    │ 1              │ 1                │\n",
            "│ Gemm       │ 1              │ 1                │\n",
            "│ MaxPool    │ 3              │ 3                │\n",
            "│ Relu       │ 3              │ 3                │\n",
            "│ Softmax    │ 1              │ 1                │\n",
            "│ Model Size │ 28.8KiB        │ 28.8KiB          │\n",
            "└────────────┴────────────────┴──────────────────┘\n",
            "\n",
            "\u001b[32mModel optimizing complete!\u001b[0m\n",
            "\n",
            "\u001b[07mAutomatic generation of each OP name started\u001b[0m ========================================\n",
            "\u001b[32mAutomatic generation of each OP name complete!\u001b[0m\n",
            "\n",
            "\u001b[07mModel loaded\u001b[0m ========================================================================\n",
            "\n",
            "\u001b[07mModel conversion started\u001b[0m ============================================================\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32minput_op_name\u001b[0m: input \u001b[32mshape\u001b[0m: [1, 6, 119] \u001b[32mdtype\u001b[0m: float32\n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m2 / 13\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /conv_block/conv_block.0/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input \u001b[36mshape\u001b[0m: [1, 6, 119] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: 54 \u001b[36mshape\u001b[0m: [32, 6, 5] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: 60 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /conv_block/conv_block.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 119] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: input \u001b[34mshape\u001b[0m: (1, 119, 6) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (5, 6, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (1, 119, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m3 / 13\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /conv_block/conv_block.2/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /conv_block/conv_block.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 119] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /conv_block/conv_block.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 119] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (1, 119, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu/Relu:0 \u001b[34mshape\u001b[0m: (1, 119, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m4 / 13\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool\u001b[35m onnx_op_name\u001b[0m: /conv_block/conv_block.3/MaxPool\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /conv_block/conv_block.2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 119] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /conv_block/conv_block.3/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 32, 59] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: max_pool_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu/Relu:0 \u001b[34mshape\u001b[0m: (1, 119, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [0, 0] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool1d/MaxPool1d/Squeeze:0 \u001b[34mshape\u001b[0m: (1, 59, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m5 / 13\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /conv_block/conv_block.4/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /conv_block/conv_block.3/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 32, 59] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: 78 \u001b[36mshape\u001b[0m: [32, 32, 3] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: 84 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /conv_block/conv_block.4/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 57] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool1d/MaxPool1d/Squeeze:0 \u001b[34mshape\u001b[0m: (1, 59, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_1/Add:0 \u001b[34mshape\u001b[0m: (1, 57, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m6 / 13\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /conv_block/conv_block.6/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /conv_block/conv_block.4/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 57] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /conv_block/conv_block.6/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 57] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_1/Add:0 \u001b[34mshape\u001b[0m: (1, 57, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_1/Relu:0 \u001b[34mshape\u001b[0m: (1, 57, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m7 / 13\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool\u001b[35m onnx_op_name\u001b[0m: /conv_block/conv_block.7/MaxPool\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /conv_block/conv_block.6/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 57] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /conv_block/conv_block.7/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: max_pool_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_1/Relu:0 \u001b[34mshape\u001b[0m: (1, 57, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [0, 0] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool1d_1/MaxPool1d/Squeeze:0 \u001b[34mshape\u001b[0m: (1, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m8 / 13\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /conv_block/conv_block.8/Conv\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /conv_block/conv_block.7/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 32, 28] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: 102 \u001b[36mshape\u001b[0m: [16, 32, 3] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: 108 \u001b[36mshape\u001b[0m: [16] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /conv_block/conv_block.8/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 16, 26] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool1d_1/MaxPool1d/Squeeze:0 \u001b[34mshape\u001b[0m: (1, 28, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 32, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (16,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (1, 26, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m9 / 13\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /conv_block/conv_block.10/Relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /conv_block/conv_block.8/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 16, 26] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /conv_block/conv_block.10/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 16, 26] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (1, 26, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (1, 26, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m10 / 13\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool\u001b[35m onnx_op_name\u001b[0m: /conv_block/conv_block.11/MaxPool\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /conv_block/conv_block.10/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 16, 26] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /conv_block/conv_block.11/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 16, 13] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: max_pool_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (1, 26, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [0, 0] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool1d_2/MaxPool1d/Squeeze:0 \u001b[34mshape\u001b[0m: (1, 13, 16) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m11 / 13\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Flatten\u001b[35m onnx_op_name\u001b[0m: /Flatten\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /conv_block/conv_block.11/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 16, 13] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Flatten_output_0 \u001b[36mshape\u001b[0m: [1, 208] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reshape\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose/transpose:0 \u001b[34mshape\u001b[0m: (1, 16, 13) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [1, 208] \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape/Reshape:0 \u001b[34mshape\u001b[0m: (1, 208) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m12 / 13\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gemm\u001b[35m onnx_op_name\u001b[0m: /fc/fc.0/Gemm\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /Flatten_output_0 \u001b[36mshape\u001b[0m: [1, 208] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: fc.0.weight \u001b[36mshape\u001b[0m: [5, 208] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: fc.0.bias \u001b[36mshape\u001b[0m: [5] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: output \u001b[36mshape\u001b[0m: [1, 5] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: matmul\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (1, 208) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (208, 5) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.z\u001b[0m: \u001b[34mshape\u001b[0m: (5,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.alpha\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.beta\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add/AddV2:0 \u001b[34mshape\u001b[0m: (1, 5) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[32mINFO:\u001b[0m \u001b[32m13 / 13\u001b[0m\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Softmax\u001b[35m onnx_op_name\u001b[0m: sng_Softmax_0\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: output \u001b[36mshape\u001b[0m: [1, 5] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: output_softmax \u001b[36mshape\u001b[0m: [1, 5] \u001b[36mdtype\u001b[0m: float32\n",
            "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: softmax_v2\n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.logits\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add/AddV2:0 \u001b[34mshape\u001b[0m: (1, 5) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
            "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.softmax/sng_Softmax_0:0 \u001b[34mshape\u001b[0m: (1, 5) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
            "\n",
            "\u001b[07mh5 output started\u001b[0m ===================================================================\n",
            "\u001b[32mjson output start...\u001b[0m\n",
            "\u001b[32mjson output finish\u001b[0m\n",
            "\u001b[32mweights.h5 output start...\u001b[0m\n",
            "\u001b[32mweights.h5 output finish\u001b[0m\n",
            "\u001b[32mweights.keras output start...\u001b[0m\n",
            "\u001b[32mweights.keras output finish\u001b[0m\n",
            "\u001b[32mweights.tf output start...\u001b[0m\n",
            "\u001b[32mweights.tf output finish\u001b[0m\n",
            "\u001b[32mkeras output start...\u001b[0m\n",
            "\u001b[32mkeras output finish\u001b[0m\n",
            "\u001b[32mh5 output start...\u001b[0m\n",
            "\u001b[32mh5 output complete!\u001b[0m\n",
            "\u001b[07msaved_model output started\u001b[0m ==========================================================\n",
            "\u001b[32msaved_model output complete!\u001b[0m\n",
            "Summary on the non-converted ops:\n",
            "---------------------------------\n",
            " * Accepted dialects: tfl, builtin, func\n",
            " * Non-Converted Ops: 12, Total Ops 27, % non-converted = 44.44 %\n",
            " * 12 ARITH ops\n",
            "\n",
            "- arith.constant:   12 occurrences  (f32: 8, i32: 4)\n",
            "\n",
            "\n",
            "\n",
            "  (f32: 3)\n",
            "  (f32: 1)\n",
            "  (f32: 3)\n",
            "  (f32: 3)\n",
            "  (f32: 1)\n",
            "  (f32: 1)\n",
            "\u001b[32mFloat32 tflite output complete!\u001b[0m\n",
            "Summary on the non-converted ops:\n",
            "---------------------------------\n",
            " * Accepted dialects: tfl, builtin, func\n",
            " * Non-Converted Ops: 12, Total Ops 35, % non-converted = 34.29 %\n",
            " * 12 ARITH ops\n",
            "\n",
            "- arith.constant:   12 occurrences  (f16: 8, i32: 4)\n",
            "\n",
            "\n",
            "\n",
            "  (f32: 3)\n",
            "  (f32: 8)\n",
            "  (f32: 1)\n",
            "  (f32: 3)\n",
            "  (f32: 3)\n",
            "  (f32: 1)\n",
            "  (f32: 1)\n",
            "\u001b[32mFloat16 tflite output complete!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!onnx2tf -i model.onnx -oh5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47MRtCThPnjc",
        "outputId": "f8c130e4-74b6-49d2-e5bc-91d1bce0e027"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "INFO:absl:Writing fingerprint to /tmp/tmpfk69cz9n/fingerprint.pb\n",
            "INFO:absl:Using new converter: If you encounter a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "keras_model = tf.keras.models.load_model('saved_model/model_float32.h5')\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
        "\n",
        "def representative_dataset():\n",
        "    for input_data, _ in train_dataset:\n",
        "        input_data = tf.cast(input_data, tf.float32)\n",
        "        yield [input_data[np.newaxis, ...]]\n",
        "\n",
        "# Set the optimization flag.\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# Enforce integer only quantization\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "# Provide a representative dataset to ensure we quantize correctly.\n",
        "# This enables the converter to estimate a dynamic range for all the variable data.\n",
        "converter.representative_dataset = representative_dataset\n",
        "\n",
        "tflite_quantized_model = converter.convert()\n",
        "\n",
        "with open('quantized_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_quantized_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXllBGAWXboU"
      },
      "source": [
        "### TFLite int8 model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAnL18lGXfgV",
        "outputId": "c9121276-69a6-4d1d-92f6-0f3ad5e800fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.88\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=\"quantized_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_shape = input_details[0]['shape']\n",
        "input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
        "output_scale, output_zero_point = output_details[0][\"quantization\"]\n",
        "\n",
        "def test_tflite_on_onebatch(inputs, labels):\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "\n",
        "    for i in range(len(inputs)):\n",
        "      test_sample = inputs[i].unsqueeze(0)\n",
        "      test_sample = test_sample / input_scale + input_zero_point\n",
        "      test_sample = test_sample.numpy().astype(input_details[0][\"dtype\"])\n",
        "\n",
        "\n",
        "      expected_output = labels[i]\n",
        "\n",
        "      interpreter.set_tensor(input_details[0]['index'], test_sample)\n",
        "      interpreter.invoke()\n",
        "\n",
        "      output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "      output_data = output_data.astype(np.float32)\n",
        "      output_data = (output_data - output_zero_point) * output_scale\n",
        "\n",
        "\n",
        "      predicted_output = np.argmax(output_data)\n",
        "\n",
        "      if predicted_output == expected_output:\n",
        "          correct_predictions += 1\n",
        "      total_predictions += 1\n",
        "\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    # print(f\"Model Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy\n",
        "\n",
        "ts_list=[]\n",
        "for inputs, labels in test_loader:\n",
        "  test_accuracy = test_tflite_on_onebatch(inputs.permute(0,2,1), labels)\n",
        "  ts_list.append(test_accuracy)\n",
        "\n",
        "print(np.mean(ts_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJc5e9z3Y_Ij"
      },
      "outputs": [],
      "source": [
        "!xxd -i quantized_model.tflite > quantized_model_data.cc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTCZ2hqtZMvG",
        "outputId": "2a7d38c6-ede3-43fb-ce12-a68e831aa8c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unsigned int quantized_model_tflite_len = 13912;\n"
          ]
        }
      ],
      "source": [
        "!tail -n1 quantized_model_data.cc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVnNHz4qdMeO"
      },
      "source": [
        "AVG Runtime: 33.94284 milliseconds\n",
        "\n",
        "RAM Usage: 9.4K\n",
        "\n",
        "Flash Usage: 39.1K"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
